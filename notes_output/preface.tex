\section*{Preface}
\addcontentsline{toc}{section}{Preface}
I have taught courses that engage artificial intelligence both directly---through machine learning and neural networks---and indirectly, at the level of data collection and system design. Over time, I noticed a recurring gap. While the literature offers many excellent treatments of individual techniques, it rarely provides a coherent path that guides students from foundational notions of intelligence to the advanced models used today. What is often missing is a unified narrative that connects intuition, mathematical formulation, and practical deployment across the diverse tools that constitute intelligent systems.

Courses in machine learning tend to emphasize neural networks and deep learning; others focus on optimization and operations research, from classical search strategies to genetic algorithms. Each approach is valuable, yet time constraints and disciplinary boundaries often force a narrowing of scope, sacrificing breadth for depth or vice versa. In one course in particular, a broader framework emerged---one that treated these methods not as isolated topics, but as complementary responses to recurring modeling challenges. That framework, though not originally mine, proved invaluable: it allowed students to situate linear regression, neural networks, transformers, fuzzy inference systems, and evolutionary algorithms within a single, coherent perspective on intelligent system design. This book attempts to make that perspective explicit and durable.

The manuscript evolved into a concise graduate companion that blends the original ECE~657 course voice with laboratory-style checklists and reflective prompts. The chapters move from supervised learning foundations to fuzzy logic and evolutionary computing, mirroring the trajectory of the original course material while adding connective tissue so that a reader can revisit the material years later without searching for missing context.

\subsection*{Origins in ECE 657}
In 2019, I was asked to teach ECE~657 at the University of Waterloo. At the time, the course leaned heavily toward soft computing, and fuzzy inference systems had constituted a large portion of the material in earlier offerings. Prof.~Karray, who built the course, felt it was time to broaden its scope beyond that single paradigm, and he was generous enough to let me reshape the arc of the course.

Over the following years, I came to view fuzzy inference systems as one important piece in a larger mosaic rather than the organizing principle. I iterated on the syllabus---moving topics, adding or removing chapters, and tightening mathematical through-lines---toward a narrative that is coherent, broad in coverage, and implementable in engineering practice.

At the time of this first edition (2026), the field is in the era of large language models, and this book covers them (see \Cref{chap:nlp,chap:transformers}). But it also emphasizes other ideas and toolkits that may underwrite future breakthroughs in intelligent systems: careful probabilistic thinking and diagnostics, principled optimization, sequence modeling beyond any single architecture, and hybrid reasoning approaches that have repeatedly re-emerged in new forms.

The material has since been rewritten to stand alone as a book. Any offering-specific details (schedules, grading, local policies) now live in \Cref{app:course_logistics} (especially \emph{Using this book in ECE~657}); readers outside that course need not consult that appendix.

\begin{tcolorbox}[perspectivebox]
This book treats intelligence as engineered self-correction: choose a representation,
define an objective, pick an update mechanism, and audit failure modes under realistic
constraints. Paradigms differ mainly in how they update (rules, gradients, energy descent,
population search), not in whether they must be evaluated honestly.

The intent is deliberately anti-mystical: every method earns its place by making its
assumptions and breakdown points explicit, not by fashion or rhetoric.

For a practical reader's guide---roadmap, prerequisites, and suggested reading paths---see
the final sections of \Cref{chap:intro}. Notation and reading conventions are collected
near the front of the book in \emph{Notation and Conventions}.

The goal is a self-contained reference for researchers and engineers who want a rigorous
but narrative-friendly treatment of neural networks, soft computing, and hybrid reasoning systems.
\end{tcolorbox}
