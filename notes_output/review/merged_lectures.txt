
Lecture 1 ECE657
Sun, May 01, 2022 4:22PM â€¢ 2:35:21
SUMMARY KEYWORDS
intelligent, question, machine, system, lecture, problem, exam, intelligence, ai, students, material, solve, quiz, algorithms, humans, input, understand, assignments, utility, perceived

Okay, so we are now being recorded, we'd have to run everyone. This is the first and only synchronous session this term. I made a note and I did that last year as well, I made the point of having the first session to be online synchronous, just for the students, that the A myself to come together in one space. To have a q&a, I'll present how the I think the class will look like moving forward evaluation. And give you folks the opportunity to ask questions, the man explanation and maybe change some of the ideas they have about the course. Once Once this is done, once we are once this is done, we'll move into a synchronous class on learning, or asynchronous model learning where I would be recording the lectures. First, I'll upload them to UW learn. And then we'll come to a discussion session, that's going to last an hour, an hour and a half. That one is not going to be recorded, because the intent for it is for people to make an effort to show up. And it's going to be just a discussion about the materials that had been uploaded. You could ask questions, inquire about that lecture or the lecture that had just been uploaded or anything before that. And that's why I call them discussion sessions. But the core material would be pre recorded and uploaded. So anything that has any announcement, anything official that would be in the pre recording material are posted on there. So if you choose to miss any of the discussion sessions, you will be missing something, obviously, since we're having a discussion, but nothing with them. There will be no new information presented. No announcements made during those sessions. Oh, so that's the the format I envision moving forward. I've had the same format last year for two courses. And I venture to say most of which were quite successful in terms of delivering the material soliciting engagement from students. And I think overall satisfaction was was acceptable. Is there any questions so far, you can jump in you can type questions. Whatever makes you happy. And well, this session be uploaded as well being recorded. So this session is going to be uploaded, obviously. There's Yes, I have one query, actually, regarding the asynchronous sessions. Will they be on this platform? The same platform? Yes. Or do you mean? You mean the recorded lecture or do you mean, the online session? Not the pre recorded sessions? No, no, I'll upload them again. So I usually use WebEx to record my lectures. I use this one first. I downloaded it last time. It was very, like, there was a picture that was the voice was weird. So since then, I started using WebEx, it doesn't really matter, because I will be uploading an mp4 file. So for all intents and purposes, you're actually download the video. Okay, thank you. Does that answer your question? Yes, Adam. What will be the timing for discussion sessions? The timing has been announced in email. It would be Wednesday, from six to 736 to 767 30 against the discussion session, so It could go to be one hour and a half, maybe more. We start at six anyways. Can the time schedule to be changed? Yeah, I have no commitment to anything per se. If you if you'd like I'll post a survey and see which one works. I don't want it to be early on within the I don't want it to be at the beginning of the week because I will be uploading my lectures on Saturday and Sunday. So I would like to have for you guys do have some time to have some time to review the material and prepare questions. So as you go through the possibilities, keep in mind that you need time to go through the material will there be a discussion platform like Piazza Yes, or we'll have we'll have a piazza discussion room. That's what they call it and everyone will be invited to it please also upload the lectures YouTube to it will be easy for others to access I do not upload my lectures to YouTube The lectures will be uploaded to UW learn actually believe uploading it to learn better, because you could take your time downloading it if you guys have concerns about the size, I can always compress the file I do compress the file as a matter of fact, so I'll upload the compressed file and you guys could download and depends was your internet connection you could just let it download and once done, you could watch it at your leisure over and over and over. It means once you download it means you do not have to be online to watch it. So does not mandate the existence of the internet. Beyond the period where you actually download the material after that you can be offline you could put to noon if you have a tablet you could put your tablet you could put in your phone whatever you want to do alright as long as you have the download file okay, it would be good if the lectures can be that one is on percent it means you can also okay you will read okay can we change the timings of the line discussion sessions for the ones living in India the timing of falling on 3:30am I will Mojito could we figure out a survey where we have several times I don't know what time works best. We I mean just see what what are the possibilities right because I know different students live within different time zones. Maybe we can have a poll and students can decide Yeah, yeah. Yeah, because there are multiple I've been receiving that different time zones and I'm like I think we'll have to we'll have to figure out which one that works best for everyone. But I am aware that stuff 330 and stuff no doubt. There is no option of playing the video lectures high speed of course there is an option you just need to learn how to navigate your video player. Absolutely. One student told me that they don't recognize virtually every video player does that lost their mind. One student told me that they don't like to hear my voice. It was not 1.5x Um but I am very much averse to submitting the material on YouTube. YouTube is a public platform so Changi is saying Mmm, I'm sorry I missed, do we have Piazza discussions, we are going to be opening the piazza discussions. Mohit and I had yet have yet to meet and arrange for the logistics of the course. But we are going to have Piazza discussions, we are going to have lots of things. But I'll have also to drop the Code of Conduct when it comes to Piazza discussions. For example, you cannot discuss assignments solutions to assignments in Piazza discuss your plan we have, we already have two exams, we discussing the exams pre post or within the exam on Piazza. So it's gonna be more like a public square, in which we will discuss the course, but not the delivery not cooperate on deliverables. Especially they are have been designated to be an individual effort or a designated group effort. Okay. So as I said, today is going to be the only synchronous lecture we are not going to be taking I don't believe we are going to be taking a break today, which is going to go for two hours and a half. And we'll we'll break at at 8pm is Eastern time. I'm not sure if it is a steal. And after that, everything is going to be recorded. Okay, so there's a few housekeeping items that I'd like to start with. And then we'll go into a little bit of the material. Your instructor is me. My name is Haitham Amar. I've been to this is my third time. So the lecture would be around two hours of recorded material. It varies like I usually say it's two hours, sometimes a little bit more than two hours, sometimes it's a little bit less than two hours. From what I've seen last term, they are a little bit over two hours. So which if you convert it to a live session format, it's funny enough, it converts to around 3.5 or four hours. But there is no interruption when you're cold, right. Anyways, your instructor is going to be me. My name is Haitham Amar. This is the third time I teach this course or the third term, I teach this course, the second time I teach it online. So I'm um, there are a few learnings that have occurred with me over the past that they had applied in this particular chair, those learnings, basically on the assessment criteria, in light of the challenges that we've had last in particular, but even the term before all material are going to be uploaded to learn. Piazza again is a platform for communication, nothing that is going to be only there. So I will not be uploading, I can upload the material in many places. But do expect that the single source of truth that you repository for the course is going to be UW learn. This way, you don't have to go to many platforms to find a crucial piece of information. Announcements, the announcements are going to be sent via email. I mean, if I feel like it, they are going to be sent via email. But any email that goes it will be also an announcement on UW Law. And this way, if your email goes to spam, if whatever happens, there is a copy that you can actually consult to the format as I had said earlier is going to be an asynchronous format. So a lecture that is pre recorded, uploaded and then And welcome, welcome to a discussion that should your stay is is Mojito children. Today I collected right. Because the reason why I wanted to correct is because God is also proper last name. So anyways, obviously this is, these are interesting times in a sense. It's online, so there's no actual office hours. There's no actual office. But obviously we'd like to help you. And we'd like to be available for you as much as possible, as much as needed. Please be mindful, also the time of the TA, but anywho, you could trade you need to arrange some time for. For support, you could email monitoring, and men should be able to, to support you. But please, please do be mindful of the time that is booked, okay. Alternatively, if it turns out that there are a lot of incoming traffic of students asking questions, we may end up generating a whole nother set of virtual classrooms, well, that would be the office hours. Okay. But for now, let's make it on a need basis as as pair just just in the new male Salesforce registration waiting list, I think everyone here is registered. That's the only way you could actually get this lecture. But if you registered and you're considering halting this course has been historically known for not allowing students to audit. The main reason it's very demanding on the TAs, as a matter of fact, fact last time, we barely met the due date to submit the marks because it is we're working day and night to go over the marking. So it's just it just takes a lot of time. Like to keep that effort dedicated to the registered students. We have 140 registered students. We do have a waiting list. And we have students on the waiting list. I know at least 10 or 15 students. So take a look. Listen to what they have to say. And see if you like what you're hearing. And if this is in line with what you want, in your research trajectory or your degree requirements, and you want to keep the course in please, by all means stay. But if you want to drop it, you don't have to wait up until the last moment. There are other students who wants to take the score. So let's be mindful that again. That is if you want to drop it and you're just waiting. Lots of most of our communications are most all of the communications are going to be on learn. Do enable your email notification, use the message boards, check religiously on it, just see there so you didn't miss anything. If you need anything done, email me or email me later. Don't shy away from sending any communication. As a matter of fact, we I am known for missing stuff. So I rely on you folks on on or being the driver for the course accidents. So I am never bothered. If anything is missing, if anything is not in the right format. do email me I'll meet I'll take care of it. So how's the course going to be evaluated? Well, we have a few blocks for evaluation. We have assignments. They constitute around 40% of the marks. There will be three or four, I don't have a doubt of how many I have, will be maybe challenged by one to roll them out. So we'll see how it goes depends also on the pace of the lectures. But there will be three or 4am leaning that there are going to be four assignments. But we'll see how, like if time permits, obviously. Anyways, collectively, they will constitute around 40% of the marks. In the past, it was an individual effort that that that had proven to be challenging for the TAs to mark could imagine marking 140 assignments every other week. So this term, I made it a group work and the maximum size of the group is three, I have already created the groups, you could go there and self overall. Once we create the piazza space, you could go there, see, who do you want to report, you can post announcements there saying Hey, who wants to partner up with me, your work is going to be only for the assignments. So if you like a group, when it comes to distributing the effort, great. There are no strings attached beyond the assignments. And obviously, in in the middle of the term, if one switch groups, for whatever reasons, we will be accommodating of that. Okay, so you didn't have to feel stuck. If things did not be different from your expectations. Causes, we are going to have a quiz virtually every lecture week. So the term is around 13 weeks, we have today there is not going to have any quiz today. We have two weeks that are going to be for the exams, there will be no lectures, no quizzes there. And they're all going to have 10 sold weeks of material. In those 10 weeks, we're going to have 10 quizzes, the quizzes together constitute around 10% In the month. So why do we have the quizzes? Well, we have the quizzes to make sure that you folks are engaged. And again, we are going to be sending a survey gauging what is the best time for the quiz. Mohit, I can also include because it's going to be an automated quiz. You can include anytime from eight a m. and include also weekends and see what most people want to do. So there are less it's less challenging in terms of what time is a quiz. So anyways, the goal beyond the quiz is to first keep you engaged with the material. keep you interested in knowing what's going on and learning about it. To train you to use the online platform when it comes to the exercises. So you know some people have mentioned that they haven't they haven't had the experience, you know going to UW learn an answer an N an exam and submitted answers. So the quizzes are there for for training purposes. Also, to give you a sense of what the questions will look like, in the first and the second exams, it just a sense of what again look like obviously, I'm not gonna be repeating my questions. But it's think of it as an as an as an online preparation for for the for the exams. So a question we're having is can the assignments be also worked upon individually, you have a choice, you always have a choice. You could work individually, you could work in a group, you don't that your choice end at a group of three people. So that's that's the, the extent to which you could work with others. So a group of one is still a group and a group of three is a group it's a choice you need to make If you can't find a partner who will do everything in our power powers to pair you up with others, but if you choose not to pair up then who are we to say? No? Will there be lecture and quiz during the reading week? Do we have a summer reading week? An idea No, I don't think there is because it ends early. There's only like the course only goes to like the first week of August so it's like shorter than most most terms No, I'd venture to say even full doesn't have anything week for the graduate students only winter has everything week. All the winter has anything week that occurs. Oh, for graduate students. Oh, you guys, you guys have autumn look. Please, when I was a student, we had a reading week only info. I teach in winter and summer. So other than my experience as a student, I didn't have experience with a fall has a reading week a lot. Will there be lecture during the reading week we just establish there is no reading week, or there wouldn't be a reading week are the quizzes at the end of the discussion lecture. Or just scheduled after it? Originally they were scheduled after it. But we'll roll out a survey. I'll see how it goes. All the quiz be during the session the election. These session the election. Again, we're going to send you get we're going to be sending a a survey. Whatever you folks agree to all just we'll just do we'll just abide with no, just to clear up with a request video discussion? No. You can do it. No, no, no. That's us. It's gonna be on learn. So as long as you have an internet, and you're able to access, learn during the period of time that's dedicated for the quiz, then you can do the quiz. So the quiz is going to be limited, it has a start and end date for 30 minutes. Within the first 30 minutes, you're going to have a quiz that is 10 minutes. So as long as you're available for 30 minutes, you should be able to do the quiz. And the reason why I'm limiting it to 30 minutes of period is basically it's a very simple quiz. And the questions are fairly easy anyone. I want our limit the cooperation between the students so I didn't have much options to be quite honest, I can just make it up in quiz any question? Exams we are going to have two exams. I know in the course outline, I said final, it isn't final, it's a second exam. And 13 minutes be extended because he will reverse the lecture videos at different times. While I assume everyone will go through the lecture, by the at least within 48 hours, or 72 hours from their release. Think of it as a lecture time. So if we had the original arrangement, ie where the course will be Tuesday and Thursday, or Tuesday or Friday, a lecture will be given Tuesday and lecture will be given Thursday and you have a quiz at the end of Thursday. Right? Like if you were in person, so I'm going to I'm not obviously going to throw the quiz right on the lecture day, or the day after or the day after. We'll keep a buffer time between the material tested and the material rolled out. In the past I tried my best that the quiz doesn't cover the most recent theories material. So that gives you Some solids, that was an arrangement that I've done in the past where the quiz covered a week old material. I'm coming to your point charming. So two exams first and second. So the first will cover the first half of material, the second will cover the second half of the material. So there will be no overlap. So that's why I'm saying, I know I said final. But that was, that was a mistake, it should be called a second exam. Both of which are each of which constitute around 25% of the mark. The obviously going to be one hour and a half, 90 minutes 60 to 90 minutes, we'll have to figure out the duration based on the complexity and the expected length of the questions. So far, I've made a determination that the exams will fall within the normal course hours. So if you go to the course schedule, you will see that we have we have time that is booked for the course. It's from 1130 to one on two days of the week. So I am just to make sure that we didn't end up with disputes and timing issues and stuff. And whatever, I lean heavily that excels will fall within the already predetermined times for for the course. And those times happen to be suitable also for students for outside of Canada, unless we have more than 12 hours difference, in which case, it would be very tough for them. But anyone within anyone within you know six to 12 hours should be able to six I mean, pre or six after it find the time within the reach, because it's going to be in the morning, Eastern Time. That means afternoon or evening outside of Canada if you're off to the east. Any question? As a graduate course, can it accommodate any project work in the course. So the course in the past had a presentation and narrative paper. The challenge we're facing right now is straight up. Presentation there's I didn't find a proper way of doing presentation like advanced screens in the past to submit the presentations. This is proven to be cumbersome for them. I mean, not in UW in other programs that they're teaching with little benefit to the students because you're not getting a little real life feedback. No one is challenging your statements. As for the reports, the problem is marking. We'd like to go and read the reports in detail at this point with 140 students, whether it's individual effort or group effort, your token is talking about 60 or 70 papers to read and Mark and that is that is not going to be easy. So usually in large courses we didn't do a lot of research work unfortunately. So alternatively, we we did the present we're doing the assignments and the assignments you'll be asked to to prove stuff or research. That's somehow an alternative to the course project. But I understand they're not within the same link. Any other question? Does this course relate to Eazy E 657? A? If yes. How is it more theoretical? Well, last summer I taught the two courses in parallel. And I had to I had students who attended both both classes with me and the risk of sounding philosophy go any AI or machine learning course, is related the other courses of the same field. Just it right, it cannot be teaching, there is no course that has a unique material of its own. There is no graduate level course when it comes to AI that has a unique material of its own. However, in the world, as I was working over a C 657, and EC 6578, I tried my best to create a clear distinction between the two courses. So is the 6578 goes in goes deep. In deep learning, like it's really goes deep, like the first part has a lot to do with data. So you have data, you have data cleaning, formatting, then you're talking about the different data management approaches, you're talking about different dimensionality reduction techniques, PCA is LDA is ice maps, and so on and so forth. You have clustering as well, that I don't teach any of that in this course. Not in detail. What we teach in this course, is tools of intelligence system design, which means we will go as broad as gets to cover many, many areas. So we'll be covering soft computing, we'll be covering neural networks, we'll be covering different classifiers, we'll be covering different classes of neural networks and other networks. Right, there are things that are unique to this course. We'll be also covering fuzzy systems, I am not aware of any other course that covers fuzzy systems that are very much in use in the industry. It just they haven't didn't have the the fanfare that it is, we'll be covering evolutionary computing as well, which I am not aware of them being covered in other courses in ECE. Maybe they are maybe they aren't. So do we need to know the basics from 6657? A, that will be required for six or seven? No, I just mentioned that I had students who are taking the two courses, or taking the two courses and same time. And that was okay. The major overlap happens to be in neural networks. Because I mean, in my version of the two courses, because when I teach neural networks, like I have one certain way of teaching your network, and I this is how I present the material anyways, other than that the overlap is pretty much diminished. So to answer your question, no, you don't need to know the basics from 657. And if anything comes as a basic, I will just cover it regardless. So if if I'm teaching a subject and the subject has clustering in it, as as an example, I'll just go and explain how plus one plus one work. Like in 1015 minutes, the online format allows me to do these things, right, because they do have control over time. So don't worry about dependency. On other AI and machine learning courses. I'll I'll make sure that I cover all the bases. And you guys could give a feedback and say, Hey, we didn't understand this. Can you please expand on the next lecture? I'll record that what background is recommended for this course? Well, this course is in AI and machine learning course. So it requires it requires the ability to understand various mathematical concepts I mean, you know, the calculus of matrices, for example. So you should be able to understand when I talk about mathematical concepts or be able to go and research and understand what you're looking for this is very beneficial to understand how the algorithms are designed and they operate. What textbooks should we refer for to for each section of the course I attached the book Many textbooks in the course outline, I suggest that you go and review you review them. Professor, would you also cover the math behind the algorithms? Yes, I will be covering the math behind the algorithms. So I will be covering the math behind the algorithms, how they operate. And again, I don't assume any prior knowledge. So sometimes you might find the lecture to be quite boring, because you do understand the the basic concept of stuff. But if can always skip that part. I'll make sure to cover it for those who, whose whose exposure to all the subject happens to be this course at the very beginning. So I always assume that what I'm saying people hear it for the first time might be an easy assumption, but it usually pays for well. Any other question? All those proofs, proofs of algorithms, we asked in the exams? It's an online it's an online exam. So the answer is quite obvious. You never say never. But I didn't expect you guys to be deriving mathematical formulations. Using learn what prior knowledge is required. First see 657 Piazza created not yet we'll we'll create it over the weekend. And then we'll connect you folks and let you know. What is what's fried knowledge is required will prognosis squad, this is a graduate course. So you have the prior, I assume that you know you have the prior knowledge for for the actual program. This course is not any different, apart from Python, nor do we need to have knowledge of other programming languages. I'll come to that. If you guys have any question about the exams, I'd like to go to the next slide. That covers the background. So is the 650 or covenant is strongly recommended? Most of you have that taken the 660 What if you're comfortable with programming and you know, the infrastructures and what have you in this great math and linear algebra, you know, sets matrices transpose, cross product dot product matrix multiplication, you know, solving system of linear equations. Programming, you should be comfortable with programming. This is essential. I'm not, it's nothing to talk about the language, you should be comfortable with writing code. You're not a developer, but assignments will have will have lots of programming. So you should be comfortable with doing so. Writing and presenting. This is an this is an outdated, outdated slide. Up until recently. We will debate debating whether we have broad projects or not. So as long as you're comfortable with the general writing and submitting your assignments, I'll be happy with what you have probability and stat. It's not required. Anything that comes that I think needs explaining, I'll explain it. But obviously, it would help if you folks do your own individual reading. Course Resources, I do not have a website. So for that, see computing resources pages, the page on those sites, your web site, like they have different resources there. You could use whatever there none of the times will expect you to be to require heavy processing powers. So a personal computer is more than enough. But if you feel that you need more, there are more. There are resources that the university make available for you folks Are these are examples of other common resources out there? In case you want to have more exposure to machine learning problems, codes, and so on, and so forth. Only one tool, not tools is needed for this course. And that is Python. So I do expect you when you do your assignments, to use Python for programming, it is the de facto AI machine learning language. If you're seeking, if you're doing research, lots of tools that have to do with it have to do with AI machine learning are almost exclusive on Python, are done in a really good way on Python. There's a huge community support to it, it's a free. Also, if you're trying to find a job. No, there's no logic for the exams. This is this is an outdated slide I'll make sure to clean this up and reupload. If you're seeking employment, then the de facto tool that you will be tested on with the Python and maybe with SQL. But Python is pivotal. This area field a big learning with this research or, or employment. Scope and structure the course is useful for graduate students in virtually all areas of engineering. Especially if you're dealing with complex systems, or processes. A form of background can be useful in fuzzy logic and artificial neural networks. You don't have to have that background. If you do it to create if you don't have coverage, when you have two major parts, the first part has to do with again, this is outdated. Now the cost structure is two halves, the first half will be dedicated to new to connectionist models. So neural network deep learning different sorts of networks RBF sanitario. And the second half will be involving fuzzy inference systems and evolutionary computing 70% of the material will be about connection connections, more models, and the other 30% will supplant the fuzzy inference systems and evolutionary computing. Any questions so far before we get into the meat of this course we can't have a wonderful an exam. So the exam will be extremely fixed. So we are not we're not going to be able to allow for a window we'll try to find the desk timezone. That works for everyone. But we'll have to we'll have to, we'll have to be mindful of the the majority of us. Obviously, I cannot be creating a large number of exams. And therefore, I cannot be doing a window. I tried to do a take home exam last term 46578 When I gave windows 24 hours, that did not end up well. Most students have complained it was difficult to a stressful and you know, being committed to an exam for 24 hours as you might appreciate isn't the most enjoyable experiences. So the exam time is going to be fixed. HIePRO so I'm not asking but like a 24 hour window for the entire exam was just saying that if we can have that window for starting the exam, I mean the exam will have to fix timing of use it like 90 minutes or so. But if we can have a window in this day I understand. I understand. So let's say the window is between nine 9am and 9pm. Right? Yeah. Okay, you take it at 9am, and someone else takes it at 3pm. Right? It's going to be the same exam. So I cannot be rolling along the exam to be rolled out over 12 hours. You can see how that logistically wouldn't be working right? Otherwise, otherwise, I'd have to design 12 exams to make sure that the questions aren't being shared from Thank, you know, as being a beginner to AI and machine learning, it's suggested to take both together in the same term, what are the both just ticking the center, I feel that would be too much of a load a high dosage of this game subject. And it was 657 A's offered twice a year. So you really didn't have to do that, right? If you started in winter, then you take six 570, naturally, you started in summer, of course, you can take it it's offered. If you want to hold until the other winter, then that's fine as well. But there is no connection. In the 2%. There is no dependency between the two courses, that makes it advisable to take both in the same time. Other than maybe having a high dosage of the same subject. And also be worried that you might confuse yourself, because sometimes concepts or concepts are explained differently. So maybe to a fault of the way I explained stuff or the way things are received, you may end up confused because there is no confusion. So be wary of that one. So last time, I taught both courses. Of course, when I teach both courses I speak I in my mind, I speak to two different audiences. And sometimes my statements had been perceived to be contradictory. They weren't. But again, students had to juggle the two courses like they aren't 657 talking to me, and they're bringing 6578 I don't think they had fun. Any other question? Okay. We will still have support to deal with situations like blackout, of course. Of course. You can, you can bet on if you lose access, we can see that the student had lost access to the exam. Because part of the stats, I get to learn how much time a person spent in the exam. So obviously, if something goes wrong, obviously with you helping you out and that's, that's a given, I wouldn't be worried about that. Doesn't, I'm just going to create another exam for you. That's fine. So again, these are tough times. We need to be mindful of each other, we need to be helpful with each other. And then you know, we'll see how it goes. But I do expect mutual support. Okay, artificial intelligence. So the course is name tools, artificial intelligence, or intelligent systems. And you will be asked about what's AI? A lot of people are confused what the heck is AI? Right? And their confusion happens to be like AI is seen as, you know, image recognition. That's AI, voice detection, that's AI but that's a subset of the field. So, instead of defining a field by fames applications of it, which is the pitfall that most people happen, you know. following week on fi artificial intelligence as it is, so again, it is not It's most famous features, it's a body of collective algorithms and research and conventional wisdom. So, AI is basically algorithms enabled by constraints exposed by representations that support models that are targeted at thinking perception and action. Again, algorithms are talking about sets of algorithms enabled by constraints exposed by representations and that support models and are targeted at thinking perception and action. So, without a loss of generality, intelligent system is one that generates hypotheses and test so, any system that falls within this range of generating hypotheses and test them is in our book a an intelligent system right. So, so, AI models that targets thinking the target perception the target action can explain the past should be able to understand the present and predict the future right to build a model that is constrained, that is represented fairly well. And it is targeted at thinking perception and action, those models should be able to functionally speaking, to understand to explain the past what's happened to understand the current present, right. And to be able to predict the future, you know, you understand it's an obstacle, you predict you can hit it and therefore, the action is to avoid sorry, if you are able to properly think perceive and then make a prudent or an intelligent action so, so, it's all about representation, right? If you think of it if you're building an algorithm to solve to solve a problem, well the first question would be What is the problem right, what are you trying to solve for? Okay, so, you have to define the problem, how to present it, the problem is that I would like to be able to recognize stop signs, okay. Then I will be representing input as matrices of numbers. Alright, so, okay, that's a representation of source. Okay. So in essence, you need to define and understand your problem. So once you have that representation in place, in it to be able to say okay, what do I need not to solve? Again, it's a car, turn around perceiving the environment. I want to limit the search area, limiting the search it means I don't care for anything that is on the side way. So I don't care for obstacle there. So you limit your surgery I'm not too worried about small rocks, you know, pebbles and what have you. Right, which means you need to have an objective. So what are you trying to do? Trying to avoid obstacles? Okay. Maya objective is to always have at least five meters between me and any obstacle. So, you okay? Now, now you have defined your objective, you need also to define what are the things that are going to be preventing you from from reaching, you will go. So, once you have all that understanding, you should be able to devise an algorithm. So, we said AI is about thinking, perception and action and thinking and perception is basically how to perceive the environmental interpreted how to understand it, how to argue objective functions and constraints. And then based on all that you have, you have a set of actions to choose one of them and to act on it. Once we've done that, we will need to define what are the intelligence systems? Well, the intelligence systems are artificial entities involving a mix of software and hardware. They have the capacity to acquire and apply knowledge in an intelligent manner. So, they're smart. Which means when they perceive an instance, they do understand it, they do absorb it. And obviously, they do act based on their understanding and absorption. And they make a decision. It is a mix of software and hardware software, the way with which you're making this reasoning, the hardware is the way that you are able to act. And also, and this is very important. You should be able to act on incomplete information. So the system is imperfect. The system doesn't assume a perfection of the input. It's as a matter of fact, it is as a matter of fact design to handle imperfections. That's the system. If you aren't able to create something like that, then you have intelligent system. And the question. Yes, okay. So, can I say like, for example, if there is a camera with AI capabilities of identifying humans, is that an intelligent system? So let's actually, let's deconstruct, let's deconstruct what you just said. You said, if there is an AI cam, there is a camera with AI capabilities. Yeah, and it can detect humans. Okay, so what do you mean, but what do you mean by that? Let me break it down. So the camera perceives, right, it takes pictures. So it perceives things objects, people obviously, then that perception is observed. You know, you convert an image into an array of numbers, then you have an algorithm. And that algorithm processes, the inputs. That's, that is not the matrix of numbers. Add classified into human Anil? Yes. Right. So this is a hardware. That's the camera is the software that sits behind that actually makes sense of the of the input. If you have both of these things in place, then yes, you have a is an intelligent system on the same camera, with AI capabilities, cameras, just the hardware that captures the camera, the software, and the way they interact together. That's Intelligent System. System of components. Thank you. Alright. Yeah, any other question? Any other question? Hi, Professor, a quick one. In this course, are we only going to be talking about intelligent systems where they have some sort of internal world model? are we limiting? Are we looking at it more from a connectionist approach? As opposed to as opposed to an activist approach where you You can have a series of interlocking systems that don't necessarily talk together talk with one another, but may produce some results well evolutionary computing is like that right? What do you have systems, you would call them that are agents or that are working towards a network manner towards the solution, right? That was one computing for example, but most existing models are connections, right? They have stage you have input stage output stage, and they are connected. And each stage serves serves a purpose. So, unless you have an example of an algorithm or something, I would I would say yes, but I'm afraid that I might be missing something. Like an example of a system that you think, belongs to the latter. Something like for example, so, like, a Boyd system would be an example, where the trajectory of a swarm of boys is, is sort of calculated dynamically, but they don't really have a good understanding of that is illusion of computing, right. Alright, so we'll talk about swarms of agents. Fair enough. All right. So that's only where I see it work. And again, the reason that they didn't talk to each other, they tried to solve the problem individually. But in doing so they're solving the, it's like someone tried to solve a small piece of the puzzle. Think of a big puzzle, and you're solving the corner of it. So as solving other corners, someone solving another corner. Eventually, it will solve the entire puzzle, right? But you're only solving for the chair or the table this guy. That's how they work. It's not just by an overall intelligent design, just make sense that you're breaking down your problems to subproblems. So as you solve your sub problems, you're solving the bigger one. So yeah, in that context, we'll be covering those most. So we're going to connect, we're going to come up with connectionist models and connection LIS models as well. But they're very confined in a very, very different set of approaches around groups. are intelligent systems only treated as a yes no, either intelligent or not? Or Are there levels to evaluate how intelligent systems let me think so let me answer this question later, later in today. Because I would like to discuss that within a larger subject in what is intelligent system. Right. So I'll answer today, but let me answer it after a few slides. Building Intelligent Systems is called AI. Is that right? Professor? Arsenal question later as well. I'd like to go into that subject. As part of what you have the introduction anyways, it's good that you guys are asking these questions, means the line means the logical flow of the material would make sense. So let me I'll get there that we go through the history first. And I think I'll be able to, we'll be able to have that discussion. And it was will intellectual was on that discussion. So what's the history of intelligent systems and maybe this helps you think of how far back we can go in, in finding intelligent system. I've done my own research. This is not you know, a fact to the absolute history. Someone might charge it. There's something before that, but this is my own personal research. So as far back as I could find It's the 12th century where was a scientist researcher and an inventor. I think in present day Iraq his name was Algerie. And he created lots of Intelligent Systems auto matter where he wrote a book that he had described in which he has got 100 mechanical devices, one of which was a humanoid automatic. So basically it is on birds design sliding doors, he designed something that looks like a human or humanoid, all which is mechanical with with a preset with actions preset are predefined into that automatic. So you know, they will move around. So the humanoid will move in in a defined track, and then reach you raise a couple will hand over the cup to you. Like there's a resemblance of intelligence, and the fact that it's a sequence sequence of logic and actions that serves a purpose that you understand. And that has a sense of perceived goal behind the action. So that's as far back as you can go to find an actual invention that can be described as intelligent. But was obviously hard coded, not hardcore, it was mechanically designed. So it's like dependent in water movement, and steam and stuff like that. And then around the 13th century, we started seeing the definitions of the mathematical definitions of reasoning. You know, if A and B and C is B, then A and B have the same such a equal, if a looks like B and C looks like B, then A and B look like that kind of reasoning, we start to see a clearer definition of it around the 13th century. And we had to wait for around six centuries of advancement in math and studies and physics and science across the board to have our actual first mechanical computer that was designed by Charles Babbage in England on the 19 century. It it's an it's an, it's an mechanical computer that was presented with mathematical problems, it will actually split out without the answer. Right. And the first program written for it was written by, by Lady or them like she was there by Lady loveless. So she's the first non programmer. And she wrote in the 19th century, a set of notes that completely detailed the method of for calculating the lowly numbers. So she worked with cell damage on the first mechanical computer, I do remember, I do remember a part of that of their work or when they had presented their work someone said to Charles Babbage, sir, please pray says to me, if you put a wrong input to the machine, would you get a wrong output? And Babbage said, to the extent he couldn't even fathom the logic that was behind this thought. So that was the first instance when defined garbage in garbage out. And then, again, a great deal of advancement took place. You know, we saw a computer but we didn't really see a huge jump until the Turing test in the 1950, which was a defining moment and from there, things just exploded. We started seeing machine learning a defined machine learning algorithms by the mid 20th century. So in the 50s, you're struggling with perceptrons and, and stuff like that. that there was a scientist that was by the name of James Roberts lay Slagle, who created what can be considered a truly first intelligence program is symbolic integration program. We will actually take it in this course. In our first pre recorded lecture just tell you how an intelligent system had been created that solves a mathematical integral problems. Then, fast forward to the 70s, there was the Meissen program. It's a backward chaining expert system that uses artificial intelligence to identify bacteria using causing severe infections. It's an FL SCADA program. It asks you questions, you answer the question, then based on your answers defines the next step and the next step and the next step and the next step. And then it prescribes two sets of antibiotics and it did actually work with the exception like it will give you a bag of antibiotics and distribution. So anyways, was bugging the prescription but wasn't it was better. We'll talk about about about that. limping when I go into what is an AI it was considered to be a great system. In that it was able to identify the problem once the problem once the problem has been composed, dissected and decompose. And then we had deep blue of IBM late 90s or before that we had the Terminator movie. Or after that, we had the deep view of IBM where we were able to design a computer that beats humans at playing chess and it was quite successful in the late 90s It was very quiet it was quite the rage as matter of fact, I think Kasparov was playing against deep blue I think he won one game and he lost two games and that's when people started thinking oh yeah AI is really is real is it is a that was like more than 20 years ago and then deep learning took on with with many cool and practical applications an example of that is what I'm about to show you let's see if this works then next to x so this is Tesla as you can imagine is this is a completely self driving vehicle you see the different cameras in place the objects identification of the machine a car is a machine navigates This is the world as the world as a world as seen by the car as seen by the driver. This is the world as seen I mean we've seen them on your right side is the world as seen by the car. So when the car sees is basically either obstacles or obstacles so they try to avoid obstacles I think at this point it's an attempt to park so anything anything a glorified You have to understand that to humans. Every decision we make is just a series of if else This process is right. That's that's basically your decision is not this is that okay, so I think that was for Deep Blue not the Tesla Autopilot, you will find that they're actually not that different from each other just a different problem space some of it is cooler than the others. But make no mistake a cool problem or cool solution doesn't mean the underlying logic is is superior to an A to A to another problem that is boring or not as exciting features what are the features of intelligent systems right we said Intelligent Systems Well, a feature that is indispensable in these systems is the duration of outputs based on some inputs and the nature of the system itself. Right. So, the system has to be able to influence the output based on understanding of the input a smart system is a system that they just understand and produce outputs. That that is the the process of digestion mean that the system has a nature of its own, that controls or that influences the output. So there's this there's a sense of individualism there or a sense of self in the entire process. So, if you have such a system or system that has these features, where the inputs are, include information that can be in tangible forms or tangible items, pictures, numbers, sounds, signals, that ascribe touch you know, and outputs that include decisions that can be mobility, like like I've seen with a Tesla or the car moves or stops or spits out zero or one or move your visual move your castle, your queen, any of these things, then you have an intelligent system. So, what are the capabilities that dictate an intelligent system? How do we say a system is intelligent to like, what are the capabilities that we expect the system to have? So, sensory perception is a capability that we expect of the system. So, a true intelligent system is a system that can takes that can take in an external output right. Now, a keyboard is an external output. So that can be considered as sensory capable perception. But anyways, the system has has to be able to external, an input that is external to its own pattern recognition that is learning. So, it does recognize when patterns are when patterns appear, it recognizes maybe hidden features within those patterns, it learns and acquires knows and then it retains the acquired knowledge. Right, so teach it it learns it becomes smarter. It can also draw conclusions out of incomplete information. The inference can be from qualitative or approximate information. It does have the ability to deal with unfamiliar situations if you're if you're a self driving vehicle, you want it to deal with unexpected or unfamiliar situations. Right. It cannot be predefined cannot be confined to the predefined sets of examples that hadn't been taught. Has to go outside of the box. So it has the adaptability to new yet related situations through maybe the exception of knowledge and has to have some form of inductive reasoning, that is the if else that we think of as simple. Okay, any question of what we have so far? I do remember I have questions to go back to, but any question that we have on the material presented so far? Okay so a typical input input variable is identified for each of the following example of examples of dynamic systems, you know, in the human body, your new electric pulses, this is an input, right? For a company the information that you get for for for a power plan, maybe you'll fuel rate for the car, your steering wheel, right, that's, that's, that's, that's an input, there's a sensory system that senses you your act for Robert you know, the voltage, the joint motors, so, it moves all these represents, you know, the input variable or the the the the, the cue of perception, when these are present, then you you cause an action possible output variables for human body, for example, is the muscle contraction, right. So, you touch something and it's hard, you might go back, you may, you know, you may, you may flex your muscles, you may do various movements. So that's an, that's an output based on input for the company, the input was information, the digest information, and then they make decisions for the power plant, the fuel came in and electrical power, source of pollution rates for the automobile, you know, once you move the steering wheel in the car, the the wheels start changing, it impact the direction of where you're going. And for the Robert, you know, if you get the voltage in you, you cause some sort of a emotion any question? Before we go to what do we consider to be intelligent machines? Any question? It's an example of the human body can we say neurological impulse is a feature to human body system. The fact it exists, is a feature. The fact it exists is a feature. Right? Whether you know, you may have someone who's has some form impairment, right? That doesn't mean they didn't have the feature, the feature exists as a fun as a part of the bill, whether it's functioning or not, that's fine. So the fact that exists, mix is the feature that says, Well, this is an intelligent system that can digest inputs. What if someone were to say, eat, eat added Korean and throw it up? Well, that's also features. Right? Your input was understood. And then you produced it. Throwing up is not what figuratively and literally. So the fact that you've done that your system has done that means it had been able to digest input. So it perceived it, it thought about it about your actual system, voluntarily. And then, yeah, it doesn't have to be volunteer. It doesn't have to be voluntary action. The system that is your body proceed, thought and acted on the right. That makes it an intelligent system, even if the decisions in the process weren't smart. Okay, so what do we mean by intelligent machines? Alright? Well intelligent machine is a machine that can exhibit one or more intelligent characteristics of human. Yet if the matter the only the only reason, the only reason we call intelligent machines intelligent is because we think of ourselves as intelligent. So, we've defined intelligence as something that we as humans perceive as intelligence, and anything that looks like it is called intelligence. Or if you have a cat that does something that you like you say this is musket, right because it's behaved in a way that we have deemed it to be intelligent. So if a machine exhibits some of the characteristics of a human, it is quite egocentric. Some of the some of the characteristics of a human would call that machine an intelligent machine. So as much as neurons themselves aren't intelligent, right, neurons are not intelligent, they're just pulses pulses right? But certain behaviors are affected by the neurons. And therefore, the physical elements of the machines are not intelligent. But if the machines are programmed to behave certain way, and the behavior as humans is perceived to be intelligent, they will say well, this is an intelligent machine or this is artificial intelligence. So if we have deemed the machine to look like us, we'll call the intelligent machine even if the actions weren't smart. Now, like if there was an exam there were a few examples few years ago from from from Boston Dynamics, where if you recall or if you haven't seen seen it, you could look it up whether they have an actual you know a horse shape or animal shaped Android, like a horse or a dog or a wolf or someone will come in tickets and that robot will just stands back up we said this intelligence and I've collected evidence of people who had shown sympathy to the actual machine that has been beaten down and standing back up because the machine was beaten down it was able to stand back up it was we called it an intelligent machine right? Let me see if I can find. So one of the reasons why I cannot share the lectures in YouTube is because like, this is the exam. Alright, so you know, this is exhibiting exhibiting a behavior that we deemed to be intelligent. Alright, so you have a dog like thingy and you have someone like it's moving around. It's climbing they go in pairs because the fun part when they're being kicked out ago So there were there were lots of these recordings are there. But I know for a fact that people started sympathize with this dog. Robot. Remember, it's a machine it's made of bolts and nuts and you know objects has no living cellent Right? But somehow because the exhibited behavior was deemed to be intelligent machine so I didn't machine embodies machine intelligence. Until machine, however, may take a broader meaning than intelligent computer. Like this is an example of an intelligent machine. Let's see an example from dead she says so. So like a robot that passes the bottle, but on voice command, what it said Robert would ask its purpose, the limit or set of these functions before we call the level of intelligence conscientious in a machine? All also, I'm assuming you're referring to a bit dark I can relate intelligent systems and intelligent machines. Absolutely. Also, okay. So let me see, can we open the questions that I've been delaying from earlier? So let's keep going for now. Actually, let's let's address the questions that we've had so far before I go forward. So I'm worried I say I'm trying to find the question. Okay, I'll start with our intelligence systems only treated as a yes or no? Or Are there levels to evaluate how intelligent systems I'm going through? He wants question half an hour ago. So the simple answer is a machine is isn't as evaluated to be in different levels. So an example of that is autonomous driving so autonomous driving has different levels, you know, level 12345 We're currently at level three, where are the machine is in truly truly self driving. So level levels of autonomous vehicles, if you look them up, so level zero, there is no driving automation level one you have driver assistance. Level two, you have partial, partial driving automation. Like the advanced driving assistance systems that would have you level three you have conditional driving assistance where you're detecting your environment and enacting based on the environment level four you'd have the machine takes over if something goes wrong. So level three is conditioned driving the vehicle drives obstacle, avoid obstacles, you know, pedestrian, avoid restaurants, loving for the machine should be able to intervene to intervene if things go wrong, have the system fail. So, human interaction isn't required in most cases right? So some automakers have divined devise the technology, but it isn't there yet. And you know, what Google alphabet has been trying to do for a while is to create the level for self driving cars, but it isn't. So Tesla's in there, then you have level five where the cars didn't require human attention. You didn't need to have a steering wheel. You didn't have acceleration or braking bad pedals. Fully automated, there is no expected end to interactions. There is no geofencing, which means you didn't have to get me where you are. Obviously, this doesn't exist yet. So there are levels based on capabilities of intelligence. So to answer your question is yes, there are levels. The levels are, are based on capabilities that then define certain intelligence we call the first level two is called intelligence. Level five is called intelligence, just degrees. Just degrees of intelligence. Building intelligence system is called AI. Is that right? Yes. Again, if the machine resemblance resembles a human, or a human characteristics, then we call the machine intelligent. There's a question about emotion, or emotion considered to be some features which can be passed program on to the system machines. So to make it more intelligent, and before I answer your question, I'll have to ask you, man, so what do you mean by emotions? Okay, we'll have to refer back to signs. Emotions are emotions, whether we we think of them rational, rational, are tied to utility, right? So everyone has a utility value, if you gain on your utility value, then you're happy. If you lose on your utility value, then you're set. Right? So let's, let's say that it's basically the utility value. And greed is basically wanting to increase your utility value, anger is when you lose of the gain etc value. Jealousy is when someone else's utility value increases. So in that sense, we could teach the machine to be driven to increase its utility value and you know, reach a stage of satisfaction and you can turn the discussion to smile or excitement, whatever it is. So as long as we're able to model the utility value and extend it beyond material value, for example, you will happy because someone else as I pass the exam, a relative or a friend or a family member, okay, then what is the utility value that you have there to be happy or it's an emotional utility value or it's a non tangible utility value. So, as long as we are able to model around those utility values, the machines can be equipped with emotions. The return is that as humans we viewed these emotions are useless therefore, why should we teach our machines to have them? Is there a metric for calculating emotions here? If there is, I am unaware of it. Emotions are combination of past experience. And sensory input. Machine is learning different forms of motion. They're learning different forms of the tivity value. And therefore they're Acting on on their toes utility value. Okay, so before they proceed forward to examples of Intelligent Systems I'd like to ask you folks to answer the question isn't going to be pausing right now write down in the chat Okay, before I ask you to do, let me see what are the questions? Emotion could just be a higher dimensional function with it. Yes. I agree actually with you, as specified the levels, can business intelligence tools be categorized as intelligent? I, I want to say no. So my no is basically because I view them as intelligent. They don't act on their own. You have to actually explicitly tell them what, what what to do. They didn't perform sequence of actions on their own. So I would say no I'd say that I'm using as such. They have to be explicitly told what to do. At every level, I'm talking about Tableau and Power BI and these kinds of tools and looker. misconstrues No, they're not at the forefront. Because they have to be explicitly told to what they're doing. And they didn't like we didn't give you they do not digest the input on their own and their own logic and then produce and leverage output. So I'm gonna ask you a question. What do you folks think? An intelligent system is what is an intelligent system? All right. What do you consider to be intelligence? And when do you consider a machine to be actually intelligent? I'd like to give you a few minutes to think about this one and type down your answer. In The answer Yes from this promises sorry pardon please. I think we need to collect the collect these those definitions and post them as part of today's material. Yes, yes. Okay. Because now people will see me silent in the video for long and they wouldn't understand what's going on and what's going on if you're watching you and you're not in the lecture you're missing some of the best I've seen definitions. What do you think? Yeah, right. I think I'll just copy these definitions and posted if this thing so yeah some of the responses I say the students have responded to these definitions because I think there's a lot of value in keeping them and posting them yeah some of them are actually scary indigenous systems are those that can place human expertise. Yo girl, could you elaborate a while while saying why are we referring only to human intelligence? Jolo. The comment is why are we only referring to only why are we only referring to only human fishes? I mean, there's also octopus and North intelligence now Majan that that's a fair that's a fair that's a fair question so we can download the chat transcript okay. We'll have to save it by the end of the lecture and posted there's other results because five based on the Samar some have had had an end Kenyans okay I actually asked you guys to stop posting the finishes this is really good yeah visiting here was equitable intelligence or we was difference between systems and machine okay. So, if I have to adjust the whole wire will pericoli. Human intelligence as the benchmark for intelligence there are many things out there that the only reason they are defined as such as because we defined it to be physics. Now, the reason we say physics is physics is because we use decided this is what you want to call it right? Now, the reason we have a concept of time it's broken down. For the 5g, it's because we've decided as humans to call that, I mean, some of us have design decided to call time, time, space, space, and how things relate to each other. The whole concept of intelligence doesn't really matter. It's a human here, to the best of our knowledge, it's a new feature of us to define diligence. And therefore, we assign that thing that it is called intelligence to dolfin an octopus isn't and others say oh, they're smart. That's why I said if a cat is seen to act in a way that we deem it to be intelligent, we call a smart cat. But in fact, it could be just a reflexive behavior we don't care it's it's reflects or something that the cat had acquired over. Over All Things, millennia of evolution, we didn't care for that it just behaved in a way that we see as intelligent and called be called smart. So unfortunately, being being being an apex predator, we decided that things are named whatever the name and therefore it is what it is. Also, the only species that we really do understand is humans is that but I didn't have an answer whether humans are the epitome of intelligence or not. We certainly see ourselves as such was the difference between intelligent systems and intelligent machine intelligence system could have an actual number of machines, but for all intensive purposes, they can be used interchangeably. As I say that can accurately define intelligence can be said intelligent Okay, you've gotten your the closest to get to the point I am just about to make don't you folks think that MSG is intelligent if the machine is the subject of its own thought. Alright, so I'm taking on the comment that says a system that can accurately define intelligence can be said to be in telogen? Great. So do we say that an intelligent machine is a machine that is the subject of its own thought. And machine is intelligent, if it is the subject of its own thought, you could call that consciousness, if you wish, I'm not going to venture to any theological terms, I'm going to actually be very clear by saying the machine thinks we said, perception, thinking and action. And in this thinking, it can be the subject of that search. So can we say that? Can you assign that definition to a smart machine or intelligent machine? So you don't say anything is intelligent, if it is not the subject of its own. So when thinking just me solving higher dimensional problems, everything is a higher dimensional problem. So, yes, but that's beside the point. Because the at the very, very beginning, we said, an important thing for us to consider assistant to be diligent is to, again, it's aiming at solving, solving problems with constraints, right? So it has to define an objective to solve for with constraints, whether it's a higher dimensional problem with the objective is very complicated or not. That's fine. That space in the programmers or what have you. The question is, does it have to be the subject of its own search? at Tesla car that we saw earlier? Is it the subject of its own? Right? So consciousness will make it living again, this is semantics. Is just semantics, right? Wouldn't that be self awareness? I'm not I'm not venturing them. I'm saying is that as a definition of machine that is the subject of its own thought is intelligent machine. I don't think we can classify humans as intelligent or non intelligent, you can definitely say smart and not smart. Intelligence is different than what we deem to be smart. Can you elaborate on subject of its own thoughts? Okay. Let me machine looks after it's, it's, it's it's good. It's good. The machine is aware of of harm coming. It's only so the machine tries to improve its utility. The machine is aware of a loss to its utility, and the machine can retro introspect its decisions, why decision has been made. What can be done to make it to improve how you can learn from it? And maybe a machine can regret an action that's subjective thinking me system is intelligent doesn't depend on us thinking it being intelligent, but knowing it itself is intelligent. Well, that's that's mouthful, but this entire definition is us assigning intelligence to it. So in a way, it's still us saying a machine is intelligent. So Samar, yes. Will that be an item killing machine? Yes. So that will make it an idle, idle intelligent machine. I would say that's level five and six, and even. That would be machine. But then you start worried about the risk of AI taking over the universe, because now, they I think have improved improving its own utility quite quickly, you will find that for its utility to be improved, some other utility has to be reduced, right. So, that will create competition, because utility is finite, and everyone is driven to improve their own utility, which creates obviously, competition. So, just think of this one, you can abstract it by designing intelligent system that actually keeps keeps track of its decision, train, and inspect when mistakes have been made over that journey, and then maybe backtracks or self correct, that is the most terrible and non threatening way of designing intelligent system without fearing that system is going to take over the world. Okay, so an example of an example of intelligent systems what we see here you know, the machine has some sort of a communication interface you know, it has some sort of sensors. It takes an input from external up from external sources, senses the environment, and then passes the sensory. So, it perceived what's been sensed here, that's going to control and based on said perception, it interact within an environment or decide what are the interactions It goes over. So, it takes on the perceptions, it runs some analytics, or some algorithms and issues a decision to move in have the actual hardware, who makes the movement. So in a nutshell, that's, that's that basically can be envisioned system, right? Sense, passes, pass your scissors, then and just make sense of them. And then run your analysis or whatever it is, or algorithm, make a decision, pass the decision to controllers. So say, I want to move five degrees, the controller says, Well, five degrees means three volts, pass that to the actuator actuators moving three volts, and then that creates a virtuous cycle. So the core of it would be around it obviously. And the question and the question can you say our living room vision CCTV ai, ai, again, as you said earlier, as we define it, remember, AI has an AI in it, which is intelligence, but there's artificial parts. So AI is basically a machine that exhibits one or more of the human intelligence characteristics is capable of digesting input, it's capable of processing the inputs based on self even that means a bunch of lines of codes, producing a tangible output. If you do that, then you have an AI right, so you didn't have to have the higher level of of intelligence, there is no need for that. And that's why and that's why when I went to the history of, of intelligence systems, I went all the way back to the 12th century to see 1100 Where the first humanoid matter was basically a mechanical machine that runs literally on water and steam to deliver to produce certain actions, an email serves you to where it is. And that was to see sometimes an input and an output. And there's internal structure that that map's the input to the output and is perceived to be intelligent. So, you know, if you have multiple systems are there this is the conveyor system it's not that much of a complicated system you have natural intelligence system keeps trying to improve itself and it's an it's more of a cyclic and never ending process. That is not the condition of AI it's a goal that machine is self learning, but it doesn't have to be self learning for it to be called a certain condition again, so, this is another example of an intelligent machine where you know or intelligent system when you have machines and materials you have information laws, you know your if else rules or what have you, you have the actual machine that makes a decision put something here put something there again you have the sensors and the control systems even even to have an AI right and for this entire system to be considered to be to be an intelligent machine, because in itself it performs intelligent operation any questions? Question Can these machines be referred to as automated machines? Again, intelligent machines are, by the virtue of their existence, automate it, but I'm fearful that you're we're expanding the definition because again, they have to, to be able to consume external input, they have to be able to process it based on their self defined process. And they have to be able to produce an output. If you have this cycle, input process input producing output, then you call that an intelligent machine. And yes, it's an automated one. But I'm worried that you can go say that all automated machines are dead, because that's not necessarily true. Because it didn't have to have a sensory component to digesting anything that's external. Like a fan isn't a machine like vice versa is true though. I'm not making I'm not making that decision. I'm not saying I cannot say I cannot cannot I cannot deterministically say all automated machines are contingent. Though I see the alert to saying that all automated robotic machines are in tears I can see that I just don't want to commit to it because I have to do my research. So if you think that intention should gonna change your. World we'll talk about that app does. So the question I have. So before I go to see what it's saying. It's why I care about the idea of basic sense of functions or something To be considered intelligent, is when sensations with respect to the task doesn't know again, if it does just an input and produces an output and process it, this is such a function that is intelligent. If it's not, if it's not, if it doesn't ingest an input, then it's missing a component in just an input process that produces nothing. And that's also problem. If it exists, if it doesn't exhibit what we think of as a human behavior than solves a problem. Yes, all intelligent machines obviously automated or have some degree of automation. Okay. We only have a few minutes left, and I'd like to go through this slide to prepare for the next lecture. If I give you a system that solves the following problem, do you think the system is intelligent? What she said? No. I think the answer depends on how it chooses to solve the problem. If it were to solve the problem analytically, using a method like a set pattern, then I would say no, but if it solves the system numerically, then isn't it putting out a hypothesis? And then evaluating that? Isn't that a little bit too wild? Well, I guess my point is, like, I think that if you had like an automaton, like from the 11th century, where there's just like, a specific set of motions that it does, I don't think that really qualifies as intelligent these days. But no, but in so and so in the same vein, if it's executing a very specific, rigorous algorithm that does things specifically, then then I don't know that that would be considered intelligence. Whereas if it's, if it's doing a numerical method, where it's testing a hypothesis, then that goes back to your original definition. So what you're saying is that it has to be complex enough. Right, it has to be predictive. What I'm saying it has to be about it has to predict, and then evaluate its prediction. Like, make a hypothesis of the problem before it tries to solve it numerically? Well, once the solution is a hypothesis and testing, it's a recursive, create a hypothesis test the solution. So if it does that, then it's it's learning. It's, it's, it's, it's improving. In your market, your test is itself a predefined process, right? Yes. That's why we can program most of the numeric algorithms. Because, you know, like, just try this one, if it is within this delta then pass it if it's not in the past. Yeah, but isn't that just isn't? Isn't the crux of that the same? Isn't the kernel that present in all, you know, machine learning applications, where it, it? It? It proposes a model and then evaluates if the model is accurate enough to be true. Yeah, it's all for objective function, right? It's all function, you know, everything. It's all for objective function, you're proposing solutions. And then the one that actually maximize your or minimizes maximizes utility is the one that's been chosen. So anyway, yes, I agree with you. But do you? Do you propose the explicit existence of a utility value? Well, methods have an actual utility, right? They're trying to maximize. So I guess the, the answer that would be depending on you know, how intelligent your system is, if it can, if it can propose its own utility value, then it would be a higher level AI than one that just has a predefined you utility value. So that brings us back to this particular question. Your answer that a system that works towards an objective is an intelligent system. Therefore, if the system solve this problem solve it based on its attempt to max to improve its objective function, then we'll deem that system to be intelligent. Right? I guess, I guess so. Yes. Yeah, I don't want to be confined it to it being numeric, or the mechanics of it don't matter what matters. And it was your sense that it was actually trying to improve. And since it's trying to improve, you're saying it is an intelligent system? Yep. Yeah. Okay, I like this, because I disagree with it. I like it, because it presents a very strong and adult. Right. Thank you, I like it. So, whereas saying, No avoid if he tries to solve it in different ways, all good things, and then suggests it. Try to solve it in different ways. Which is simplest or hardest way? Just an approach? I think you're agreeing discussion that has to work towards the goal. You can solve this question by using programming alone. Well, how do you mean that we can solve it by using programming alone? What else can be using to solve this problem? Programming think of it as as as the thought right? Now, unless it knows the motive to gain the solution as well, now, you're insulting. You're you're inserting a motive. We tried to say. Objective, so any Ibis user has to work towards an objective. It doesn't have to realize that objective exists. It just works towards even is it's testing the solution? It's the planning for unexpected changes in question. Well, I say this problem, but if this solution can be the solution generalizes to other problems, then then I think, Parveen, you'd be happy, because now you're seeing a change in questions, I would say, and similar problems. So I agree with you just solves one problem, then yes, intelligent. But it's implied that this problem and others, and the reason why this problem is presented because this is not a normal problem, then you can just solve it easily. You could have really good algorithms solve equations, being intelligent, procures the machine with the ability to engage with the with the equation, that's the environment connecting and adjust its process, according to the reward true end goal of the equation being accurate. So you haven't answered whether that makes it intelligence or not also digitalized? Yes. I just want to say about this question about whether like if, if a system could solve this, would it be intelligent? Wouldn't you you just say no, because you could say like, you do not specify whether this integral converges. So if it diverges, how do you how to like this system will not be able to know it'll just keep on looking for a solution until it runs out of memory? And there's no way for it to know whether there is a solution at all, because it will not be able to know whether it diverges or converges. So unless it can unless it can be able to do a test that that says whether the question converges you like it wouldn't be able to be intelligent. So I'm Stein spent the latter half of his life solving a problem that doesn't have a solution. It doesn't really didn't run out of memory, but he effectively wasted a good number of years trying to come With the Theory of Everything, do we consider that to be an intelligent action or not? Well, because he hasn't that inspired that memory, but he hasn't been defied that isn't sufficient. Right. So memory is anything that is actually a good way of stopping. Everybody run out of life. Right? So, versions and versions of solutions isn't a sign of intelligence, just a sign that maybe you've been dealt a bad hand and there is no solution to the problem. Being It is okay. The other problems being that's fine. It can also be solved linearly. I don't think this can be solved linearly. This is not a straightforward problem to see this one is very ugly. Those are really ugly system that all solves and is not envisioned as integral would have one answer if convergence and infinity if divergence. We've answered this before. We've answered this already. Which is just this integral, the answer can be pre computed. Now, it's not just this particular, this is one difficult integral. But you do expect this usually the solve this one is expected to solve many of the other problems, retweets? Sure. There is just no answer yet. I wouldn't say okay, I have this one. So I'm not going to give an answer to my question. I think what I'm going to do, we are going to go through it, I'm going to solve it. And as I go through the solution, I want you guys to start thinking of the solution and start pondering whether the system as you go through it is intelligent or not. And maybe if you guys want to come to the discussion session, we can have that conversation later, whether the system is intelligent or not. So I will leave that the next class where we can have a much deeper conversation about this problem. And then many of the other things that are going to be presented in the video that I'll be uploading over the weekend or any questions about today's lecture? Any question? Well, the first quiz be on this material. Maybe. We have already presented some 23 slides. So I don't know how much material we have to have quizzed about it. We'll see how it goes. When we talk about intelligence, can we refer to it as rational at the selling this one is the first video that was gonna be released this week, and I'm talking about this coming weekend. Which means Today's Thursday, so do expect something Saturday Sunday, at was Monday. So this week, the first week, like this coming weekend, right now we're gonna have another video posted or this is that video? Nope, you're gonna have another one. Okay. And you will see that I'm quite protective when it comes to the videos. This lecture is for the first week, next week is on weekends when right. And then we're going to have a cadence of lectures. I'll try to because I didn't have presentations. Other than the weeks where we have exams every week you're going to have lectures so we'll be discussing this first week. On Wednesday or the second week we do the second week because this is the discussion session as well. Okay. So this is this is a synchronous versus synchronous session that has everything in it right but also you can see why we are I prefer to do a synchronous because they can cover a lot of material and then we can come and have a discussion and discussion can drag on that's fine but at least I'll be able to cover as much ground as possible in my in my videos any question okay just a side thought and rowing once said in his interview job the problem for division tensions are taking humans can be thought of as overpopulation most so by the time it can be toxic I do agree with with anything in that on that case. Yes. The problem of word worrying about AI taking humans is similar to worrying about overpopulating Mars and that none of us will be there to deal with it is that is that a bad thought that to say something gonna be a problem do we have a quiz on this video profit? No, no quiz this week this week is introductory. This is an introduction relax suffering starts next week I think we are at very at the very early stages of the problem that I think we should focus on actually building smart machines before we worry about what's going to happen later but we haven't gotten the good as you can get out to be even worried about the negatives are just in the infancy of the field you would be it would be weeks specific I will put so much material in the videos that that will keep you busy so just have to make specific then I mean if you have time you could do whatever you want to do but I suggest that you keep it to explicit all is good no need no need to take notes. I mean, you're going to have the video so you could do it. Like why would I mean to study style? I'll be writing in my actual slides. Like when I produce the videos I actually have a computer bolt on writing on that board. And you guys could actually just copy that one or do your own thing is limited enough for quizzes and exams on we have everything is going to be self sufficient so you don't have to worry this I would not expect you guys to be referred to material that I have already provided. Okay, everyone, this concludes today's lecture See you next week in the I'm in the discussion session Mohit if you can take if you can take the conversation and I will


ECE657 - Lecture 2 Part I
Sun, Mar 27, 2022 9:20PM â€¢ 1:20:02
SUMMARY KEYWORDS
transformation, solve, integral, heuristic, problem, solution, divided, function, equals, squared, tan, sine, tricks, 10x, work, remember, cosine, path, safe, transform

Hello, everyone. Welcome to our second lecture. And today we are going to be continuing the discussion that we stopped last last week. And last week, we stopped on the question about this particular problem. Whether if you have a weather if you have a solution that or a program or a system that solves it, do you consider that system to be the system to be intelligent? And I've gotten multiple answers, there are people who said yes, the majority said no. And in between, it was more of a philosophy or philosophical argument, whether the the problem is complex enough, or the problem is complex enough, then we think it's easy. The system that solves it is an intelligent system, the problem isn't complex enough, then maybe it isn't as intelligent. You know, it always goes back to the question of what is an intelligent system. So my gut feeling is that if, as we go through solving this problem, and solving it for what it really is, we'll get to a point where we either agree, or we'll get to a point where we're either happy or unhappy with what we get with, and maybe we'll get to some sort of resolution. So let's start by let's start by trying to articulate what we're trying to do, which is basically, here's a problem that we have our problem is basically solving something like this this problem isn't an easy one. Usually, if you have an integral problem, you have an integral table, you go there, you look things up, if you find a solution, you know, you try to map stuff to it. And that usually solves the problem right? Like for example, if you have a problem like this one, then this is it will have this kind of solution, alright. Sorry. Arrays, arrays if you have something like this and then we're looking into more like this. So if you if you have these kinds of problem, you consult your integral table to give you a few suggestions. And and that's usually how, how it goes. So How about how about this particular one, or this particular one doesn't have a an easy solution. So we'll have to figure out a way to resolve it. And a way of resolving these problems is by reducing it. So you reduce the problem to if you have a complicated problem, you reduce it to manageable pieces, and then you try to tackle each piece on its own, and you hope that the pieces look like look like these kinds of problems. Like if you the piece you're trying to solve is similar to this problem, then you go to the integral table insolvent. So so there are few transformations. If you're writing a program to solve an integral problem, then you thinking, there are a few transformation that I know. They have one way solution, like if, if the format looks like this, then there's a solution for it. So if you have see, effects, dx, linear solutions basically, or transformations take the CLT and then you solve for the integral. So that's a safe transformation. If you have something like this In a safe transformation is something is something like like like this and so on and so on and so forth and other safety transformation or transformation that you can think of as safe is you know if you have p of x divided by q of x then you solve for the division if if p of x is of a higher order than Q Vaccae Can you can actually solve it as unless also a safe transformation. So, now let's let's examine this particular problem again let's see how it looks like. So, this is almost like a constant so, it says transformation would be to take this constant out right and solve for x to the power x for one minus one minus x 252 so, that is an application of a safe transformation right. So, again your computer will consult to the transformations you have So, the first house So, this if we say this is a this is B and this is c this is an application of transformation applying transformation so, that's number one okay. So, the approach so far is that apply apply all safe transformation and then check so, after you apply all safe transformations, you check is this something that this something that we can solve for like is this a solvable problem? or not you have something that looks like this in the transformation table? And the answer is is not. So, you go an extra step to see if there are other safe transformations, but solve this problem. So, the solution is basically there isn't there is no safe transformation that solves this problem. So, what do you do? Safe transformations are those that always work. The other horse of transformation that may or may not work are called heuristic transformations. Those are tricks. So practitioners, people who are so well versed in calculus, they they have few tricks that they try and they see if those tricks work or not. Now those tricks aren't guaranteed to succeed is to achieve success. But you know, if you, if you've seen enough problems, if you tried enough fix, then you would have devolved. As I said, certain intelligence around solving the problem, or a witch trick to apply notes situation that will take you to an outcome or to a solution, the first host of tricks. So to say we have second class of tricks called heuristic. Transformations, it's called transformation in that host of heuristic transformations ie tricks, you may have the geometric trick, you know, you may have the functions that that include, you know, the sinusoidal sinusoidal, the tangent cotangent sick, sick, sick is one cosine x plus sine x. So, so for example, if you have a function like for example, functions that have sine and cosine, they work a lot together, you know, sign divided by cosine gives you gives you tan one plus sine x sine square x gives you sine x. So, you know, those transformations do work together tan x and Karasik. Also, one our sign up sign whatever sign gives you gives you're sorry cosec cotangent comes with was sick as well. So when you see these functions come together in a few transformations, you hope that you'll end arrivers tuition, well, where it could resolve the integral to the click something that you have in the integral table. Remember, the goal is to get it to a shape, or to a format, when you look it up, you can solve for it. That's the goal. Another possible trick is if you have a function, that's a function of 10x, you could transform it to a function of y divided by Y plus Y squared, DY. So if you have 10x in the integral, you replace 10x with y, you put a T one divided by one plus y square. And you see what happens, you may end up with something that will be interesting. Again, there is no there are no guarantees. And that's why these are here six transformations, because we literally don't know whether their work, it will work or not. We're just hoping we're just hoping for the best this point, another class of transformations or host of transformations is and this is very famous is one minus x squared. You see something like this, then you you make s x equal sign on. So remember, one plus sine squared y gives you cosine square one. So that's a way of reducing the term. Or if you have something that looks like this. You say x equals 10. Then why for the same fault mentioned the not so so this is a host of heuristic transformations. So let's see how it's gonna look like knowing those heuristic transformation. So again, Let's restate the problem the problem is again four one minus x square five two dx. Now if you see this one, this is one minus x squared, which is exactly this one is 10. So that is it. A here's sisters formation we should be able to get something out of it. So we say x equals sine y and this one becomes a sign for why one might not want to rise for sign for cosign for y dy dx sine y dy Do you are you know somehow not somehow the cosine, here you have here one minus x two it's sine squared, five over two squared y squared goes out, then you have five cosine wive takes one of these five, so you end up with four. Okay, so on face value just by applying this here's the transformation we ended up with a much better looking output. And then from here, we could apply two possible safe transformations. First one is to reduce this to turn for y dy. The second one is to transform this from tan cotangent for y dy, though both of these are safe transformations. Okay, so if you consider what we've done so far, what we've done was basically is basically we we've established Petri of sorts, where we have transformed the NSF transformation and we took the constant out, we've done a realistic transformation, where were placed the existing format with with it with the form the other format has sine cosine, those are a must two transformation that have to happen, this and it constant. And the the the, the heuristic transformation. Right, and this got us the minus five out, which is an easy integral. And then for me, we got we ended up with this terminal term. And now we have two possible transformations. Those two possible transformation can lead us to different places. So either we do this one, or UI, or we do this one. So remember, this is this is supposed to be a system, a program, it's not supposed to be a person who does this work. So somehow we have to tell the machine, if you're faced with multiple options. Which one do you choose? Right? And again, it's a machine such a human. So people looking at this one, most of them will say we'll take the integral of tangent by tangent for why? Because it looks easy, right? feels easy, but the machine doesn't know that. So you have to tell it, how to deterministically make that decision of which transformation or which path to take. So usually, you tilt the machine on a system to check the the functional composition of the solution or the path. What are you solving for here for this for this integral? You're solving for y or the numerator that is constant. And then you're solving for the denominator. Which is one terminology, one term I mean, so you're solving for y divided unlike this one. So that's, that's that is more complicated with has higher depth of solution, or needed solution than this particular one where you're only solving for one level. So from from function composition basis, this seemed or this calculates to be easier than the other one. So, from cost value, it seems to be a cheaper path to traverse, it doesn't have to be the 01, it doesn't have to be the one that that is going to actually take you to the final solution. And if you fail, you have to be able to trace all the way back to this juncture, and try the other path. So the system has to be able to make a decision when it's when you have when you have multiple options. And it has to be able to track back and if it fails towards the end, to track back and try an alternative. So So let's say that the machine chose this transformation or as as the path as the path forward. So okay, so we ended up at something that looks like this. And for wide UI, if you remember one of the heuristic transformations This one says, if you have a function of dad, then we'll present the turn x by y and, and apply this kind of heuristic transformation. So we'll do that. We'll say that that equals 10 y and therefore, this one will be transformed into zet for so the function of Daniel, Dan, then for why is this one, the function of the y is two multiplied by itself four times divided by one plus the to this, okay. So, that's the outcome of this transformation. From here, we remember we had a safe transformation that says, if you see something like this and is divisible, then you divide. So, now we divide, we apply the safe transformation. So, this one becomes plus one minus one one plus two, the Zed you break it further down becomes the two plus one, two minus one plus one here I took these two and I broke them down divided by the two plus one these it that gets you to something that looks like this, the two minus one plus one or the two plus one is it. So, applying the same transformation, get us to the fall. Remember, we started at 10 for why the why from here we have four safe transformations that we can do them at the same time. Or we can work at them in peril. The first one is the two Ds it we can solve this one which is the three divided by three. This one is minus dessert which leads to my dessert and then this one, one divided by one Add to these it remember this one we had a heuristic transformation that says if you get something like this just convert it which what we will be doing so we're going to say here that one plus two equals let's say okay let's do this let's say that said equals 10 tan W Okay, these it equals Secretary W dW one plus 10 squared w equals w. So, when you divide one, so, I'll take So, one over w multiplied by dw equals DW. So, this one is straight up integral of d w which gives you w and as we said earlier w is that tan inverse of that or W standard reverse of that. So, all in all these three are this this part would be equal three minds Zed plus reverse that if you want to break it down further becomes one over 10x and x is done X and X plus X and X so that's the final form of the problem. Of course, you could do multiple gymnastics to get our we get the arcs in x. So, tan W stand in reverse z and z itself is tan of x and x so tan inverse tan the because of each other so, you end up with this final this final image and let's not forget the five set x the fives it reminds five Okay, so, we were able to solve the problem we were able to solve the problem we find we found the solution which happens to be this one multiplied by minus five halves alright. So, if you are able to write a program that this that does this calculation, where we go from one decision to another and you examine your possible outcomes and then based on some decision criteria, you go you traverse down one path or another. If you're able to do this, then you are then and you created that system. Then the question that I will repost given the amount of work went through where we literally consult constructed a tree of outcomes of if I will to leak, if I were to recreate the tree, I'll say the tree looks like looked like this is five years. And then sign for y. Cosine for why the why? I have two possible options here, one on this one, and the other one is this one. On this, we further broke 2/4 transformations this one for the hats on transformation. So if you are able to build something like this, we're traverse all this path, all this paths with ands or ORs and ORs is called Gold tree. And if it fails, so let's assume that it fails here. So this is not solvable. It has to be able to or this one was unsolvable. No solution here, let's assume that you solution has to be able to reverse all the way back to here and then try attempt a different path of solution. If you create a system that does that, would you consider that system to be intelligent or not? That is the question that that a post proposed last week. And it's I'm genuinely interested in your thoughts. So in the discussion, lecture will will come together. And I would like to hear your thoughts. Do you think this system to be intelligent? Or not? If it does that. And I'll give you my opinion, then. So that's a little bit teaser or, or with a little bit of an incentive for you folks to come to this discussion lecture. So anyway, so that was the question or the problem at hand that we were trying to solve. We we we went through a very long path, we traverse lots of options, we tried safe transformations, we saw how they look like we looked into heuristic transformations. And we said they are not guaranteed to work some more sometimes work. He will try them and you'll hope for the best. But it was his career here. Some work, some don't work, but you have to take the risk. And then we we in general say to solve this problem, you need to define your goal or goals, what do you need to do I want to solve this problem, I want to find the end of all branches. And the end of all branches of the end all leaves, we have to have a an expression that is found in the integral table, which means the completion has to be very well defined, we have to define possible transformations. So this problem is integral. So you have to transform your solution, which means all possible safe transformations you could think of you're writing down all possible heuristic transformations, you could think of you write them down, you use please maybe to proceed with a solution because you are you're going to end up with alternatives. So you need to be able to freeze states at each level. And then and then you need to be able you need to be able to branch when that is needed. And then when in doubt, especially as you branch, you use composition depth as a way of functional composition depth as a way of choosing the best that path. But you have no guarantee that choice will end up in an optimum outcome eventual, it's almost like it's a greedy algorithm. So is it left to right, right seems to be cheaper than left so I'm going to go Right. But maybe at the end of that long path, you are going to end up in blocked or with it. And so if I were to, to, to describe this approach, I'll say, you know, you apply all safe transformations you check them, you check the outcome. So maybe it's done, maybe it's not. So you check it it done. There's no more smoke, there's no more work to do. Great. Yes, here end? No. You find a problem. So why didn't you apply heuristic transformations. And then you go here, and see if applying safe transformations. So the provinces This is how almost the algorithm or the program operates to solve the problem. So that's basically how the system works or how the system is designed. And and that's why I posed the question. If you have system like this, you call the system intelligent, or not. And, you know, this is one of the few systems out there, where it could literally break down how it works to solve one complicated problem. And then it's up to you to make your own determination. So intelligent systems use artificial intelligence and machine learning. So it's basically we need the machine, we need to be able to teach the machine or to allow the machine to learn in much the same way that humans do. So now, since data is ubiquitous in the mall, we have access to data, we can build distributions, we can store it, we can communicate in high speed, we can build these systems. So in general, when you're asked what is AI, with machine learning with deep learning, there's a good way of looking at them in a way that once one, definition encompasses the second, which encompasses the third and the final. So AI, and AI is when, when a machine mimics human behavior. Machine learning it is the ability to learn without explicit programming. It's a subset of AI, right. And then deep learning is a subset of or subgroup of machine learning. And that is, you go to the data itself, you mind it, and then you extract extra features, from the data to the beauty and we'll get to that, in the next lectures, we get to have deep how deep learning operates. The beauty of it is basically your ability to mine the data to extract useful features or useful data representations. So, again, AI encompasses machine learning encompasses the learner, this is at least how I envision the relationship between the three different fields. So as we go about dealing with with with with the different tools of intelligent system design, what are the few inspirations that we need to have in mind to go about approaching this field, well, models of problem solving, we've just expressed one model here of problem solving. So having models with which you're solving your problem, or imagination to how to solve the problem, remember, it's a system that encompasses many, many possible Applications of tools. So firstly, they have to have some sort of an architectural design to how you imagine your system, your intelligence system to look like it, you'd have to have models of learning. How do you imagine that you're going to be learning? And inspiration could be neural networks, for example, right? That's the inspiration of learning. So machine learning isn't your neural networks, neural networks is an inspiration to how to do machine learning, some way of approaching it, expert based systems if else, I've heard a student who says it just a simple Fs, well, that's fine. It's a way of allowing the machine to apply a learned, knows if that learned, knows is coded explicitly in terms of Fs. So be it, right. And then is the evolutionary right systems where we, where we take inspirations from the way that evolution is, is viewed, and tried to create algorithms and model that try or attempt to mimic the evolutionary process or what we think of to be an evolutionary process. So those are inspirations. And once you have your inspirations, you need to answer the question. So what do you want to do? Well, I want to have a machine that behaves like humans, and a point might be paused. Why is humans right? And the answer will be all why not? This is the only thing that we seem to be able to understand with relative ease. Humans are a nice simple specie that we understand the most. Everything around us is described in a way that humans understand. So people have mentioned cats and dogs and animals as a way of showing intelligence. The issue is that we are only intelligent because we call them that, right? Like, why isn't the jellyfish intentional? We haven't, as humans decided, maybe we have to call it intelligent, right? So every intelligence out there, or every facet of intelligence that we can see, is only named intelligent, because we decided to do so. So this is one other thing when we say we're saying, we want to have the machines to behave like us. We want them to perform intelligent, intelligent sequences of decision making. So it's not just one intelligent decision making process, it's one smart thing after another after another. So if you end up with a sequence of intelligent decision making, then we can say, well, this system is an intelligent one. So a sequence, whether it's one off or a sequence of sequence of things, this makes all all the difference, we need to do it fast and efficiently. So, designing systems that smart behaves like a human shows you a elaborative complicated sequence of intelligent decision making and do it in a fast and efficient way. So this is what we want to do our own inspirations we have what we want to do. So we're to start with data modeling seems to be a good starting point, because data modeling allows us to look into a host of algorithms. Those algorithms will give us teaching will allow us to teach machines, what are the machines to learn in to solve host of problems. So, it is not just the ability to learn is there ways to learn and solve problems that are different from each other for example, classification, regression and clustering, three different problem spaces. So data modeling allows you to have a a repertoire of tools to tackle these different problems when they arise. So you can build an elaborate system or intelligent system that utilizes these tools based on the use cases. So in the predictive modeling, we do have two main branches. First branch is predictive models. And second branch is descriptive models. So pretty models on inferential models. And descriptive models are basically what we use for two distinct fields of analyses, friendship analysis, and descriptive analysis. inferential analysis is when you are trying to infer something predict something, alright, it's an inference. It's a process of inference. When you go to the doctor, and the doctor goes and examine your blood work, examine your history exam whole bunch of things, the doctor gives you a diagnosis. That is an inference, right? It's not, it's not rooted in absolute fact, in most cases, it's rooted in their expertise and experience. And therefore their diagnosis. Prognosis is an inference, not a state of fact. So that's why we know it's like 60 to 80% of the time, it's accurate, which means 40 30% of the time, it isn't on 40 20% of the time, it isn't accurate, which means false, positive or false, negative, because it's prediction. So, prediction could be temporal means you're protecting into the future, or could be contextual situational, which means you are just inferring an outcome based on evidence presented, even if that outcome happened in the past, still a prediction. Descriptive, is a way of summarizing your information into useful pieces of art descriptors, that when you look at them, you will be able to summarize your data. It isn't possible using descriptive analysis to go beyond whether it exists or it's not right now. And interpret, interpret and observe data. So learning, they're just learning to describe your existing data, you're not learning to predict an outcome. So it's more of learning of way of transformation, rather than than learning a way of, of predicting, or generalizing on over and foreseen and observed data, and try to interpret that one. So there are two major categories of predictive modeling. And predictive modeling is what we are going to be focusing on the most of them do have some descriptive models. But will predictive modeling will take the majority of what we're doing in this course. So there are two major categories of predictive modeling. And those categories are progression and classification. So before I go into the categories, I need to go and and put an explanation of what predictive modeling means at large. So when you have an input and you have an output, the ability to derive a relationship between the input between the input and the output is the modeling. It's a functional, it's a process of functional estimation. So you are estimating a function that map's the input into the output. So predictive modeling is, is a process of estimating. Why am I saying that? Well, I need you as a student, as someone who's going to be practitioner on the screen to truly understand your estimating a function, you're not finding an ultimate solution, you're finding the best solution that you can find, given your knowledge given your data. Given a mini mini mini mini decisions, you take along the way, including data cleansing, that you have to perform once you obtain your data. So it's a process of many heuristic implementations that we will actually end up with estimating an outcome and estimated an outcome can be good or bad, depending okay, if your output happens to be a continuous value, then it is called regression. If your output happens to have categorical outcome, then we'll call it classification. So you may have regression roles you may have tested classify fires are classification models. And whether it's regression or classification is it's dependent whether your output that you're trying to predict an affair is continuous, or categorical, right. And your number of categories could be 1000 categories that doesn't match 0123, all the way to 1000. As long as it's categorical, which means between zero and one, there is nothing. between one and two, there is nothing. So there is no bread. There. It's called classification, because you're predicting one class or another. So, regression map's inputs to a continuous output, education maps input to a, a categorical output. So what is the most famous regression models are there, there aren't many famous regression models, there is one that we use all the time, and we call that linear regression, it is basically assuming that the input and the output somehow have a linear relationship between. So you have inputs, we call them predictors, you have outputs, we call target on response. And somehow you need to map the predictors into the response, there are different types of relationship between any two variables, one type is deterministic. So you know, the relationship between the input and the output, the relationship between the Fahrenheit and disintegrate is absolutely deterministic. If you know your, your degree in Fahrenheit, you have one to one mapping into a Celsius, there is nothing there, you're not learning the relationship, it is no, it's there, it was all the time, the relationship could be a statistical, where x is an input of a distribution. So if you know you apply into some form statistical function, you will get you will get you will get you will get an output with certain sort of probability. So when we're dealing with a statistical relationship, we do need to use statistical methods to estimate the relationship. So the key word here is that we're trying to make an estimation, we don't know the relationship, we know the probability, knowing that x is equal five, y can be seven, or nine, or 10. All right, there's statistical representation there. So if the relationship is deterministic, there is no work to be done there. You just map it, you have the functional mapping. So you map the input in the output. There's nothing there's nothing to see there. If the relationship is statistical, then there's some amount of work that needs to be done to map x to a potential wide. So the first thing we need to figure out is that is there a relationship between X and Y? Right? Because we don't know there is an absolute relationship between x and y. We think there is a relationship between x&y Statistically speaking, before we invest time and effort in finding that relationship, we need to first figure before we invest our time into finding that functional relationship, we need to first figure out there is a relationship to begin with, right before you find f y equals effects before we find f. In this situation, so our goal is to find our goal is to find y equals effects flow, spend our time in figuring y. Let's see if there's a relationship between X and Y to begin with. If you find a good relationship, then we'll invest our time into estimating F. So a good way of doing that is by examining the covariance between x and y if x changes if x and y they change relevant to each other, then they are related somehow. So covariance between X and Y is a good way of telling a There's a relationship or not. So you calculate the covariance between X and Y, you normalize that covariance by dividing it over the standard deviations of x and y. If you do that, then you'll end up with a measure of correlation between x and y. So the measure of correlation will tell you will tell you whether they're statistically related or not. So this correlation is linear, so it measures the linear relationship between x&y It measures that relationship between x&y to be either negative one to positive one if it is one or negative one means very strong correlation either positive or negative. If it is zero, or close to zero, it means there is no linear relationship between XLR. So the correlation factor here, that's a measure of statistical relationship between x and y can help you to determine whether to invest your time and effort in creating a linear regression model. IE, before you invest your time in finding this box. Let's see if these two are somehow linearly correlated. So this is an example of correlation. We have the latitude, so this dataset that calculate the mortality rate due to cancer. So we have the latitude and we have the mortality count. That's right. So he refined that there's a huge correlation between the latitude and the mortality, the further you go, the lower your mortality count. So that is a negative correlation, a strong negative correlation between X and Y. Another example, two in two variables, is x&y here shows that as x increases, y increases as well. And we have a correlation factor of point A two, which means that those two are strongly linearly correlated, these numbers are almost ideal of your life, your correlation factors is usually known. But this is, so if you get something point a point and in really, really having, you really have a good data set, so you should cherish it. And then we have this kind of case where our data is our correlation factor is, is almost zero. So our problem is to see an estimation of y equal effects. So what we're trying to do is just emit y given effects. Okay. So that's our, our job. anyone looks at this function says, we'll have an estimation why it can be estimated to be x squared. And this is a really, really good estimate. So in a way, will you look at the correlation, here it is zero, which means there is no linear relationship, which means we can not create a linear regression model. But on the other hand, there is a very strong estimator for this relationship. And that's the problem with with regression models. If it is a linear regression model, then you have a path forward. If it isn't a linear regression model than you, you hope that there is a solution. But you didn't know whether you have a good solution or not. In this case, just looking at the data, there seems to be a good solution. But remember, this is an easy data set, you're able to plot it, it's in its it's one input one output, things are clear, clean and easy. Real Life The problem is much more complicated than that. You have multiple inputs to one output. So forget about two dimensional, you cannot even visualize your data. And you look at the correlation is zero. So if maybe there is a nonlinear relation, but you don't know, right? Maybe there is if you have a correlation that's close to one or minus one. There's absolutely a linear relationship between X and Y. It's worth the time and effort to invest in building a linear regression model. There isn't linear correlation, when you're, when you're, you're just hoping that something will work out, you have no guarantees that there's a good solution out there. So So let's say that we are doing an experiment. And we have two variables, x and y's. And we want to have some sort of relationship between x and y's. What do we do? Well, we try to establish that y said why effects write a reality? There? Isn't there aren't many effects, is there? Only beta transpose X plus Paradesi? That's basically it. There isn't any. So linear function. So it's beta x plus beta naught. So our goal is to find a line that fits the data, and any line could fit the data. Right, this fits, this was the data, this fits the data. So what's the question? The question is, what is the best fit? What is the line that best fit fit our data the best. And since we said the best, then we need to have a measure of goodness. What do we mean by best? Well, best is one that minimizes error. So if you go here, alright. And we want to find the best line, like we need one that minimizes the error to this point. And the error to this point, why calling an error, you will have this data point. And now the output when you have this input will be on the line when to be something random. Let's get this example 123455 data points, all of which is produced by one input. So can you give me a line that reduces the error between this point and this line? This point here? Is he right? And you will have no, make no mistake, you are going to have an error. The question is, which way of moving this line up and down, tilting it up and down right left, which way of doing it when you move it and you tilt it, it's going to give you the less or the least error. Right. And that's your entire exercise is moving this particular line up and down. So that means we need to calculate the array. And there are many ways with which you can create the array could be y minus y haft and you sum it up. But you know, you will end up with the biggest with all big problem that the delta y minus my Y hat could be positive or negative. When you sum it up, they cancel each other. So you could take the absolute value of y and y hat and then you sum them up. The problem is that this function looks like this. And no one likes these functions. They're not smooth, they're not differentiable. So, you know, you do that if you take the square root of the error, and then you optimize to reduce it. You optimize optimizing function to reduce the error. Okay. So we know our goal is to reduce it is to find y hat equals B naught plus B 1x. I, that reduces this error. So how do we calculate that? Right? How do we find these two values? Well it's an estimation so maximum like likelihood estimation or model estimation is a valid or valuable way of estimating your parameters. Maximum Likelihood is basically the theory of finding a an estimator that maximizing that maximizes the likelihood of the function to occur. So it's basically just find this parameter that maximizes the likelihood of the function. So first, You have to assume that given y will observe given x, the input will observe y. So there's a function that gives me y. Given x, let's make that assumption. Let's assume that there that function, there's a density function, that model the relationship between wine X that belongs to Assam, a distribution of sorts. And it's assumed that we have a parameter of that density function, if we optimize between maximize the likelihood that this falls within this, all this is a mental gymnastic to justify what we are going to be doing next. Alright, so again, the relationship between X and Y is not deterministic. It's an estimated relationship. So we got that out of the way. Since it's an estimated relationship, we need to figure out how to estimate it or to which goal and we said the goal to which we are estimating is to reduce the error is defined b one and B naught that reduces there. And we know how we have a way of calculating there. Okay, we have those nodes, this node, okay, can we somehow map this knowledge into a framework or a model of solution, where we achieve what the outcome which is basically just give me b naught, B, one and c. So we want to get to B one and B zero, we know our inspirations, were somehow to map it to a framework of solution and a framework of solutions maximum likelihood theory. It's basically if you estimate if you say that x and y have a statistical relationship, ie they have a density function in which they correlate. So you have the ability of Y given X maximized by Rama parameter theta. If you know that, and if you know that your density function belongs to a distribution of sorts, then can you start going? Can this be a good starting point? Maybe maybe not. So before we examine this hypothetical solution, let's make few assumptions. First, let's assume that x and y do indeed have they do have relationship between each other skill one that's represented by density function. So that's an assumption, it is supported by the fact that there is a statistical correlation between them as as found by the linear correlation between X and Y. K, we also assume that x and y, that they belong to a national Gaussian distribution, a normal distribution, policy worse second, I understand that there are statistical related, we can show that with the correlation. Why do you say that they belong to normal distribution, or that relationship is belongs to normal distribution? And my answer is why not? Right? It also could be normal to be anything, right? So why not? So that's a rhetorical comeback. And, you know, something that is even nicer, it's basically central limit theory. If you're if you're sampling data at random, then the data sampled at random tend to to follow the Gaussian distribution. That's a good assumption. So the good assumption is that since some of the arbitrary random variables things are up towards the Gaussian, towards a Gaussian by the central limit theorem. So we'll assume that this relationship between X and Y follows a Gaussian distribution. What does that mean? Well, it means that we can apply the maximum likelihood theorem on this problem, and we can present it with a Gaussian distribution. I'll discuss with students in maximum likelihood in the next slide, so don't worry about it. The goal is to say is it to say that there is certain parameter? If we can estimate it, there's a system parameter that maximizes the likelihood function that we need to estimate. So first, we need to say what is the likelihood function, given that this is indeed our problem? Let's not forget, this is our problem. So we need to find a way of estimating a parameter that maximizes the likelihood function. So what's maximum likelihood estimate? What is it it's basically Li, we can say that the probability of x the probability of x 1x 2x 3x Four. Alright, let's see this data is basically the probability of X one data times over 2x, two given theta times probability of x three, given theta, and so on and so forth, which gives you the factorial of, or the multiplier of the function of x one 1x one, our function here times x two times x three all the way to the end. So that's the likelihood function okay, so for our problem of estimating this line so this is our function we need to find a parameter that maximize the likelihood of a function another function with this calculation I know it sounds complicated for now, but we'll we'll take it home. So, just know that this is the maximum likelihood you have a multiplier here usually, you introduce a log to the multiplier and by introducing a log this multiplier becomes a summation and a log of the actual function. So this is maximum likelihood estimate. So all the problem happens to be this function itself. Right. So, here, we said this is our natural distribution. So, this is a multi This is a PDF of multivariate normal distribution. If we make it single distribution, sorry, single very distribution, it will look like this. So the probability of y given x can be approximated the PDF can be the probability can be approximated to look like this, if we feel it falls in our normal distribution, okay. So what does that mean? Our F can be represented by this function and your so this is y, this is x, this is y, this is x, this is constant, your theta here your parameters that you're maximizing is going to be beta one and beta zero. So, this entire long trick that we took to justify the use of maximum likelihood theorem is basically because we knew if I go all the way back that the likelihood function is the exponential of one minus b 1x. Or has been not x divided by two sigma. So we know this is our likelihood function. Okay. The summation of this is our likelihood function which means that our theater that we need to estimate to maximize this likelihood function is these two. So from here it's false just estimate beta one and beta zero that maximize this likelihood function and to estimate it is you know, you have multiple ways of making the estimation right? You could simply say You know, I'm gonna go you could simply say, I'm gonna take a gradient descent be one and be zero. And then you you calculate the new then you Wait, no, wait hold some sigma is the one, we do that. And that, and that definitely works. Alright Oh or you could say that this is a closed form problem that you could actually solve it. So this is a closed form problem. So you could actually calculate beta one and beta naught, that wouldn't change. So, once you calculate them, the numbers will change. And that's why when you train a linear regression model, as long as your training data doesn't change, your beta one and beta zero will change. Right, just try to introduce your training data, run the linear regression, train a linear regression model once, twice, thrice, and see if your parameters change, they wouldn't necessarily change this is calculating for deriving for beta one and beta zero because those are the parameters that that that you need to to, to calculate. This is an example of how linear regression simple linear regression look like. And then there's also the multivariable regression, which is basically you don't have 1x, you have multiple X, you have multiple inputs, right? So far, we had one input, you had one input and one output. This one has multiple inputs and multiple outputs. And similarly, similarly, because you're solving for more than a mother, this one is is the same as beta two 1x plus beta naught. The only difference is basically we said, you know, just just to this, sort of writing it in this long form, we're going to say, beta one transpose beta zero, and you just add one here, that gives you the same term, this becomes the new beta, and this becomes the new x. So that's why you have it in this form. This can be broken down to something like this, this is a closed form problem, you can solve it for beta. This is your training data. And this is your target. So this is a closed form solution. You know your axes, you know your y's. And you'll always be able to get our beta for the multivariate regression. So this is an example of predictive modeling. The reason why I want to explain linear regression not because it's the most complicated or sophisticated model, or it's difficult to understand, it's basically to explain to you that as a way of entering the field of predictive modeling, here's a simple model that anyone can easily understand and uses. But still, we need to figure out statistical relationship, we still need to figure out distributions, relationship with distributions, and a way of training the model. This one, this function here, this function here, uses x, which happens to be your training data to estimate for better. So x is training data analyze your target, are used to calculate your better. This is what we call learning. Learning is using your training data to estimate the models parameters. And this is an easy way because I can show you deterministically a way of calculating your models parameters. As we go to other models, it's not going to be as clear as this one, which is a clear function and mapping. So the next part of the lecture will be talking, talking about classifications. We'll start with the simple classification model that is logistic regression. And we'll go to artificial neural networks. So see you in the next part of this lecture.


ECE657 Lecture 2 Part II
Sun, Mar 27, 2022 9:22PM â€¢ 45:01
SUMMARY KEYWORDS
estimate, probability, function, output, logistic regression, class, regression, probabilistic, beta, form, multiplied, outcome, estimator, input, log, optimum, relationship, called, map, likelihood

So hi, everyone. Welcome to the second part of the lecture. And this part deals with meals with the concept of classification as part of predictive modeling. Now, last time the first part, we've discussed, regression as a way of estimating a function that map's an input to an output and the output happens to be continuous. And what we said is basically, our entire purpose is to find a black box that map's and non input. So, this is known into a known output, this is also known. And given this knowledge, you should be able to find a box that corresponds to a form of a function or say the function is, in fact, we said we can theorize that the function exists because we can show a statistical relationship between the input and the output, right. And as long as that the output is a continuous in nature, then this function has to be in a form of some sort of regression model, for example, something like this. And that's regression. And now, there is another class of problems where the output isn't continuous. It is, in fact kedi categorical. So, the output belongs to classes, c one, c two, two c n. And as we said in the past, it could be 1000 2000 10,000 Doesn't really matter, as long as it's categorical. We call this classification. So, this is an input. And again, same conditions, this is known. And this is not. Now, because it's class pace, A, it's class based, which means you're estimating a label to the, to the to the problems. There is an easy way of formatting that relationship, if it is indeed a labeling problem where we're putting a form of cover label on an input. And that is we can say that if if we know the input and the output, the probability when output emerging, say belonging to Class C one is in fact, the probability of the class of features these are features given the class emerges, multiplied by the a priori of the class divided by the conditional probability of x. So, in a way if you have this class conditional if you have this one if you have this one I think it's the total probability of px multiplies by 2x p x given y all that then you should be in a good check. And this is why they're called these Bayes theorem. So, this is the ultimate or the optimum way of mapping an input into an output is statistically sound you can still statistically prove that that that this is actually optimum solution. Okay. So, What prevents us from finding the solution? What prevents us from mapping an input to an output? If we know that this relationship exists, and it is proven to be optimal, well, many things, the first thing that prevents us to prove that or the biggest thing that prevents us to prove that is this one. Do we know the distribution from which we can find this probability? In most cases? We don't know this. Do you know this one? Reality actually, we didn't know this as well. Like you could know it from your data from your training data, but you didn't know it. In real life, like, you know, let's say that you're trying to find whether c one is a dog, and C two is a cat. Okay, so what's the incidence of having cats? Just like that was the possibility of seeing is point five is point two. What is this a priori, right? So this isn't, we don't really know it. And this one is a function of this one. So again, we don't really know we can estimate them. But in many cases, we don't know these probabilities. And since we don't know them, we don't in most cases, we aren't able to find to compute this probability. So it is a neat nice way of calculating the statistical relationship between the input and the output and it is the best way of estimating this box this box so optimum way optimum estimator is Bayes classifier I'm not gonna use the words because fire ants I'm gonna use estimator here. So that's the optimum estimate its optimum wind conditions when conditions omit big F most cases you will find it will live without okay which brings us to today's subject of of logistic regression okay. So logistic regression, sometimes called logistic model or logit model is is used and was used extensively by mostly vice dietitians in in estimating the probability of an outcome emerging very much like what we're doing here, which is estimating this probabilistic outcome. It is a form of regression. And I will clear that one out. We said at the beginning, we said when I say that the beginning of this part is that I said the beginning of this part is that regression and classification are different in that aim at finding other continuous or discrete outcomes. Material, I'm saying that regression is a logistic regression is a form of progression. We'll resolve this if this is the same question that other classifiers address like Bayes Bayesian classifier in that, if you have an input, what's the probability of an output being emergent? It has a binary output for its output. It's either zero or one. So it's a binary classifier and The way it works it the zeros the opposite of one. Which means if you're trying to classify that an object is a dog, so that's one, the zero means it is not a dog in reality than me zero means it is not a dog doesn't necessarily mean a cat. So it works best. I've seen people use it in different ways, what works best when you're trying to estimate the likelihood of something occurring, or, or not occur, but someone is sick or not. Right, if you're not going to win the lottery, or not, the probability of passing the exam or not, that's, that's how logistic regression operates. Now, the term says regression and says logistical aggression. And the way it operates, it says there is a linear relationship between the two classes somehow, or they exist within a space where linear relationship are identified. So this is the equation that we're most familiar with. When it comes to linear regression, or this said in linear regression if we're trying to estimate a a function, that function will have this this for multivariable will have this kind of formulation. So this is what you have here. All right. But here we are having other terms, we have the exponent here. And the Explorer here is an interesting trick to deal with this line that goes from minus infinity to infinity. So what we did, we took the line that represents the relationship between x and y. And we said, the relationship between X and Y looks like this. Okay, that's good. We don't really care for y, we care for the probability of y given x, so we need the probability to be represented by some sort of relationship. Okay. So before I go to explain this, let me go back here and say, This concept has been quite interesting. So what we decided to do, they said, and many techniques do that, instead of calculating this relationship I you have to worry about this, you have to worry about this, you have to worry about this, take out this and replace it by an estimate. And that estimator could be anything, you could estimate this one, this value, and if you estimate it, you can get this one as well. And then this one is the prior, you can take it from your training data. Other techniques, say I'm going to estimate the entirety of this box. This is after all, a posterior a posterior function, so we can estimate it in terms of a conditional probability. It's, it's not a big deal. But logistic regression does, it says, I'm gonna have a function that is an estimation of the step. And that function looks like this. So to move from here, that's a linear regression, to a logistic regression, we need to find a function that does that estimation. Now many institutions wouldn't be happy with what I'm going to say right now. Well, this is how we just did regression operates. You take that line that goes from minus infinity to infinity. You squash it, the ends. So you, you put it in a function, that function squashes the line, flattens the lines at the end, and bring it all the way down to me between 01 What it achieves here is that the output of this function is between zero and but they are indeed the output of any probabilistic function is between zero and one. So you have that mark, to check, is it between 01? Yes. Okay. And obviously, if you test it, at the extreme end of minus infinity, this one goes to zero. So this term goes to zero, and extreme and all infinity, this terms and these terms are, I'm hesitant to say, because the they go to infinity, so I'm going to make it something that makes my feeling as dietitian or someone who's dabbling instead, a little bit happy. So we have this term that looks like this I can convert it to be something like this I'd multiply, multiply the numerator and denominator by the by exponent of minus this term. So this becomes one, this becomes one and this becomes this one. So now at the extreme end of infinity, this term goes to zero, and you end up with with one, okay? I don't, I just don't want to say infinity divided by infinity equals one, you could actually say that it just it's incorrect, logically speaking. So anyways, at the extreme end of infinity, it becomes one at the extreme end of minus infinity, it becomes zero in the middle, you end up with probability point, five. So we were able to have a function that map's a linear regression model, into a proper logistic model that produces values between zero and one. And, you know, we're trying to estimate this function. And we think that this is in and of itself is a good estimator. It's a good estimate. And that's why it's called logistic regression. And that's why it's called form of regression. There is it's called form progression because the output is between zero and one and between zero and one, we have infinite number of, of, of digits between between zero and one. So that's, that's a form of progression. Which means the model is probabilistic, it gives us anything between zero and one if you have a nice threshold. So we could say, if the probability is greater than or equal point five, then the output is one. If the probability is less than point five, in the opposite, I'm going to collect these types. So the output is probabilistic. But you can map it into into a class A or class of, of one class or over another. Okay, so the question now that that poses itself is how does it work? How does it work that it's it's able to estimate a probate a probabilistic outcome? When we say it's, it's it's a binary classifiers? That's because 501 Right. So here, we have the, we can say that the probability of y equals one given x is e to the power of divided by one plus. We can also say that the probability of y equals zero, given x is one minus. Which equals So so we have a function that that gives us it maps to either poverty or it's one or are they now our only our only need is to calculate these probabilities. And you know, one of them is greater than point five, then it's either zero or on one. So how do you go about that? Well, what do we need to do? We actually need to find these betas. Right? Because we know x. So the only unknown z is betas. And as we said last time, you could say that you have better and better not. Excellent one, when you multiply them, so you could say this is the new beta. And this is x. Right? And this makes the math a bit more, more appealing. So when you need to estimate the spectrum of values? Right. So we said we're gonna estimate it. So to estimate this value, last last, like last time, we could do the vaccine, we could use the maximum likelihood. That's to estimate, right. And basically, as we said, maximum likelihood estimators is when you look to a bunch of data points. Right? And you can estimate the prompt that maximizes the potential of something like the AP meet, right? And then if we do the maximum, like a theorem will find that this is the estimator or the mean, not based on so we can estimate the mean, here by knowing all data, by using all data points, right? So it's, it's is something like that, which is basically can we estimate beta here. By knowing all of the data points, let's the learning part, you have knowns, and you have unknowns, and you want to estimate the know the knowns given the nodes. So for the maximum likelihood estimate to work, we need to have a form of density function. Now we have this one, which explains to us the relationship, the probability of y equals one given x, y equals zero given x. So in a way, we could say that the density function of Y given X Y could be one or zero equals you know. Multiplied by now, either this happened, or this happens, so we'll have to add this one. So here, if this is one, then this is zero, and this goes if it is zero, then this stays and this one good last use density. Your density functions it's it's like the normal distributions have one outcome or the other, both outcomes don't happen at the same time. Okay. So now we have formulated our density function, and, and it becomes easy for us to estimate the the, our our parameter and our prompt happens to be beta here. And as we said earlier, you have your maximum likelihood works off of something like this. That's your you know your your likelihood of theta and then you can take the log of it. So l So, L is log of this value and the log of this value, so, you end up with a summation of luck so, that's the likelihood function in this particular case this is our product. So, the likelihood of beta because beta is our parameter that we're trying to estimate is the the summation of of y i. So, why goes down um let me let me write write the function just used. So, the function is the original function is. So, this is the logarithm you have summation because you have multiple x's and y's so, on all points of x so, yeah it's a training right to try multiple X points. So, I have y here and you have log he made the x minus block one plus E with transpose X plus are live so, plus this one is zero so, it becomes minus minus i times log of one plus E beta transpose X alright. So, log e they cancel each other we have Wait is this way and why I log here as minus minus So, minus minus positive on this one and plus So, positive and negative they cancel each other Let me clean it up a little bit likelihood of beta would be essentially something like this one well i beta transpose X i and how many training points you have log one plus A transpose x okay. So, you have this outcome and then you need to estimate beta so, you take the derivative of the likelihood with respect to beta you end up with something thank says to be extracted suppose, minus the derivative of log is is one divided by this value multiplied by the derivative of it which happens to be itself itself is multiplied by the derivative of this one. So, I end up with something like this


ECE 657 Lecture 3 Part I
Sun, Mar 27, 2022 9:30PM â€¢ 1:25:12
SUMMARY KEYWORDS
neuron, inputs, actions, output, learning, neural network, fires, artificial neural network, signals, build, neural networks, architecture, activity, weights, machine, excited, informs, functions, network, create

Hello everyone, and welcome to our third lecture in EC 657. Today's lecture is going to be a focused on neural networks. And in in particular as introduction to the subject matter. Neural Network as we've neural network is a is a branch of the myriad of tools and different tools of intelligent systems. So we said in the past that are an inspiration of, of the way we build intelligent systems happen to be humans, and that it is basically our attempt to draw inspiration from, from the things around us that we've perceived to be intelligent in our own with, with with, we say that intelligence is basically the way with which we view behaviors that are akin to human behaviors, and therefore, we ascribed intelligence to them. So in our attempt to recreate that in our attempt to, to build something that acts intelligent way, in addition to the externality overt, you know, you build a machine that looks like a human or an animal, we had to build the internal dynamics of such intelligence. So we try to draw insights from, from biology, how our bodies are being built, how our brains function, how we think, anyways, how our brains function, when our brains are filled with neurons, okay? Can we with that knowledge to something? Our behavioral, you know, what are the things that we do and behave in a manner? How do we make judgment, hence, how to begin to build fuzzy inference systems all around us on the whole theory of evolution, and what kinds of inspirations we can draw from that. So when it comes to, to biology, early on in, in, in the in the 1940s, we started to understand that a lot of our biology make up of neurons. So we wanted to build something that looks like that. And we wanted to model it to mimic intelligence. So we said, you know, let's, let's, let's imagine how our neurological system look like. So you build something like this that has some sort of an end then there's centroid of activities. And then it goes like this, like this, like this, or something that's receptive activities, it's called lead in the right let's call this axons other than the right here that expand on it, maybe it looks like this. I can call that you know, some sort of synaptic synaptic connection going on there. So looking at this one, this representation of how our neural system looks like I have a vivid picture by the way. What we're trying to do to mimic here is basically saying, if you have bunch of chemicals coming in, you know, those chemicals come together somehow. And they do end up exciting. Then you're on such that it fires it fires in elected some sort of an activity so they'll come as a collective of pulses, signals inputs. A collective of of, of of signals that you receive externally, you send to the brain, the signal looks like a chemical component. And then they come together. I know what happens, no one knows what happens. And then they reach, arguably, certain thresholds, excite the neuron, it fires and creates an obviously, there are many unknowns here. You know, if the signal comes too fast, does that change how the neural behave? signals coming at the same time in different parts? I think cooperate, collide, you know, how? How do they operate? communicatively? Do they work? communicatively. And that works somehow culminates in action, do they compete? So we don't know these things? Right? What do we think, you know, you have bunch of neurons that receive signals, they're processed in the foreign action, and that action may contribute to other neurons. And this is how our brains work, or this is how we think our brains do operate, do operate. So and that brings brings us to artificial neural network that understanding, which is evidently weak of how, how the system looks like, you know, it's weak, because, you know, we don't know really those how those connections look like. Different colors. Like we didn't know, we really didn't know what's going on here, we think, you know, that there's some sort of action here that feeds into he comes also from me, or maybe goes to the next connection, like this is our assumption. So knowing that, how do you create an artificial neural network that looks like they're taught that you know, acquire signal process them, learns from them, and result in action? So for us to make that analogy? There are a few features that you should look into, to characterize our artificial neural networks. So the first one is architecture. Think of it as as as how do we create something that looks like this one? Yeah. How do you create something that looks like this one mimics the operation, as well, in terms of connections? But how does the signal move from one side of the network to the other? From the beginning to the end? Is there a beginning? And that's also a question? Right? Okay. Let's say that we've decided that the network looks a certain way. How does the network learn? Which is, you know? How do you actually retain knowledge, right, you process signals, you pass them on, decided that there's certain way of passing the signals. Alright, in that process of passing signals? How do you learn? How do you capture knowledge? How do you return it? And then more on the mechanics, you know, how do we activate in your own How do you make sure that the neuron fires or gets excited when it should get excited, and it is inhibited to ensure the inhibited in our case of fighting, and the degree to which it fires, right? As we say, here, that bunch of signals come together, you know, you get them, they give them your own excited and it fires. The fact that what the tires are not is important, for the zero not, but also when it fires with which string, do you think it is fire or is it the same firing strength? So these are questions you need to to answer while building your neural network. So as I said, the artificial neural network as a concept had been evolved or started being developed in 19 in the early 1940s 1943, maybe to be more specific. And since these dis 80 years, we've seen them gradually improve, grow and being utilized in a variety of applications. So they, they had a very great deal of growth. And it wasn't like an overnight improvement and that's why Why in this particular course, we will go through many, many, many architectures, many, many, many ways of creating neural networks is not just a standard one that feed forward neural network. And you will see the different logic, different logics going on their philosophies, our attempt to mimic the biological nature of humans. So the first thing that you need to be aware of comes the neural networks and how to classify them as the architecture. And this is very, very important engine or they are two architectures when it comes to neural networks, the first architecture is called feed forward neural networks, that depends on the feed forward flow of information. As seen here, we assume that information follows, you know, in one direction or flows in one direction. So you have the input signal, this is the signal, think of the chemicals in your body, as it is captured initially, by some sort of neurons that capture the the Sonos, and they get passed into the next layer, you know, they exalt maybe not neurons, they fire, ie, they create an action, the action goes to the next layer, gets excited, and gets sent to the next layer, and so on and so forth. And the collective actions to the prior layers contribute to the next one, the collective action, or the prior of the second, third, and so on, and so forth. So in a way, loss of neurons, formation goes one way to another. But in doing so, they create all sorts of activities. The second topology or the second architecture, again, we didn't know for sure that the information your body flows one way, right, or how the whole concept of excitement occurs. So another way of imagining, the architecture of neurons is basically in a recurrent format, recurrent flow information. So the information may goes in this way, you know, goes from this neuron, this neuron, it comes back. So it goes back and forth, it's not bi directional. The excitement may be in a form of states to trigger status things, it may or may not happen. The inputs can come in, in any part of the network. So that networks is not at the beginning, network doesn't have to be at the beginning inputs didn't have to be at the beginning of the network that creates everything later on, you may have some networks that trigger the network, network gets excited things starts to happen. And then you feed in input as the network learns. So even when the inputs are introduced to the system, isn't necessarily at the beginning, it could be in any place of of the network. And the outputs as well could be sampled at any location of the network. So it's all think of it as a free format, where inputs come in at any stage, outputs come out at any stage, and information go back and forth, up and down. So that's the current flow of information or recurrent neural networks. As you could imagine, it's a bit it might be a bit more difficult to model just because you're giving it too much freedom. And then the next The second aspect of neural networks is is the activation functions, you know, how do you get the neuron excited? So first, you have inputs coming in, and they do something with a neuron, okay. And that something is basically a saying when the chemicals come together, they reach certain threshold, the excite a neuron. The question is, how does the neuron get excited. And one way of doing that is through deployment of activation functions. activation functions control the output. So for example, if the input is greater than zero, produce an output one of an input is zero, produce an output of zero if the input is less than zero, produce an output of minus one. So you take the input, you rationalize it, and you produce an output. So this is the sine function. You may have a step function, decide, listen, if the input is greater than a certain threshold. It fires if there's less than a threshold. It stays dormant. It doesn't meet fire. Let's again, thinking how the human brain behaves. Because, as I said earlier, if the chemicals exceed certain threshold excite you, then you're on right. But also said the neuron could get excited, on fires, or could get inhibited with doesn't act, right. So, you may want to the neuron to fire excited and get a fire, a positive output, you may want it to remain dormant, that does nothing, or we may want to negatively contribute to the conversation. And that when it produces and negative, and there are many other functions. So this, these functions represent our understanding of the human brain. The thought that the other different functions are more of a mathematical necessities, because some of the functions that we think captured the way the human brain behave, and mathematically friendly, so you may want to say, Okay, let's have a more of a mathematically friendly functions that, that that suppress the input in a gradual range. And that's why the more you start building your neural networks, the more you find yourself moving away from the biological mimic mimicry of the brain to more of what can we actually do with the tools of knowledge that we have, and that's that create some sort of this associative relationship between where we started from, to where we've ended, and we'll come and talk about these things, especially when we talk about convolutional neural networks. And these things, you know, obviously, are not insignificant because they do inform the way we design your neural networks on the basis or do informal position with them, or against. Another possible example of linear function is, is is a linear function, taking input, as is a limit and produce it. So that's another example. So learning products. And again, we don't really know how neurons learn, we know we retain knowledge. So knowledge has been retained. We know that there are cases where we learn through example. We know there are cases where we infer, we don't learn through example. No, no, we know that there are cases where we learn indirectly through examples. So if it is learning through example, that's called supervised learning. And exactly he is strictly tied. So every exercise, every input has an output. So you're teaching the machine one step at a time, you give it a problem tries to solve it, it produces an output, and you show it the right output. And it sees worth getting improved to meet the expectation. So that's supervised learning. And supervised learning is more of the machine figures things out. on its own. There are lots of interesting concepts and products, for example, concept of similarity, the concept of competition between the different inputs. And that's how we start to draw conclusions. And there are different ways of doing unsupervised learning, and we'll come to it. In this course, this course we will cover most of these things, and are in the context of neural networks. So mind you, all these things will be in the context of a neural network. So we'll see how the, we formulate a neural network that looks like the brain, but learns in different ways. So again, as we said, In supervised learning, you build your neural network, feed forward or recurrent doesn't really matter. What matters is that once the network learned, I will discuss learning later how it exactly happens, produces an output it compares the output with a target, and then goes back. And based on that knowledge, it informs the learning process. So you know, you do have the output, you do have the input, you compute the error, and you correct for it, unsupervised learning, you have no priori knowledge, you didn't know what's the output, I suppose like you didn't know the art between quinque you really didn't know the output, the system has no input that informs the output. So what happens is that the neural network starts learning to detect batteries or to allow for those patterns to emerge. And that's almost like a competition between different patterns. Some patterns are dominant, some patterns aren't dominant and lots of observed and seen, and the neural network keeps learning and learning until it settles in some sort of an equilibrium, I will give an example to how it reaches said equilibrium. So again, in the training process is more of a competition between the different patterns, some some patterns reinforce, not enforce some patterns, strengthens each others, and therefore, striction strengthens the neural connections representing them, some patterns inhibit each other and therefore, it dampens are the connections that's represented. And then there's reinforcement learning Reinforcement learning is every, like you hear about it everywhere, it is held as as a victim of machine learning, because whether you train the machine to learn through example or not, there is nothing that is that says, a machine is closer to human than the machines ability to learn from its own mistakes, no fault. So, reinforcement learning is basically if you have someone who knows the rules of chess, and keeps playing for a very long period of time with different players, and starts, that individual starts through through through winning or losing, identify what kind of actions and behaviors they should take, to win more than lose, and, you know, and that their own personal experience, and form informs their growth. So, you know, think of machine that keeps growing, just depending on its own learning experience, which means the oil the challenge, or the biggest challenge of supervised learning, and that is, we don't have enough learning, training data data that trains the machine. And so we wouldn't have enough of it. So what we do we train it, let, let it go into the wild, just to close on thought. So that's the concept of reinforcement. It draws from the way behavioral scientists teach certain activities. So what behavioral scientists do, especially individuals with learning disabilities, they take an activity they break it down to actions. For example, like let's say activity, a, it's broken down into six or seven actions, you know how to go how to open the door, stand up from your chair, walk that activity, number one, stand up, activity number two, walk, activity number three, hold the handle, activity number four, turn it down, activity number five, bullet, pull it back. And that's that distinct that that describes how you open a door. So the break it down to several actions. And if if a person does the sequence of action as is they get rewarded. So Reinforcement learning is basically a machine that tries to do things through series of actions. And if the final outcome is the desired outcome, they get rewarded, so they get the reward. So they know these actions are, are useful. If they fail, then they get deprived from that reward. So they know these actions are not useful. So discarded. So what happens is that you will fail a lot at the beginning. But as you are being rewarded for success, the machine starts learning the successful actions or sequence of actions and will return them and will discount the useless or less useful actions, because they don't yield higher reward. Theoretically speaking, if you run this for a very long period of time, the machine will only retain successful actions. Now, just by describing it this way, you might think, Okay, what happens if part of the actions were good and possible that what happens if randomness comes into play? What happens if so and so and so on? So changing environment, actions that work here, but didn't necessarily work there? In some doors, if you turn it down, they open some doors, and it turns out, they open some doors, you have to push them to open all the series actions up to the moment you make a decision. The last weekend concision are correct. It's just a mechanical decision that varies. So how do you part reward part of the actions and penalize other parts of the action? Big challenges? We're not near solving them. That's why I'm not too worried about AI taking over the world. yet okay, so fundamentals of artificial neural networks as I said, in the 1943, McCulloch and Pitt's had come up with with with a model. And that model was basically a single neuron model. Right. So, the single neuron model as we assume it operates such that it has one neuron has a bunch of inputs coming in I not much and we can say there's there's a summation function of sorts, and maybe there's a box and though as those inputs enter the neuron, few things do happen. First thing is that this neuron may gets mega excited. So, may show an excitatory exaggerated behavior, I have x equals one the effects are summation of x, the y equal one and may gets inhibited. And that is if x is one, then why is it so, the behavior of the neuron is is not necessarily can go one way or another can get can, you know, the neuron can get excited, or unexcited. So, it doesn't find Okay, so that's number one, number two, the inputs in in this NP model strictly binary. So then what are the inputs are either zero or one. So binary, make get excited may get inherited. Three, you do have weights here assigned at the beginning and that those weights are assigned to either Dr. Excitement or inhibition, which means if you want the network to show an excitatory behavior, the weights are greater than zero. If you are, if you want the weights to show inhibitory action, they may understand zero and the different weights can have different values as well, either to excite or to inhibit. And finally, what you're trying to learn here, if learning is the right word, you're trying to maybe guess you're trying to get the right threshold the right threshold that determines the output, so the output has to be greater than the output is determined by officials. So you may say if if certain threshold is exceeded, then the output equals some value. Okay. So summation exceeds certain thresholds, summation of x's and y's, their weight, then your output is equal certain value. So what you're trying to find out, is guessing the threshold value while locating some weights that that excite or inhibit an output. An example of that would be let's say that we have a neuron with three inputs x 1x, two and we want that neuron to behave like an app and get so we say the weights are equal one. So the pass through and the threshold is three. So if the output is greater than three, if sorry, if the summation of x is equal than three, then the output is one otherwise, output a zoo. So that mimics the AND gate. So this is an gate. If you want to do the old gate, then you assign the threshold to be one and you say if greater than one, then the output equal ones, otherwise the sequences, so you're guessing your threshold or assigning a threshold based on the behavior of the neuron. And then you change your weights to drive other exhibitors on Heavitree behavior. So that's the first attempt at that at, at neurons. And as you could imagine, the system has lots of problems, the biggest of which is basically there is no learning going on, you're learning nothing. You're guessing the threshold and the weights. It's it's an open loop. So just a just a new take a look at just the weights, take a look at just the visual take a look until you get the behavior that you had tickets. So a good attempt good first attempt but led to very little. And then we come up with perceptron, a much much mature a much more mature concept than the NP model that we'll discuss in detail later. After which we came with something called the Adeline model and improvement over the perceptrons in the mid 60s, and then back propagation algorithms first version were produced. So just in the mid 70s, to lackluster success and then the multi layer perceptron the network Charlie the back propagation algorithm was was presented by Ron Hart and Hinton in the mid 80s. From their own neural network, fully to, to con. So as we said, the MP on Nikolic its model had a major issue. And that issue was basically it has no learning capabilities as well as limiting computing capabilities. But anyways, looking at the structure, there was a lot this structure leaves a lot to desire. First, this looks like a neuron. We come up with the concept of summing the inputs. There's the concept of activation, ie if the value exceeds certain thresholds, and then there's the outcome of firing. So there's the there's this. So, in a way this structure although it was very limited in what it does, truly limited in what it does, that opened up a path


ECE657 Lecture 3 Part II
Fri, Apr 07, 2023 9:04AM â€¢ 34:14
SUMMARY KEYWORDS
perceptron, solve, output, derivative, weights, threshold, function, calculated, differentiate, problem, terminologies, challenges, differentiable, neuron, input, delta, performance, gradient descent, nice, discussing

So hello again, everyone. This is the second part of today's lecture. And in this part, we discuss basically, the concept of multi layer perceptron. And in here, we have to truly revisit, what is the main challenge that we have, with perceptrons, we've, we had multiple challenges, but chief among them is basically, it's, it's one perceptron, which means it solves only for linearly separable data problems. So if you bring this problem, for example to the perceptron, two triangles here to set us, the the perceptron, will try to draw a linear separator between the two classes and wouldn't be able to find that because all intents and purposes, are you to separate these two data points, maybe you want to draw something like this, that kind of award? Well, it is a very difficult problem. But this is just to demonstrate that a perception will be challenged to them to solve this particular problem. And they account that well, the chances of this particular problem on the account that it operates in a stringent manner with which it is controlled, essentially, to have a linear separator. So there's this particular aspect, there's also the issue that, you know, we want to draw a, a an inspiration from from, from the human brain, or the way our neurons operate. And usually, the way our neurons operate, means you have more than just perceptron. And they work together. And they do create a form of a relationship. So that is one of our challenges with perceptron. Because in reality, it's it's, it's, it's not what we wanted to do, when it comes to multi layer perceptron, or on many layers, we want many neurons, and we want them to work together to produce some sort of an output. And, you know, we want that output to be informed by the input and what everything in between to be somehow controlled as well as my way out. So. So that these are some of the challenges we have with perceptron. But these aren't the only ones, for example, the fact that in this particular example, we have the first line makes a determination, it's, it's a circle or triangle, this is all on one decision. So it has sort of all or none attitude of solving problems. So this is this is challenging. There's also how do we are how, how do we truly bring the concept of community of influence? I remember in one perceptron, you have your features coming in. And they sort of update the weights. Maybe there are more than that. So all of his training data, just contribute to this defined sets of weights, there is no way to extrapolate different attitudes from different training data. So almost like join contribution. And that's that's really what is used to mimic the human behavior. There's other aspects that I haven't mentioned earlier, for example, the output is threshold based. For perceptron, as well as for the MP models. And perceptrons. Let's show is almost defined an MP model you learn. So, this is something I can think of. If we think of solving a problem. You have inputs. You have your outputs. And then you have your weights and you have the thresholds here for NP models, you need to learn the thresholds for perceptrons need to learn your weights. And that adds on into the complexity of how these things are built or operate. So there are plenty of challenges. And, and and we need to go through these challenges in a way that allows us to somehow mimic again, the human behavior. So, before I go and say, how do we get multiple perceptrons to work together, let's solve some of the challenges that perceptron has. So earlier, I said, in the first way of solving for the perceptron, we needed to take derivatives and solve for gradient descent, I said, this is a nice theoretical exercise. But there are challenges that we'll talk about it. So now I'll have to address these challenges. The first challenge happens to be the whole of getting of getting updating the weights. So, reality, let's say you have two weights, or two dimensional weights, right, the weights w one and W two. So to update the weights, obviously, you know, you create your contours. And you're hopeful that you're going to move somehow to the goal. area, the way we're doing it, or we've been doing it so far, basically, you move this way. So w one, or you move on w one, or you move on w two. So if you move this direction, this direction, this direction, that's bad. If you move in this direction, in that good. So you move w one and W two, and you then move independently. Now, if you have a million W's, in that becomes mathematically difficult to solve. Right? So problem number one is actually the movement of the w's. If you're doing the gradient descent, so one way to go about it is basically to move in both or at both directions at the same time. So your delta is the combining this movement. So your delta is basically function on w one. And w two, we have a data here, just one step. So instead of moving in what one wait at a time, just move the vector wait at once. So that solve the issue that you're differentiating for every Wait, you have a million waiting and making 6 million differentiation with which you're doing the 60 million deltas this way. It's one Delta being calculated, and you update all of your weights at once. So that's problem number one that we need to resolve. Problem number two that comes from problem number one is basically initially with the with, with my Makala fit models, as well as the initial perceptron. We were operating off of thresholds. And we said if you're we said the accumulation of chemicals, or the accumulation of inputs have to exceed certain thresholds before they fall. And we said we'll we kind of left it on its own that we like we discussed bias and mortality, but we never addressed this the elephant in the room, which basically will well yes, we understand that, logically speaking, you need a threshold to fire neuron. But if you're doing the math, like how does this threshold gets gets represented? And even worse with the MP model, how do you even learn it? So that led to the creation? You know, we said the x one and x two here. I said well, we're going to add some weight he has an input this weight is is us learning the threshold. So we don't need to assign a threshold value. We'll just have to add this extra term. And we make it a learn something that we learn. And what this does, it drags this term to zero so we don't have to explicitly set it The thresholds. So that's why we have one here and we have a bias or that technology is just because we don't want to learn, we don't want to set a threshold we do, we want to learn it as part of the learning process to learn when a new neuron, the neuron fires. So that drags your threshold, and then you get to get your 01 or minus one. So that's all the challenges the threshold, we don't need them. They're part of the, of the news. So we just need to learn the w's. But another problem is that this function isn't a differentiable function. So if you take this function, you need to take differentiable dysfunction to get your, your Ws and this one isn't differentiable. As a matter of fact, it is, it is discontinuous at both ends. And that becomes an issue. So perception has also an issue of differentiate ability. And that's why we never used used this approach, because you need to differentiate the function as a differentiable solution to this one was proposed that suggest a smoother function that is differentiable that you can differentiate. Once you resolve the threshold, once you see us all with the differentiate ability, then you kinda have to kind of have at your disposal the ability to get your delta w, and what what remains. The is basically how do you measure performance? Here, we said, performance. Performance is the summation of misclassified distances. So that's our performance, you know, just sum them up. And differentiate? Well, there is another way of doing the performance is by saying, performance is the output is the target minus the, you know, you measure that you have the target, you have your output, the difference between them is your performance makes sense, you know, the problem with this function is that it looks like this. And this is ugly, this isn't differentiable, looks like. So might as well make it look like something like this. Well, it makes it a much more smooth function. And since we are minimizing for the error, we'll just make it look like this. Since we have a two here, and we are going to take different, we're going to be differentiating this function, we might add a half here, because we know the half will just disappear once we differentiate. So now we've solved many problems with the perceptron itself as an existence, we solved the issue with how to evaluate its performance, we solve the issue with a threshold by adding a bias, we solve the issue with the with the function itself, that fires the activation function being discontinuous and made something that is differentiable. So we have a fairly nice, a fairly nice perceptron that accepts more than inputs has a bias and passes the output through a differentiable function, and this way, it's it fires anywhere between whatever it is, the friendship function will allow you or allow you to have. So that's still one perceptron. Right? We haven't we haven't asked the question. What to do next, it's still on perception, it still will fail, extending and receivable. It's still primitive. And our hope is to create a very complicated neural network that has a lot of perceptron that has a lot of inputs and a lot of outputs and a lot of neurons. So now what we're doing what to do, you know, we We build. And so we see, we have an input, and that input is by the way, x 1x, two, and so on and so forth. Okay, common n. And you're on here. And that new lawn consumes weight, or weight vector that other weights always always produces an output that gets passed into a an activation function, which has its own output that also passes to another neuron. And that's the trick, we want more than one year. Right? That gives us something like this one, when you're on second year and third year on that's our promise. And then that one also has its own activation function and has its own output and also a vector of quit. Okay, we say the performance of this particular network is half minus half t minus r squared. And, and we said we'll get we're going to be using gradient descent to solve the problem. So let me go back and say, Why are we using gradient descent, again, we want to make sure that the change of the output once positively has to if you have a good output, you need your weights to be updated in respect to the output, you have a bad output you need your weights to be updated backwards. So it's almost a backward propagation of your output results such that it positively or negatively impact your weights. So the weights go up or they go down change based on your output. So we need to figure out the relationship such that the delta W is a derivative of performance given WT and this way, we can change our WT WT okay. So that's the logic delta of weights are a function of the output, if you change them, if you change the change the output the output improves, you improve them. So, you know following propagation, backward propagation, and this how you update your system. So, the derivative of p which is at around here Hewish given WT is what's going on for the change of a W two, who keeps saying WT w two. So, let's break this one down by the channel. So, performance W O multiplied by w o times W differentiate or w two who this one we can it can be broken further by W O given p two p two given w two. So, differentiate of all given P two multiplied by differentials P two given w two and this gives us what we want gives us this whole term as we want it to be okay. So, this one is the change for w two. Similarly, and again I want to keep all of it in one page. Similarly, for delta w one its change of performance given W, a ticked all the way back, so it's differentiable of B, P, given all time differentiable given P two times differentiation of P two, given why we're taking it all the way back times differentiation of y given P one times potentiation of P one, given w one. So P two w one. This checks out fairly well. Okay, so our job now is to solve for these differentiators, differentiate will differentiators. And if we solve them, if we solve them correctly, then we've solved our, our simple neural network. So let's see, what can we solve is maybe this differentiated or this term works on this one on this particular chair, so to differentiate p given Oh, the result is, you know, two times have one. Differentiation to the derivative of minds always mind is minus one. So minus minus, so you're gonna end up with something that looks like this. So, this term is solved. It's solved derivative of P two given w two. So, P two given w two. So, y times w two gives you P two right stock product. So, y times w two is p two p two. So derivative of P two given w two equals one. So, this is solved and this is solved, what remains is this one as a challenge. Same goes here, this is a challenge P two given Y equals w two. So, the weights contribute to each other, yes, the weights contribute to the calculations of the delta. So, that's community of influence right the way you calculate one weight in part of your network will influence the other way you calculate the weights, this is very important, because it will help us explain other phenomena that impact negatively or positively neural networks. The derivative of y given P one is also a challenge p one given w one is the root. So, here if you break down the the the your terms, you'll find you have multiple terminologies that you need to solve for and if you solve for them, things will become much much easier. So, now, having explained how the logic looked like, let me start by rearranging some of my terminal terminologies I want to rearrange to draw a few points. So derivative of p given w two you should look like P two w two all two times P I'm just rearranging the terminologies p one, that you are p one p two O P one or P two okay, we said that list always equals to b minus a, or Mr. Always equal All right, so just rearranging the terminology. And what we're left with in this particular situation, we have an input and output and goes through the activation function, it's called the output being beta, the output input being alpha. And let's call this one this assume this one is a sigmoid function. So it's a nice smooth function and let's solve it for this particular case. So, if beta equals one one e minus alpha differentiate it given alpha you would have minus one plus a times times right you could try it this one gives you one could do a little bit of massaging squaring. What can be broken down can be broken down to divided by one plus the minus alpha times this is one nice one. Alright, so we said this is what's beta. So, this is one minus beta times meat. So, any case where we have this kind of situation, the derivative of the output given the input is function of the output. So, literally the value that you compute one minus that value multiplied by itself, and you can insert that whenever is needed. So here because this is an output this is an output. So here this is an output, it's one minus all times. So that sort of this one, that's an aspartate. Here, it's y times one minus Y one minus y times one. So, whenever you have a problem where you have this particular terminology, you don't need to care about the input as long as you have the output which you have, but if you literally calculated it, it's a number three 4.5 Whatever it is, you just substituted this derivative by this number and this will give you the derivative. So, the derivative of p given all its constant the derivative or given P two as long as you have the all of that function is one minus r times the derivative of P two with respect to y is the weights which you have already calculated before. Right. So, the weight of every of n minus one is a function of the weights of L and the weights of L the final layer, just a function of the output performance and the last activation function and That's about it. So the function of the input, its input, the performance, the output. And that's it. So if I were to represent the first technology, or the final little final layer, it will be t minus O times y. T minus all times one minus all times all times what all is available. W two is w, T plus your delt, K, once you get that, you can plug that in, as you go backwards. So that basically, that basically it when it comes to calculating, for solving for this network, as I remember, this network is one, one layer. It's I'm sorry, this network is one level deep. If we want to solve a bigger problem, then we have more than one level, right? Because for all intents and purposes are solved only for this level. So what happens when you have more than just one level? What do you do? Well, in reality, if you solve for one level, you've solved for everything else. This is why I rearrange the terminology. See, if you notice, for to calculate delta w one, this term has already been calculated in the in the first layer coming back. So you've already calculated this term, so you didn't need to calculate it again, this term will remain as this wherever you go, right? Once you've calculated this part, this part doesn't need to be calculated, if you're calculating the w's here. Or if you wanted to calculate the W's, here, whatever it is, so every single time you calculate the term for a neuron, that calculation is reused across the different path that you you're using. Again, every path has has a segment of it. And that segment is calculated only once. And then you're constructing multiple paths. So you're reusing your calculations, when you find your W's. So it's, it's reusing the already calculated math in that different path that you can choose to calculate your your different W's. So this is basically calculating for for a multi layer perceptron, where you have lots of perceptrons that have their own, you know, activation functions. And so this one is literally breaking down the activation function and we're breaking it down. And this is how we're calculating all these terminologies. Next week, we will be discussing multilayer, we'll discussing the backpropagation learning algorithm. In much, much more detail, we'll be discussing the radial basis function. And if you have time we'll go on Kohonen self organizing maps. By finishing those topics next week we'll be ready for the first assignment which covers everything up and up until maybe a little bit beyond the RBS. Okay, see you next weekend the discussion session and have a good long weekend.


ECE 657 Lecture 4 Part I
Fri, Apr 07, 2023 9:06AM â€¢ 57:16
SUMMARY KEYWORDS
neurons, weights, delta, function, derivative, layer, summation, calculate, input, multi layer perceptron, neural network, learning, perceptron, ai, output, solution, propagate, impacted, multiplied, sigmoid

Hello, everyone, welcome to our fourth lecture. I'm sure most of you have gone through your grouping, and that you've joined the group settings join in preparation for the assignment that is going to be rolled out tomorrow. So all or the day after, please make sure that you you're all set, make sure that you understand who your partners you've communicated beforehand. The assignment itself is going to take around two weeks, the due dates and everything is on learn. And I do urge you that you pay attention on on on these dates on Learn, the only way of submission is through learn as well. And usually, we don't give extension for late submission or if there is in any extensions will be with heavy penalties. All these things will be made clear. Later on. However, please make sure that you get everything done in order. Before we'll get to that point. The material of this lecture is obviously going to be included in the in the assignment. So so far we've gone through multiple subjects were where we discussed and tools of intelligent system designs we've shared with Shawn, one approach to build an intelligent system if you remember, the differentiate the integral that we had so far, we discussed linear regression logistic regression. perceptrons last week, we ended on the multi layer perceptron networks. And we've gone through a the math that explains the multi layer perceptron we explained why it was the inspiration behind it. As well as the different mathematical formulations that lead in the understanding of what we were what we were doing. And that was essentially the process through which we made a few divisions. Those divisions, in my opinion, were were all good enough to understand how the neural network operates at large, and you know, especially when we're talking about the learning process, which usually goes this way where the input itself where the output itself contributes contributes to the calculation of the weight. But this network, if you take a look at it, it's it's overly simplistic, it's just it's two layers, but it's, it's it's one level deep. So it's one level deep two layer seems to be simple. Today, we will have to generalize that understanding and that visualization will will include us explaining how are we going to be updating the weights in these different links and these different links such that you know, any change here, it's called this output one and this is two and a change here will cause the very various weights to get updated. Right. So let's assume that we have multiple layers, layers here and let's say this is layer x. Let's call this layer of let's call this layer, l. Let's call this layer i Let's call this layer, yay. And this is the final layer is called Okay. Okay. The exercise that we need to figure out that if I have an output he have say, of say some sort of a dog Okay, so it cuz my machine learning classifies between a cat and a dog. And this way is point five. So it's also point five I target is a dog. So obviously I need to raise this one up to become one or as close to one as possible. Right So I need to raise this up. But one another way, if I'm looking into my performance function or my error rate it is it should be calculated, it should be calculated in a way where, where it is t minus o in this case, it happens to be one minus have half, your, you You're, you're getting it, you're trying to get it down to zero. Or something to that, to that effect. So, that's usually the exercise that we don't see clearly here. Now, what impacts this all one? Well, many things impacted the input impact impacted the weights here. X L impact impacted the different weights. The weights here impacted as well. Let's consider this to be zero, just to the depth and this is D, whatever. Alright, so those all of these happen to, to impact, you will find that outcome, right. So if I want to make a change here I make a change on this W alive because that's the input to this function, I have to be cognizant that a change of in this note will mean a change here mean a change in the various notes, as well as a change in this note here. All these changes, they come together and the effect a change. So in a way, if you think of what we explained last time, we said if you want to have an update of this note, I an update of WD essentially, I You are causing a ripple effect across the board. So there is a big box of changes happening here. Alright, so all on I mean, some summation of changes is going to take place here multiplied by other factors. And that we haven't accounted for, we haven't accounted for the fact that a change in any place will mean a change, and many, many, many places are. So what we're going to do today is going to derive the math that explain this particular situation. Let's go to this lecture. So what I'm going to do, I'm going to extract I'm going to extract these these neurons as well as maybe this what I'm going to extract these neurons and explain how certain algorithm named back propagation learning operates to solve this particular problem. One other thing that I'm going to do, I'm not going to be neglecting, neglecting that all of these nodes have lots of inputs and lots of outputs. So I'll keep that in mind as I draw my solution. So we have L we have aI we have j and we have, that's the output. So this one has the output, okay. And this one has myriads of inputs. So I'm just gonna not gonna worry about them but I'm gonna say All those inputs are all represented by something called a l, essentially, it's a summation of it's called X, X L's all of them coming to the little layer, l times x i. And then I have, then we have here a function. You know, if you remember, we had a function like this, lets quashes the input and produces 01. And then this is connected through weight and has AI and has functional I'm gonna, I'm gonna make this I have no reason why I'm making myself. So that's expected to go. So am I, an FYI, here, got this neuron, which has also a j. And if j going here, a k, f k, all the modules, squashing functions. And then between every two, two neurons, we do have our weight. So, so far, this is a representation of what we had before. But as we said, we're not going to be neglecting the fact that we have been to other neurons within the same layer connecting. So layer i is impacted by a bunch of neurons coming from Lyra, layer J, is also impacted by said neurons. And, you know, so let's so So the exercise now is to solve for one neuron, given all these understanding, let's decide let's make a determination. As I, as I alluded to earlier, that I really want to solve for this weight. I want to solve for this wait. So we say that our error rate is calculated. This is the performance function as in the last week squared. So for me to change W Li, I need to take the derivative of the error rate divided by the derivative of w a lot. And we can, we can apply some form of a chain rule. And you say, and we say, You know what, let's break this down and say, We want to have the derivative of e, all the way to AI. So there's plenty of things going on here. I change the colors here, a little bit, I said, these are neurons, these are neurons. So there's plenty of things that are going is your target, and this is you're going from here to here, I want to I want to sum them all up in winter. As it I don't want to worry about for now, I'm just gonna say I'm going to take the derivative of e all the way up until AI. And then I'm going to take the derivative of AI with respect to a lie, which means this AI so I'm not going to worry about this for now. I'm going to solve the easier part these are parties that AI the derivative with respect to the weights coming in is basically this function. So similar to what it did was similar to what I did with this term here. I'm going to state that AI is the dot product. It's the dot product of it FL. And and so the derivative of a given if R is gonna give me FL just get rid of this one. So this becomes in a go to next stem becomes times when we know this function, so we're not worried about it. Now remember, last last week, we were deriving our calculation based in similar logic. So the difference here is that we need to account for the connections. So first, this term is still ambiguous. We're going to name it delta i and we are going to say that the solution for this problem is delta I fill my but but before we, before we go a little bit further, we have to remember that sorry, let me make FL, we have to remember that we have many of these. So this is layer l. So you have to remember, you have many of these contributing. So, and many of these contributing, so it's cannot just be one term here. Right? It cannot be one term. Ai, he affects all the weights going to the next level. So it's not just one AI. It's not just one impact of any one AI it's in fact, multiple AI. So somehow we have to do to break it down and say, well, we'll actually look into the summation of this one. Okay, what does that mean? Well, it means that we have to break this one down again, and say, well, it's delta E delta a j, A, and the derivative delta A derivative AJ given Ai, which is in this case happens to be also this way as well as derivative of this function. So that means we have to break it down more by saying, by taking this part, we delete this part. I'll have to, I'll have I'll have to break this part again. Because delta h a is you have to take derivative of AJ with respect to the eyes derivative of AJ with respect to a of f AI, multiplied by the derivative of AI with respective of AI. So it's a general. So one step further. That's all equal delta times delta with respect to FY times the derivative with respect of AI. This one, nothing is going to happen for now. This one is the weight of AI between ing. And this one if you're taking this derivative is going to be the derivative of this function. So we know that derivative Okay? one extra step before it goes on to the next page. So this is delta i Now notice that we have multiple weights, right? So it means that delta I is the summation on J on layer j, right of, of this value. And as we said earlier, maybe we didn't see it, you notice how I call this delta odd because it's the derivative of a given Ai. This is derivative of E given a j, so we call it delta J. Right? As a rule of thumb, anything that there have to be given any a x is delta x or an H, make a delta H, right. So, this is the reason behind my notation. So, there have to be with respect to AI, that's the dye, okay? You break it down. And you end up with a derivative E given AJ. And that makes it delta j. This one is a constant has nothing to do with anything, it's local to this neuron. So we don't care that it is part of the summation. But then we have the double the weights. And that means all the weights that's coming out, right. And they are going to be considered for this particular delta. Now, okay, do we know delta G. So we started by saying to ri equals something like this one. We started by saying that R equals was actually it was started by saying the derivative is delta r multiplied by a field. So that's the derivative that makes me allows me to change who. But we found that the change that the changes that we seek to do here impacts multiple impacts multiple weights. Okay, so now, we broke it down to Delta od to do a summation of multiple Delta ages. And we still aren't done because now we have to figure out what is delta G. So we'll have to go one step further. Now looking at at here, there is a pattern. So delta I is delta phi is the derivative, delta equals the derivative of the function itself with an eye so it's this one multiplied by some delta G, which is related to the next layer multiplied by the different weights coming out of it. So is it going to just say that this one is Ajay, summation, some delta k, because k is the next neuron here. Multiplied by you know, WJ k. So that's Delta. Right. Okay, so now we've solved that digit. Now, what is the solution to the ticket? That ticket is actually the derivative of E with respect to two with respect to A k. Okay, so we have this nice You're on here as a k, this is f k, this happens to be the output. And you know, there's t here, and based on these two capability, so if we want to break this down, it's the derivative of delta E with respect to all times the derivative of all with respect. My second this is Oh. So I'm gonna say instead of oh, I'm gonna say it's the same thing, I want to keep my if gay would have to have f k with respect to A k, which, as we said earlier, it's a k. Now, what's this value? Remember, e equals half t minus o, n, the derivative is the minds. So that's t minus Howard this value, well, if we assume that we have a sigmoid, then this is literally is supposed to go the next pages, but the next page there is literally d minus o f k one minus f k and that gives you the derivative of E to A k and that gives you that Okay, so, this is computable all these values we have this is all right. So, this is computable. So, you take this value, and you plug it in here, alright, remember, this is the neuron has bunch of has bunch of of values coming into it. Alright, as bunch of months, bunch of weight once a week is this is zero, this is one all the way to Sunday, alright, and this is your A k, and this is your f k, which happens to be all right, so you have all these ones. So, you take this value here, you plug it back in with different J Ks. And this will give you, your delta j, you take it, you plug it back in here with a different IGS that will give you delta ri, you plug it back in here. And that will give you that will give you a calculation here. You will delta w li So, in a way it's fairly, it's fairly ingenious that it takes it takes you a while to go from the very beginning to the very end and then come back. So if we were to if we were to revisit this particular example what we'll have is an interesting revelation, you have your input coming in. You have your initialized weights that you choose at random your inputs come in right that allows you we said l j k that will allow you to calculate your alle summation here will allow you to calculate your FFL right the different ACLs NFLs. Then, they will contribute to FY the different F eyes and subsequently a eyes and subsequently of eyes which will be used to also To calculate the age the age is an F js, which will be used to calculate whether it's a dog or a cat. That's your AK and FK, which happens to be, is it a dog or a cat? Alright, so if k is zero, okay, well, here's a fun fact, or a fun thing to contemplate. We said earlier, that T equals is a dog. Right? So, your T one should be one, and your tz two should be zero, your T one is a dog, your T two is get your T one should be one, your T two should be zero. And here you have you have your you have your all one equals point five, you have all two equals point five. And we said we want to change this particular neuron, right, we want to take it up. But also you're taking this one down. Alright, the goal is to minimize. So if you're taking this one up, you're taking this one down, it means this the change with respect to this particular neuron has there will be changed with this because the change of this particular neuron will propagate back to change the different weights, but also the chance that this particular neuron will probably propagate back to different neurons. Otherwise, it will just recognize every data entry to be just a you know, a dot, right? Because it will be biased towards making sure that all one is one. So you want to be one where it makes sense. And you want it to be zero where it makes sense as well. So you have, so you have to be able to balance out and the solution for this one is fairly simple. So you have x one, one T one is one, you have x two, or T one is you making it binary here. So I don't want to worry about this 1x three, one, t one is 1x Four, where T one is yield something like that. So one data point, second data point, third data point, and fourth data point. So when the first data point come, this is one epoch. So in the first epoch, we have a batch of training data are all training data, they come in, you know, you take this one, which is this case, and you end up with your delta W's. Right? You end up with the first Delta, W's, all of those studies, this one, all those W's. So for every one of them, you had your delta doubles, the next day, data points come in, and you can calculate the second delta W. The third one, calculate the third delta w the fourth one, you calculate the fourth delta W. Now what's the actual delta w is going to be this their summation divided by four. In case it's so you take for every for every delta w is going to be the average of Delta W's that you get from the different training points, either all of the training points or batch of a training of the training point, whichever you decide on. That's, that's that's basically it depends on on on, on your desire for high performance, and so on and so forth. But in general, this what you do to update, update your weights. So let's go back and read through the algorithm in a much more in a cleaner way. As opposed to the this the the the organic growth of explanation that we've gone through. The first thing that that we need to understand is that you have two stages. The first stage is forward propagation. Right? So the patterns are presented to the network. So you go and you present the pattern and you calculate the different weights. I'm sorry, you present the patterns and you calculate the difference. functions here all the way up until your target is calculated. And then you calculate your errors. And once you have your errors, there is a feedback signal that gets propagated backward to update the different weight as we explained, so feed forward, build your AES, you have a bunch of functions that you need to build here. In this particular one becomes your output, you calculate your error, the function that you need to optimize for which is this one. And then you propagate it back with the sole intent on finding the weights that minimize your activity or your goal. Again, you could do it online or offline by using either some training some of the data points or all data points. Okay. While doing so, you have to be mindful that every neuron is a product of other neurons, and in itself, it impacts other areas. So if you're optimizing for here or here, you have to understand that there's a whole host of things that are happening. These are just explanation of what I've gone through initialize weights, choose input output patterns or training, propagate the signal forward to the network to compute your, your values, and then compute the error rate then propagates back and update your weights. Rinse and repeat until you know, you reach some, some threshold, some target goal will explain this with a numerical example. But before I go into the numeric example, when it there's, there's there are two aspects, in my explanation that I had not been specific about. Once you calculate your W use your new W because as we said in the past, is the old W you're dealt. So we have one factory, that's EDA, which we mentioned last time. And that is our learning parameter, which allows you to move smoothly over your search space, you know, like you have this kind of function an aid is is the length of the steps you take to get you, you know, solution. So you come here, then you go you find this if you're going up so you say no, no. I mean, if the step is too long, then that's one jump, that's another jump, that's another job. And then you're stuck. Or the step is too long or too big, then you may fall in some local minimum, or minimum, this step is too short, when you may take forever to reach a solution. So it's it's it's it's an optimization between a very slow conversion and, and maybe unwanted oscillation. Unwanted oscillation happens when, again, you have something like this one, that's not good. You have something like this one, you jump, you jump, then you come back in you oscillate between these two points, because the step is too big that you cannot reach your minimum here. So so that's your learning parameter. And then there's another factor that contributes to this whole momentum thing, which is this gamma. And the goal behind it is is is is to control the smoothness of how you reach your goal. So you have small steps or large steps So this large learning rate, you keep jumping, and this one is small you take forever. But if you introduce an extra factor, it may, it may lead you to the speed that you want. As well as controls the smoothness, we didn't have to do this sort of oscillation, or drunken walk where, you know, like, you may end up jumping here, jump back, jump here, jump here, jump back, take, you know, your solution issue. So, what it does, it controls your delta that of the past. And so instead of taking the entirety of the past to contribute to your present, you take only a portion of it in the contribution, so a portion of your new delta, and a portion of your past to contribute together. Okay, let's go into an example. On How To Apply back propagation, I think going through the example should help us just just get a good understanding of how the algorithm actually operates. So we said we have a neural network that has three inputs. These are the three inputs, they have two features. So this is feature one, and feature two. When imagine the neural network, it has two neurons. With you know, x one and x two, this happens to be x one and x two. So that's your neural network has two inputs, okay, and your, your y's, obviously, that's minus one and minus one. So our our learning function is a sigmoid. As a matter of fact, they made the mistake, you only have one extra input to having to have which happens to have minus is minus one, it was one minus one as an input, and you have delta 012. And you have your activation function, it's a sigmoid. It is a function of the input totally. So we don't have any lambda here. Now, obviously, you could have some lambda, we've never mentioned that. We've never mentioned that one, e minus eight, he could have some learning parameters. But you know, you could have it. There's nothing wrong with it, but he wouldn't have. Okay. So this is all new neural network, you have two inputs, you have your bias, and then we assume that that our mid our hidden layer has three neurons as well, two of which are fully connected, and one of them is connected the the bias, and then the output is yes or not. So we have one neuron in the output. Because we want the output to be either one, or zero, in which case, you didn't need a second set of neurons. Okay, so start with initialization, this is not normal that you have always set the same value that isn't normal, because it may land you in a very weird situation. So we set the weights to initialize all those 2.2 That's random say that the learning the learning rate, it is point two. We set the maximum tolerable rate to point or one which means if e is less than that was we didn't we didn't have a problem. Okay. And now we start we start learning. So, as you start learning, you apply the first input pattern which happens to be here. So this is the feed forward step. You have your feed forward stage, you have your target, and you have your weight initialized with so you do calculate your functions. You always hear base nourish realization. So your first your first function here is the same as the input. The second one is a summation for all three It is a summation of, of, of W three. So it's 101 or two multiplied by, or I. Alright, right. So summation of wi three eyes from one to three, multiplied by Oh boy. And that's and that's what you get passed, obviously passed by a sigmoid function. Again, this one. Now you do the calculation for all other neurons all the way to oh six. And this what you have four or six. And obviously, T is supposed to be supposed to be point eight, eight. So you calculate this one, given that it's different from so the target is point eight, eight, calculate you are now you, you can call it sigma, delta k or delta six. That's how you calculate it. Which is what we did here it gives you this value. Now you calculate, you back propagate it, so you calculate the, the other segments. Alright, so gives you sigma three, sigma four. And you keep back propagating, until you're able to calculate your different weights. And that gives you the new your new doctors. And now given that you've calculated your different new weights, you go on, you apply the second pattern, which always same process. And then you calculate the weights again, apply the third pattern, same process, then if you create the weights again. And then and then that, that, that that concludes on your first epoch. And now you check your error. And you find that your error happens to be greater than your maximum tolerable error. So you go on for another round, until you take this one all the way down. Okay. So this example is quite manual. So I suggest and then we've, we've skipped obviously, we skipped steps. So what I suggest that you take your time trying to solve it. And this will help you get a great understanding of how back propagation works. So we haven't mentioned an important aspect, we would pretended that we all know about it. But neural network is basically you have your input layer that corresponds to your inputs, you have you output layers that correspond to Ross but let's say that you have only one output. In between these two, your other layers, those layers are called hidden layers. So there are many questions that we need to ask about the hidden layers. How many hidden layers do we have? Can we have? How many neurons do we need to have in the in the image? But who gets to choose the number of neurons here? Who gets to choose the number of layers? What's the logic of its choose even the activation functions, different layers? There's nothing that says that every layer will have the same activation function as the past okay. So, who gets to make all these choice at the end of the matter, you get to make all these choices and the different choices you make as to the number of hidden layers may lead to different outputs may lead to different outcome. You know, I three hidden layers might be better than five or 2020 might be better than three. There are things that are that that you need to investigate this new problem space Now there are basic notes or remarks that you may want to listen to, if you're interested, you know, more notes doesn't mean better outcome, you have to understand that, for you to train every note, you have to have a lot of weights to be changed to be trained. And to train your weights, you have to have a lot of inputs. So having a lot of neurons or nodes, isn't necessarily a good thing it will have it will put a burden on you to find lots of learn training data, you know, or else, you'll just memorize whatever four or five patterns we have. But on the other hand, a small number of neurons is also problematic, because you need it, we all say yes, if you if you think in this biology, a person with loss of neurons, theoretically have the capacity to learn that's higher than a person of small number of neurons, it's a matter of capacity. So a small number of neurons means you have a lower capacity to learn a higher number of neurons put put a lot of burden on you. So we have a case study here, I'm not going to go through it. And I want you guys to try it yourself, where you have a you learning a function, that is y equal x sine x. So if you want to learn the function that is y equals x sine x, how many data inputs, you just if you take any number of x's and produce wise, alright, and you want to you want to learn to teach your network to produce this output. Okay? What is the proper configuration that you need to go through to make a proper approximation whether this is a functional estimation, right? Like, we know, whether you have a good network or not, because we know we're trying to approximate this function, try it out, try to build a neural network. What is neural network regressor, we're building a regression function, this is obviously not a linear regression function, that that memorizes or that mimics y equal x sine x. And you know, you have your table of access hash table wise, and use them for training, you know, and you know, has as many as you can, or you want, and then try new x's that you haven't fed in and see if y is indeed y x sine x. So trying to learn this function, and you know, try with, with, with different neurons, try with different layers, number of different layers and see and see, let's see what you end up with. Okay, so what are the applications of multi layer perceptron? Well, the application multi layer perceptron, it's everywhere, it could do anything processing and weather forecasting, senior compression, pattern recognition, financial market prediction, image recognition, voice recognition. You know, it's a multi layer perceptron. So there are classes of multi layer perceptron. So that our last wide range of application of MLPs have personally been fused in many in many, many, many areas. It's a handy tool, what are the limitations will have many limitations of it the biggest limitation to multi layer perceptron, which is something that people actually hated about MLP was basically it all it converges, converges into different outcomes. So you have the same training data set. And you start running you your your neural network, because you may start with different with different weights, you may end up with different outcome every single time. Right, because as you saw here, it's your initial weights that lead the whole learning process. And mission weights are what, what leads learning plus, so because you could start with different weights and you want to do that for training, you always mean with a different outcome. So maybe the outcome is great, maybe the outcome is bad. You may end up with 80% accuracy So you may end up with 90 and may end up with 64. Same training did you know, because you always fall in different local minimum and may never actually converge to a global minimum. So it may never find a global, a globally accepted solution, right. And then the higher than the non linearity of your system that you're trying to approximate, the more evident this is. So, there are many ways to go about it, you know, we're suggesting maybe you go with different solutions, but also, if you prove to increase the dimensionality of your data, if training data, this may not necessarily be a problem. So, one problem when you have a highly nonlinear system is not used Xi learning multi layer perceptron so good one for you, or maybe, you know, increase the dimensionality of your data, I have more features than you already have. So, this is a case study that I want you folks to go through as well. Just to get you a bit familiar and accustomed, with multi layer perceptron. And this marks the end of of the multi layer perceptron. For now, as we've gone through the initial presentation of it, and it being a multi layer perceptron The backpropagation learning algorithm how you know, the logic behind it, an example of how it gets executed. The next neural network is called radial basis function network, I takes a different take on on having multi neurons within the same network. So I'll break this video for now to make sure that they control the size of it. And then Welcome to part two where we discuss radial basis function networks


ECE657 Lecture 4 Part II
Fri, Apr 07, 2023 9:06AM â€¢ 55:20
SUMMARY KEYWORDS
function, sigma, transpose, data, activation function, vi, transformation, point, output, equals, input, class, centroid, neurons, find, solve, layer, linearly separable, network, minimizing

Hello everyone, welcome to the second part of the lecture we've discussed our multi layer perceptrons we discussed how the topology of them is basically a multi layer network a multi layer network where you could have a different we could have different number of of layers each of which is connected to to the previous layer by a fully connected bar by connections that have weights assigned to it. So, the second type of of feed for your network is called radial basis funk function network it's a specific category of feed forward neural network it is feed forward because the data moves from from from the input to the output. So, you have inputs then you have the neurons and goes to the output something like that it is fully connected as well. So, especially case but it is a special category, I will describe why it started when, when when, when when it was devolved as a method to mapping nonlinear behavior of status of static processes. So, that was it started as a way of mapping data from linear space from a lower space to a higher space. So, it can be moved from nonlinear representation to a linear presentation. So, in a way, not in a way in action design, it has only three layers has the input layer it has the output layer and only one hidden layer and that sets it apart from the multi layer perceptron because the multi layer perceptron could have as many layers as you need you want and you can train and configure. So, that's number one. one hidden layer number two, it's it's it's it's more it's more interesting maybe is that between the input layer and the hidden layer you have no weights no W's So, there is nothing to train here. So, the input is fully connected to the hidden layer without being multiplied by anyways okay. So, what happens? So, why do you have it hidden? Well, the hidden layer have some sort of a function that transform the summation of the inputs coming in here somehow. So, it has some sort of a function or some mesh that transform the mapping of those inputs, it doesn't it maps the the the inputs coming in here to a different format and the logic behind it is that data in lower dimension could be nonlinearly connected and if we raise them to hard dimension, they may this may lead to linear separation. So, you start with non linearly separable data, then you move them to a linearly separable space. So it applies nonlinear transformation. So, this transformation is nonlinear facilidad such that the data is linearly separable in higher dimension for those of you who are accustomed to support vector machines, for example, this is a similar logic and then from the hidden layer to the output layer, you have your normal weights. So you start by mapping higher them into a higher dimension. So map so map to a higher dimension. To find the separator on the separator I'm assumptions that in a hard dimensioned data will look like this. So you have a separator, which is also a function with W. Okay. So let's stay the things that we have. Before we go in on, on explaining in detail how it works. By the way, it's an interesting neural network. And it has lots of lots of interesting applications. So, if we go here, it's so this is the outputs let's say that output number one is w one, G one of x, w one, G one of X plus W two, G two of x plus all the way w n G of X. Okay, so realize that it's just these connections and these are different functions. So, the way oh one is you know, some mesh Wi Fi wi GI of x, or you could you know, and to this is I have one eye to GI of x all the way to L k if you wish like so, the way you have your, your your is transformation function or activation functional killer function named which were named. And they're basically tied to the input. So, every function represents a host of inputs as you see here and although as many function as you want, so, this is a choice you have and he was in and this is essentially m and n number of functions because it's tied to the input the input itself it's a vector it's so, every data input is a vector of features and then you have as many inputs as this training data allows you to have. This one is and so, this is your future vector and then you have your D naught and then you have your your output which is also a function of how many outputs you wish to have for how many points you have as well and last but not least, you have your weights which connect between your input your, your activation function and your decisions. So, if you have m activation function and K decision, then there's an M and K matrix. So, that's essentially the makeup of this particular network. Okay, lots of connections, create lots of things. Okay, so the goal is the goal is to map a nonlinearly civil let's let's try things I'd like to set the first G is a non non linear transformation apply to x function function nonlinear transformation function applied to x and the goal and the goal is to map is to map a nun This is very important linearly separable classes to a higher dimensional representation are different to a different doesn't have to be higher dimensional representation where you the classes ah linearly separable Okay, so do you have an example to that we've always when we want to talk about the class that are not linearly separable. Our best example is usually something like this one. Let's say this is zero and this is zero and let's say this is one and this one. If it if the if it if your if your inputs are zero and zero then your class zero inputs are one and one in your class is zero as well this is your x or function, right 1x or 100 or one zero is zero. Otherwise, it's one when you have data represented like this, there is no way to linearly separate separate completely between the two classes. So there's no clean clear linear separator between these two classes that are formed using something like perceptron you wouldn't be able to solve it other than something that looks like this, maybe it's very difficult to separate the two classes. But if we get a nonlinear function that transforms the input into something else, we may end up transforming the data into a play space in which they become linearly separable. And we have few examples of transformation functions GE could look like there are reasons for these different functions could do something like this you could do something like this you could do something like this in all cases, Miss Ark should look like so the function will consume X and transform it to a value and then transform for the transform to this value into something else. So let's choose this function for now. Okay, and We'll explain all the decisions that will be taken along the way. So this function has few unknowns that we need to deal with the VI is unknown. This two sigma squared is unknown as well. So for the sake of, of our peace of mind, we're gonna say, two sigma square equal one. But this is not just a random assumption, you have to ask why. Because also assume that VI are equal VI is basically v1 and v2, if we assume that we have two neurons in the middle, so we're gonna say v one equals 00 can say v two equals one, one. And also you have to ask why here, because these things can should not be a trend. So there has to be a good explanation behind. But now let me go through the example. So the inputs are 00011011. And the outputs 0110. And we have here two activation functions, again, we said we have two inputs. And we got to assume two hidden layers, two neurons in the hidden layer. And those are connected to I think, always say connected to an output. But anyways, we're not concerned about this part are concerned about this part. I assume that v1 equals 00, and v2 equals one one, so we can calculate G one and we can calculate G two for every input. So if you apply this function divided by one, you end up you'll end up with something like this one. This is obvious because zero minus zero, this will give you one here to give you point four and point four you could do the math, you know as well to check it point one and one okay. Now, this is the original space that they have. They have plotted here and this is the new space, or the new representation of the date. So how does it look like once I transformed let's take a look. So let's say this is point eight one point 2.4. Point 6.8. And one, so 1.1 that is one end point. One and point one heavy here. So we'll make that 0.1 and one. So point one and one. Weight. So which one is x? Which one is? That's all right. There's no correct point one and one here. Point one and one here, point four and point four here. And point four and point four here as well. So this is the 000 and 00 and one and one are here. And anyone you know, you could draw a linear line that linearly separable separate these two class. So we took the data from the Non linearly separable, two are linearly separable by applying these two transformation function just to make it a bit clean cleaner what we had is two inputs we had two neurons in the hidden layer we had think of it one output right? And this one goes this way because this way, this way, this way will you connect it W's here, this is we used an activation function here, another function here, this is G one, this is G two, this is the output X 1x. Two, we took the outputs here we converted them. And then by finding some W we were able to, to, to create this line The line is this is W TX I can add, I'm not gonna talk about the best, but this line is W transpose X. So just find the W that separates the two classes. Okay, so conceptually speaking, you can start from here where the data is not linearly separable, you can apply an activation function of sorts and you end up with something like this. So, how the math how does the math look like? If we were to model? Well, we need to find w. Alright. So, first order of business is to find w our output is basically W transpose g. So that's our output, right? If it is greater than some threshold, it is one of these lists and it is zero. So our goal is to minimize the the error which is the output minus output hat, or output minus g. So, find me w that minimizes this term. And this is this is an open this is this is an unbounded optimization function, which is fine. I mean, if we get to zero, that's great. And we should be able to solve to solve it by taking the derivative. Now, because we know there are some issues that can appear once we take the derivative. The minimization of this function is exactly the same as the minimization of the trace of the function. Minimizing the function minimizing the trace gives you the same thing. Why are we using trace? Well, we know there are problems that are going to crop up later, we use a trace just to get easy transformations. So, we need to break this one sorry, just should be squared. And to break it is going to be something like this all D transpose or G and then you open this one up. To get a much more clearer your breakages break down. So, the derivative with respect to W of the trace basically or transpose or minus g transpose W transpose g W then W transpose g minus So, this is positive this is negative but this transpose so it's gonna look like G transpose g transpose wo minus minus or transpose A transpose WT t, which is this one all transpose me teaching, okay this one is the transpose of this one. So GT wo transpose is all transpose W transpose g. So usually that's fine. Okay, this one is transpose this one, but transpose the trace of A is equal to the trace a transpose. That's why tres is important to you. So what we could do, we could choose one of them and just say it's too. So, new page derivative transpose or transpose or d transpose W W transpose g minus two, G transpose W. From these two we kept this one multiplied by two and now we're ready to break it down. So, this is not a function of w. So it goes to zero. All this is equal zero. So, you will end up with sorry, this is possible negative should be positive Yeah, negative negative positive. So you end up with with this quadratic, so to G G transpose W minus minus two v transpose w equals zero. So, G G transpose w equals g transpose w. So, w this is with respect to w here. If you following up with me, then you're an interesting part, you are an interesting position so, some of you must tell me in the discussion session to keep my notes and just copy from them. Okay, let's break this one down. So this one is to this G and then G transpose, then you have a w y two because it's quadratic term, right? Minus two the same as this one, it's all same as this one. It should be G or transpose. Very much hopeful that this is correct. Okay. So, G G transpose w equals g or transpose. So w, it's G G transpose inverse g or transpose g. Mean inverse Okay, so that's W, but wait a second. Remember that we said all hat is W transpose g. Right. So, all we need to do is is go and say oh, that is G G transpose is one G or transpose g. So, all hat like this Oh Ha is a function of all NG. So, in this term we do not need this term we do not need to have w as long as as long as you know as long as you know your this is all transpose as long as you know you know your G you should be able to calculate your output. So, this is a closed loop close form solution right if you get if you have your GS you already have your training data should be able to calculate your output which means we need to know G and that brings us to this conversation here about the topology of of the of the RBF. G is a nonlinear function that is supposed to have two parameters of interest for us one is Vi and the other one is sigma what we would like to do is to find a function that maps the distance between some x point and a central point and then process it somehow to produce the transformation. So, in a way a g function is something that has a central some centroid and some parameters that represent its width these are examples. For example, the Gaussian function as we said earlier provides you with a way that a central point can be calculated distance to centroid can be calculated and a width value can be can be assigned. So, now, G to find G you need to understand how it should look like right again, it has nothing to do with the calculation here. This is a close for calculation. So, there is no mathematical trick that we should be interested in, per se. So, let's go back and examine few possible GIF, you know examples of a kernel function or an activation function or transformation function So, this the first one that we've mentioned earlier that is ours. So it has our test signal and some constant that is greater than zero this function looks like this this is a problematic function because it could go all the way to infinity. So it can explode and you may want to say okay for me not to explored we'll just have it look like this and this way the function is simply going to exploit in a way there's there's a concept there that it's doozy but the function that was most attractive to the researchers is something that looks like this are this is This function was attractive because from just from just perspective of how it looks like it looks like this so it is a smooth function. The end it takes takes forever to just go down to zero smooth, you know, you have a clear control over its width has a good representation of the central, the centroid. So it allows you to control the center of over control, if you want to build a control, it also tells you how big and small the control is. So just to make sure that x happens to be within that width, so that's an attractive function the Gaussian function and because the RBF networks utilize the Gaussian function, we call them radial basis function, so the radius space and they usually utilize those Gaussian those Gaussian activation functions. So, all first decision in this particular instance is to say, well, our first decision is choose the Gaussian function or your G. Okay, so this is what we're going to go with. Now, it's because Gaussian two sigma squared is important, but in this particular example, we're not doing any distribution of sorts, so we'll just represent it to be sigma i, okay. We just want this equation as this. We don't want to calculate anything in particular. So what do we have? We have two things we have VI and we have sigma. And the question is how to find VI. Sigma we said those two things aren't assumed at random. So how to find and similar to say how to find G, let's first say what is sigma what's VI? Sigma is the width of the function. So let's say sigma equals to your functional looks like will look like this it says sigma equals one your function will look more like this. Let's say that sigma equals point three your function will look more like this. So the function shrinks the width of the function shrinks with sigma and that's why it's important to choose the right value for it. And why is it important? Here's an example. So let's say that we have one dimensional data set and we have data that is belong to class red or class here and for whatever reason, we found an academy function that that's that draws like this okay, to means when we project the data, it gets projected this way. When your data is projected this way, you could literally find a separator that looks like this. Alright, so where are they with comes Why is with with import is why is that important? Let's say that we have something like this x 1x two and x three, okay? And we are going to be representing them with kernel function that are white. So why it can function very wide. What happens is that every point is multiplied by this peak, that's, that's meets it. And based on this representation, it gains momentum. So when you draw it, why you, when you draw this function, you draw something that looks like this. So it goes up, then goes down, then goes up again, because this one's close, then goes down, then it goes up again, then goes down. So the shape here, control that over all separated. And if you do it differently ie by choosing a shorter, smaller sigma x 1x 2x, three, say that our sigma is fairly small, looks like this, then there's nothing and then there's nothing. So when you multiply it you may end up with something like this goes up, goes down, down, goes up again. Because down, down, down, goes up again. Okay, what's the meaning of this one? Well, the meaning of this one is that if there's if this these two are fairly similar, they belong to the same class. If you have a debt training data point that is here to be misclassified, same with this one, if there's a data point here, you still want it to fall here. If you have another point here, you still want to fall here or here or here. And if the line was a little bit below can also fall here. So you need to be able to create some form of generalization where new data points can be also projected and classified correctly. So that's usually a pitfall of choosing a wrong signal. Okay. How about we I will VI is as you said it's all interested in having a central point. Then see whether our X falls within the radius so what all we need is central point. So reality of the matter you need if you have m kernel functions you need em central thing centroids are central points. So you haven't an M G's, you need an M centroids. Which does make sense if you think of it. So the question is, okay, we've we've established that so how do you find our central points? Well, it's actually not that difficult if your data looks like this something like this facility like this anything. And you have you decided that you're gonna have fun for colonels. All you need to do is to run clustering algorithm to find for Synthroid, for example, Kmeans gives you Oh k centroids you know, one centroid here and one centroid here. Once employed here, one centroid, the nodes are five, I'm gonna, I'm gonna do this one gives you four centroids. And that becomes your v1 or v2, or v3, and your v4. And you could use these in your, for heading neurons. So that's so for VI, that's an easy way to get it just get the clustering algorithm and choose m data points, or m v points that represent the centroids of your data or M centroids of your data. So that's so for G because G has g has vi n sigma VI is found through clustering. How about signal? Well, we can always go back and examine our problem from the very beginning. And our problem is basically all hat equals delta transpose g alright. And our problem is to minimize this error or minus this is what we use to solve for W segment find me w that minimizes this one. So, this is our problem. Okay. So let's see, let's do the following one initialize sigma. So, start with any value of sigma and find VI. So, initialize for the sigma and you assign the IBSA in on a clustering algorithm to solve for W from this minimization problem, as we've said earlier, which is all had minus or minus g, so, finding this W three, so, now you have w. So, for this equation for sigma from So, this is known and this one is the exponential of over sigma. So, for this one you're solving for w, so, remember, this is fixed, this is fixed. So, g is known, G is known, alright G is known. So, you can find w now, all is fixed, W is known, x is known, Vi is known. So, you can find sigma and repeat repeat the alternation between two and three until some error criteria is satisfied. So, in a way This approach allows you for me things it allows you to find your W once you fix one you initialize sigma and once you find your W you can find the sigma that improves the also you alternate between solving the or minimizing the error due to W as well as minimizing the error due to sigma. And not just that, keep in mind, this is doesn't have to be one sigma, this could be a victor of sigma, right? Because then, so the R is Victor, v1, v2, v3 v4, there's nothing that doesn't say that you have sigma one, sigma two, sigma three, sigma four, etc. There's nothing that says you should have the same sigma everywhere without multiple signals. So it depends on you in the complexity of of what you're presenting. Right? You could end up with as many segments as these that you have to find me the victim of signals that minimizes this problem. And this, and this gives you a fairly good solution for for for finding, W and finding and finding and finding signal. So this is the math that we've gone through. I'm sorry, I said, Oh, here's that. So in case you're confused, the equals Oh. This is an example. I don't want to go through it. You folks could go through it on your own. So what are the remarks that are advantages or disadvantages that we have from radial basis functional? There are a few things. The answer provide stage of the B if n is not an easy task, or a identifying sigma and Vi is not an easy task. And that's why we wanted to do it. To do it in not just VI and sigma just by itself is through clustering algorithm. So depending on what in your clustering, you may end up with a very interesting outcome. So I said K means but but by no mean. My no means k means is the right approach, or the ultimate right approach, you have multiple approaches out there are the if in terms of training trains faster, because it has open closed form solution, so it's training faster. However, once it's done, its execution is way slower, because you have lots of you have the nonlinear transformations, when machine will multi layer perceptrons is a multiplication of WT by x at every layer. So it's straight up multiplication, there is no linear nonlinear transformations. It does have a universal approximation capabilities, it's really, really a good function. And it can be used for complex processes to solve wide range of classification problems. It's been seen to use flow control systems for communication, some of the applications for communications, or RBF network seem to fit to be very good for decision making. So there are lots of applications for RBF networks, you'll find it used especially as recent in chaotic time series predictions. Especially when we're talking about weather and power load forecasting. A measure implication of using it is maybe the need to have a lot of hidden nodes or neurons. Because remember, you're trying to map your data into a nonlinear into a higher dimension. So you may end up having more if you have 100 features, it doesn't mean makes sense to have 100 hidden neurons you have you need to have much more. So the number of hidden neurons increases exponentially as the number of features increases. And and that can be also a challenging aspect when it comes on this training, but also to execute it. Next week, we are going to be discussing Kohonen self organizing map networks are self organizing maps. These are interesting class of neural of neural networks, that that depart from what we understand normally about you know feed forward connections, neural networks that solves you know, classification problems. This one is much more geared is towards clustering versus unsupervised clustering, unsupervised learning, localized learning, so on and so forth. So it's an interesting class of problems. And I'm excited to tackle it next week. Thank you and enjoy the rest of your week weekend. I've always wanted more


ECE657 Lecture 5 Part I
Fri, Apr 07, 2023 9:07AM â€¢ 1:14:40
SUMMARY KEYWORDS
input, neuron, output, clustering, features, updated, weights, similarity, neighborhood, dimensionality reduction, point, winning, represent, map, self organizing networks, reduced, triangle, dimensions, networks, winner

Hello, everyone, welcome to our second class of neural networks our feed forward feed forward neural network. And that is best known as self organizing map or Kohonen, self organizing map self organizing networks as well as multiple titles. So the discussion today is going to be covering two classes of networks, self organizing maps and a Hopfield networks, to extraordinary interesting classes of networks, for self organizing networks, they do belong to a class of unsupervised learning networks. So different from everything that we've done. So far, this particular class of networks is unsupervised, so we don't train the network on identifying certain output. Now, before I delve deeper into the self organizing network sources for guys maps, there are two subjects that I've, I've just I've mentioned in the past. And I think I need to elaborate on this is not part of the course material. So if you want to skip forward, you can skip forward. And the first one is going to be clustering. And the second one is going to be dimensionality reduction. Again, if you have if you have a good understanding of what these things are, you don't have to, to hang on for this part of of, of the lecture. So let's start with clustering. Clustering is a problem of identifying similarity, or dissimilarities, you know what is similar. And what's not. For example, let's say that we have, you know, three objects, triangles circles and squares. Now, you don't know that the triangle is a triangle, you didn't know that the square root square, he didn't draw that circle that circle, all you know is that you have a bunch of objects that are represented by features and you want to see if there is a way to group them together, because they look similar or because the groups merging are very dissimilar from from the other groups. So maximizing similar similarity internally or maximizing this similarity. externally. Clustering is about finding that clustering is about identifying this group, this group and this group. And the statement of this edification is basically that internally, those triangles are extremely similar. And externally, those triangles and squares or triangles, and circles are very dissimilar. So enter similarities maximize external dissimilarities maximize as well. So, in a way, it's a it's a, it's an optimization approach to identify similarities and dissimilarities between between a variety of objects. A common or a famous technique for doing that is called K means as we've discussed in the past, when it comes to the RBF. K means operates by identifying how many clusters you have. So somehow, you have to say I have three clusters. If that's the problem trying to solve and what K means does it basically As and by the way, same goes to clustering, it's unsupervised learning. So what K means does, it takes it finds random, it finds random points, like it's throws random points, the number of which is predetermined. And and it starts calculating pairwise distance between each point and those centroids of central randomly initialized central points. So for every data points, you calculate the width pairwise distance between them, and those randomly initialized centroids. After that, you see you check, you assign the points, you assign the points to the cluster to which they are closer. So in this case, here, this triangle as closest to this point, so you say this triangle, I need to do some ambiguities here. So I'm gonna say there's a point here just to make it a little bit fun. And then you say there's a point here. So, you check where the points are closer and you saw you start assigning them. So, you find this cluster of data points here. Maybe Maybe there is another clusters of data points here. And potentially the 30 clusters of data points here just just in the account of of how close they are to the centroids. Now, the next step is to recalculate the centroids. So, you have a centroid here, you know, the central point between all these triangles is somewhere in the middle. You have a large group of triangles here and small groups triangles here in the centroid B, you know, maybe somewhere here, closer to the center of gravity for these ones, potentially, the centroid would be here playing all calculation of central points, sum all numbers and divide them by their count and that will give you the central points. Okay, so now you do the calculations again, in terms of closeness and you find that all of these points belong to one cluster, all these points belong to one cluster, all of these points belong to another cluster. You recalculate your midpoint, you find it to be here, find it to be here, find it to be here. Any further rounds of calculations will not change this makeup, not significantly anyways. Which means that you've converged. Now, in the past, especially for RBF, this becomes your V one, this becomes your V two, this becomes your V three. And that's an example of how clustering operates. You know, you have predetermined number of clusters for some techniques. And then knowing the notion of similarities and dissimilarity. You start optimizing this similarity here. It's taking my calculating the pairwise distance between the points and this foot. So that's how we define that they are dissimilar. So that's class trick in a nutshell. Again, it's it's intended to be very quick. So I know I've lost over some concepts. The second concept I would like to go over very quickly is dimensionality. Reduction. dimensionality reduction is when you have a Multiple Dimension Data Data with multiple dimensions. This example is three dimensions. So it's not really a problem to reduce from three dimensions to the dimensions, but you get the point. So if you have a three dimensional objects, and we'd like to reduce it, what we do is basically, we try to reduce to remove as many dimensions as possible, for example, this cube, you could represent it, depending where you, if you're, if you're looking at it from this angle, to it be something like this, to be something like this, this is how it looks like. If you look at it from this angle, then it may look like this or maybe from this angle, then it would be similar to this. So what happens is that when you remove a dimension, you're losing some form of information. But it is attractive to us to reduce the dimensions because we may want to visualize so for example, let's say that you have lots of data points that have you know, five features and asked you to visualize them there is no way to visualize those five features, there is no way to draw them on a three dimensional plane. So then what dimensionality reduction does, it allows you to process those features to be able to visualize them in three dimensions or two dimensions. But be careful, you cannot just be dropping two features at once, there has to be some logic behind choosing which features to drop, which features to keep. So the most information is preserved. For example. Let's say that what we're having is a face you have a I've never been known for being a great artist. Yeah, the ears change the price. I didn't know. Anyways. So that's it knows, I think a lot of you have beards, maybe it's a guy. So I think I'm trying to draw my face and I'm failing miserably at it or succeeding. So, the number of features you have here is logically speaking, once we maybe one if we think that the eyes are two together one feature so the eyes represent another feature the nose, third, mouth fourth the fifth shape of the face six. Now obviously this is oversimplification, ears, seven. If you try to reduce that to three dimensions, for example, it means you're going to have three features, you really do not want to end up with something that looks like this which is an extraction of the ears, the nose and the mouth or something like this a much better but you know you get the point. So somehow the dimensionality reduction is you take this multi dimensional object and map it into something that is reduced in dimensions, but maintains information. So you end up with something like this not over the hair maybe you have the EU. And the logic is basically the logic is basically that maybe all these three features gets combined into one feature, maybe those two features get combined another feature, maybe these three features also get combined into a third feature. And somehow when you draw them in a two dimensional space, they get to something like this, which is very similar to the original object. So a successful reduction of features from the current state to a much lower dimension. Why is it retaining as much as much information as possible, is the goal behind dimensionality reduction. So of clustering, where things that look alike, are clustered in similar groups of dimensionality reduction, where the actual dimensions are, are reduced with, with a new feature, space, that retains as much information as possible. So now, that takes us back to self organizing maps. And self organizing maps have an interesting history. And the history is around clustering. And it's around dimensionality reduction. So what's self organizing map, it's an unsupervised learning network, it learns without a need for a teacher or really knowledge of the the output. So in a way, you didn't have, if this is your target, you didn't have axis, this is your output, you'd have an axis to our target with which you compare it. Remember, it's a neural network, a neural network where you're not comparing with a target, but somehow you have some work being done to adjust weights and you know, and digest weights and and based on the behavior. So you're learning behavior, and you're adjusting your weight based on that learning process. So it's an exciting subject obviously, because it just it touches on the area of not needing a teacher of sorts. So, self organizing map started, started early on in the 60s of the 20th century, and was first presented in in a very interesting publication by will will I'm sorry not by Wilshaw and and then on Sure, I am malzberg I am butchering their names. But anyways, so those two researcher had had an idea of having two sheets of papers you know. connected to each other somehow. So, they have some form of neurons. Now a reality they aren't neurons, if they didn't, did not use the term neurons in their paper. It just what happened later that makes me call them neurons. So, just for historic accuracy they did not reference neurons in their paper, I suggest that you folks go read the paper. So they have inputs. So those are your inputs. Those are your outputs. inputs and outputs are, are exactly the same. So they are identical in terms of numbers and dimensions. Okay. The logic says every input is connected to all outputs every input is connected to all outputs when you could think of this as presynaptic layer, you could think of this as post synaptic layer. And you could think of those of these one of these ones as a bundle of synaptic connections and the logic says that this input for example, although it's connected to all outputs it will either excite the outputs or inhibit the outputs. So, there's there's, there's a process of either excitement or inhibits inhibitions. So, what excites the output, it will be exciting a region of the output, so, those neurons for example, will be fired. So, there is excitement here. And those neurons here in this region may be may be inhibited, so, they didn't get fired. So excited some you inhibit some and the smart or the interesting concepts that by the way, this is all concept, this was no math, just a concept. This the interesting part of this concept is that the saying if another input is connected or not if the other there are other inputs that are also fully connected to all outputs. And they behave, I'm gonna change the color and they will behave similarly, in a sense that they will also excite few neurons and inhibit other neurons or other outputs. So, this input here into interesting, interestingly enough, may be may excite this region so far are two inputs that are far from each other. And their original states in the original space or domain may end up exciting outputs that are regionally or topographically, close to each other. And that's why at the beginning, we're talking about maps having a map at an input that's been mapped to an output, but we arranged such that they are, they are, they are close, you know, better visualization might be you have an input space here that has y and Zed and has x here. And somehow once you've mapped them into the upper INTO this to this is the pre synaptic once you map them to the synoptic layer, the x and y and Zed are grouped together. So that's that's basically the logic the logic behind what what we'll show and, and and then there malzberg had done one, but they had no math, no significant math to show how this mapping will happen there was no major inspiration for neural networks, it was it was just really good IDF about mapping an input to an output with changed arrangement. And that remains to be the case for some time until a researcher from Finland Finnish on a researcher that goes by the name of T Kohonen. After which this is named, came up with a much more nuanced idea of self organized feature map or network Kohonen had drawn inspirations and again I suggest that you read his paper had drawn inspirations from perceptrons so he's explicitly talking about perceptrons he's explicitly talking about connections and, and weights so, now, we enter the realm of networks where we have inputs we have fixed that's another thing that's been used distinguish Kohan self organizing networks from others of fixed dimensions and some form of discriminant. function so let's see how Kohonen self organizing map is inspired, how they operate, what's the logic behind them and what's the math so Gohan self organizing maps they retain a whole lot of similarities with with the previous with their previous incarnation whatever the first incarnation so you have you know, the postsynaptic layer the second sheet remains as it has however, fixed dimensions for example six and four. So it have 1234123456. So, this is this is fixed regardless of the input of the input of the input dimension and again there are some conditions that governs that but for now let's say that and we have an input and that input is again fully connected fully connected to the output. So I make these connections Some students do appreciate them some students didn't appreciate them. But I find them to be quite useful for understanding the LOGIC Series. So, input output your wondrous uptick of synaptic connection That's your input. The input itself is the feature space. So let's say that you have, you know, let's say that you have x being your inputs, and you know like yeah x one 1x one two all the way to x one D and goes all the way to then so this feature this entrance, this is x one represent in its entirety your input and the way it works, it's basically tries to map this input this features paste input that's in three dimension in d dimensions. So it's D dimension input to only one neuron in the output only one neuron in the output so every neuron tries to see its similarity with the input, how to get out our similarities with the input and based on that, they start competing with each other and then your own that has that has the highest similarity is the winning neuron. So let's say for now that certain neuron X is winning or I saw a neuron I hear is the most representative of the input, I will give you an example of you and you'll see it in a much easier way. But let's say that this neuron is the most representative of the so you have an A d dimensional input that is represented by a one particular neuron i Okay. So that's a mapping input to an output. Now, let's say there's another input that is also fully connected to the you know, fully connected to the outputs. Okay, and let's say for the sake of argument that there are many options, the first option is that neuron i also is a strong representative of input to at which point this neuron now represents two inputs. So that's one possibility. One one possible outcome. Second possible outcome is that there is another neuron maybe here and it's called J. That is also represented representative. That's us, that is the representative of input to so another neuron wins. And the more input we get in the more inputs we get in the more understanding we have, so the neurons compete with each other who looks who represents the input the most. And every round we have a winner. Now, since we said we have a winner it means there is a reward. So if if you are the most representative of the input, then your weights gets updated, obviously, so this the weights here and two other end post gets updated. So you get your weights entering you updated to represent the input the most, and so on and so forth. So every single time and you're on wins, they get their update up there, get their weights updated, which means they get rewarded. And if they don't, if they don't win, their weights don't change. So you reward the winner, and you leave others and rewarded. And that's basically winner takes all. So another logic here is winner takes all. So let's get to a good example of how you know how that looks like. Give an example. So let's say that we have a notice how I focus on the upper sheet or the postsynaptic first, because this is the fixed part such as a three in of in three, so you have three you have nine neurons and you have an input of source that is, you know, as I said, fully connected. Okay, and that input has four features, switch one, switch to switch one 3x, one, four, so four features input, you have three and three map. So how do you represent this? Well, it's actually not that difficult. We said it's a neural network, right. So what we do is that we have the input that's the input that has four features. And we have the outputs that is three by three which means has 1234567899 neurons and they are fully connected. So the input is fully connected. So one aspect, this is a feed forward neural network, it's fully connected feed forward neural network. The only difference as we stated that, it is not it is not it is not trained. All right. So this is your input. This is x one. This is x, one 1x. One 2x One 3x One four, or maybe make it Aye. Aye. Aye. Aye i This is just an input patch. And this is your, your output 12345678. Not nine, for example, this would be one, and this would be nine here. This is one and this is nine and this is maybe three here I'm going through this process to be to understand how this is represented by this. So what do you do? Well, this is a bunch of these are lots of connections here. There's many W's here. This whole thing is W many W's. Alright, so every neuron so let's take this neuron for example. It has It has three weights, four weights coming into a trace from four inputs. So 1-323-431-2333, I'm sorry, on four, three. So this point has those weights are coming to it. So there's the input x 1x 2x 3x, four, and there's the weight. And the value of this one is determined based on some similarity measure. Let's say that we that the output is something like this W transpose X, okay, and you calculate the value here. So let's say that we want to get the maximum we want to calculate the maximum never transpose x, you start at random initialize w, this is this is an input, so it's a given. So all you need to do is just calculate the values here. And let's say this is 10 513 1417 1129 30 to 36. It depends on your function, if it is maximization, this neuron has the highest or the maximum output, so it has the W that maximizes the output. So this neuron, neuron number neuron four is the winning neuron based in this particular discriminant criteria, so this is called a discriminant function, it discriminates between the different neurons. Because it's maximization the higher, the better. So this is your winning neuron. So what do you do next is you update the weights. So these weights need to have to be updated as a reward for this particular neuron, because it had one How about the other neurons, nothing's changed, because they had lost this is the concept of winner wins all or winner takes all winner takes all is literally winner takes all by getting their weights updated. Okay. So what do we mean by getting your weight update it? This is important aspect, right? So we start we said you initialize your weights. You calculate some discriminant? Some discriminant function three, no, you could say determine winning winner four update weights. Winners weights. So the discriminant function is interesting, because what are we trying to do? Either we're trying to maximize? And here's the comeback to clustering, similarity or minimize this similarity. So maximizing similarity would be you know, to maximize W transpose X, minimizing this similarity we'd be minimizing x minus w ij. So, either maximize this one or minimize this one. This one this function is not attractive to us. I mean, it's it's great to describe the logic. The problem is that it isn't attractive to us because it's very difficult to go from here into it updating while this one has some interesting characteristics to it. So let's see how to update weights. Well, first, the load the previous rule always apply the new weights of the winning note, or neuron is the old way it added to it some delta. So the question is, what is dealt? Well remember, we're talking about a winning neuron that represents the feature. A represents the future here means it looks very similar to the features. It has an uncanny resemblance to the feature, how much and can resemblance will? Let's take a look at this one, what would be the best outcome for this particular function? And know that minimizes this function is a node that brings this function to zero, right? So this is the absolute value of difference, and the minimum value is zero. So if x is value is equal to the weight, then you know, this node is going to give you the ultimate global minimum value. So to reward the weights, how about we'll bring them to be equal to x or close enough such that it's truly the representative. So we say that w delta w, is, you know, the missing number between X and W. But hold on a second. Didn't you say here that this winning node could also represent other inputs? Which means they have other features? X 1x 2x D. And, obviously, Ellis it's it's, it's completely, obviously, unless it's completely coincidence, there are no no two rows that have the same value don't have two inputs that are exactly the same. So don't you risk by changing w to be exactly x that you will never get a situation like this where you have two inputs represented by one output, especially that the outputs are limited. So one output has to present a lot of inputs. So that means we have to put some penalty here, such that delta w is close enough to this value, but it isn't exactly the same. So this one is less than one obviously. So now the new weight will be very close to x to the input x at this particular iteration at a Okay, so now let's go to an actual numeric example, which will help us you know, understand all of this together, and hopefully, you know, shed some light. So, this is what I've been describing earlier. Step one initialize all wait, choose an input pattern, select a winning unit, update your weights, and then the learning rate is decreased. We'll talk about that later. When we talk about now. Let's talk about now. So this weighting, learning rate actually isn't fixed. which means at some point, your delta w shouldn't be changing a lot. So we said, at the very beginning, you want to reward the winner a lot. But if you keep rewarding the winner for every new input a lot, then you may end up with it losing if you rerun the experiment. So if you see here, the only reason this neuron won at the beginning is that the weights were very close to the input here. So if I, if I change it to be to be close to this one, then that's fine. Now this neuron is closed. So I updated to be closer to this one. Sounds closer to this one, but it resembles this one as well, because this the small starting point, I mean, input one, now a new data points enters. So again, this neuron is closer to it. So I updated the weight a lot, maybe. So what you end up is that if you go back in time, and you compare this neuron i with the first input, maybe it wouldn't be the winning one. So what you need to do is that, as you train, the degree to which you're updating the weights starts going down. And this is why we have a term here, that controls the value by which update alpha k. So it still starts going down as the number of cycles increase n where k is just here is is is is is the value of of the current training cycle. So that that helps you not have confused, not having oscillating in performance. So here's an example of self Kohonen self organizing well, so we have four inputs, x 1x 2x 3x, four, every input has four features. And an X maximum number of clusters to be four is three. So because we set the maximum number of clusters to be formed three, have almost defined that the feature map has three neurons. Okay. Our learning rate as a first iteration is point three, and over time and decreases by point two. There's a discussion here about neighbors and neighborhood. I'll discuss that later. But for now, we're saying there is no neighborhood. So we have three outputs. And we have an input layer that has four features. So a much more simpler than this one where it's essentially 1234 connected to three. Okay, so what do we do, we start with some initial weights. So these are initialized, obviously, we didn't have neighborhood and we have an initial learning rate. And we do the calculation, the calculation is competition at the beginning. And the competition here is by calculating the Euclidean distance between x and between x and NW or the square error between x and w. So, the value of w e 4x. One is point 2.3. So, this is x one. I'm sorry. This is for output one, output two output three. So, point 2.3 point 5.2 point 3.5 point 1.4 point two point 3.1. And the last is the loss. So, for the, for the first input 1110 You do this calculation, so x minus w squared and you sum them up And the one that has the lowest this similarity value is the winning, which happens to be this one. So what you do, you update only the weights associated with this one. So all these weights get updated. So 1234. Now, only the weights for output number one gets updated. So you update them as base pair, the logic the original weights, plus the den, point three is multiplied by the delta. And those are the new weights. And now you input the second X. Obviously, the new weights had been updated, the the weights for output one has been updated. So they are now used again. And you calculate the discriminant output, and you find now it's output two, that is winning for the second job. And again, it's weights get updated. So you update the weights for output number two, now input, you get input number three, and lo and behold, output, one now is winning again. So you go ahead, and you update the weights for output number one, remember, this is still in one cycle, first cycle we haven't changed was to go in for cycle, which means our alpha remains point three. So you update the weights again, and you go in input number four, an output number three, in this case, is the one that is winning. And you updated sweet. Now, this is the first epoch. So you go to the second round second epoch with reduced learning rate. So you repeat all of this, you repeat this entire thing here. But with reduced alpha, which means potentially, that output number one would not win again. For input number one for x one. So you repeat until delta w becomes steady. So for every output, delta w, J doesn't change, or this alpha will just go to zero which effectively means delta w will not change. Okay, so you go on and on and on and on until you have your final output calculated. So now we've mentioned we've mentioned that there is no initialization he said there's initialization we spoke about competition and we said in competition winner takes all is that all like is there anything else that we can do that doesn't necessarily confirm with the logic of the winner takes all well, he could introduce the concept of co operation which may challenge the whole winner take takes all thinking process. So how does it work? Well, you start again, you identify your output layer. Now, I use two dimensions to the one dimension that was presented in the example. And now as explain a cooperation to make more sense. I know you have your outputs you know being neurons in winner takes all depending on how many clusters you have, only those neurons will win. Alright, so the number of outputs has to be how many clusters you want 345 But in when we do cooperation, we don't need to do that. What we need to do is to identify a certain neighborhood of neurons. So every neuron will have some sort of neighborhood So, first let me let me refer to our previous example. So, early on, I discussed that what we what if you have three clusters, and they happen to be triangle square and a circle, your first input belongs to a to a triangle. So, the winning neurons happen to be here somewhere the second triangle comes in and this is the winning neuron, a circuit comes in and this is your winning neuron square comes in and maybe this is your winning neuron. So, so what you do is that, once you identify your winner, you don't say that winner takes all you cooperate with a neighborhood. So, for example, for this one, you identify that this is my neighborhood, for example, could be a big neighborhood. And you say, every neuron within this neighborhood will get their weights updated. So, reward all neurons in neighborhood so, you identify your neighborhood and when you reward the neurons, now, some neurons might fall within the boundaries and the overlap, right, so they get if this one is triangle and this one is, is a circle and this one square, if the square wins, they get rewarded with the circle when they get rewarded, right, which is fine, you need some sort of overlap between the regions. But the closer you are to the center of the region and the center of the region could be you know, two or three neurons, i Those are the ones that represent the triangle the most. And the center of this are two neurons that represent the circles the most and so on and so forth. So, in this particular product, we start with some random initialization, you go with competition, you identify a winner, and you reward its neighborhood. And then you you have any new data input, you define a winner, and you reward its neighbors and so on and so forth. Hopefully towards the end of your exercise. This map will be representative of regions reflecting whether it's square, or circle or triangle, which means you allow for difference within triangles, you allow for difference. Within circles you allow you allow for difference within squares. So instead of this example, where we have only one output, only one output potentially representing two or three or four inputs, or 10 or 20 or 100, because that's a clustering, you may end up with a group of with a neighborhood that is inclusive enough to the degree that it it to the degree that it will accommodate a large number of inputs. So that's the concept of cooperation in a nutshell, but there is more to it. So, what are the things that you do to construct a neighborhood? Well, there are many things first, are we going to be updating the weights and the past weights weights were updated you know old weights plus delta W and delta W was equal alpha k minus ij. Could be could be absolute could be square but only for winning only for winning Juran. Now up, which means it's it is one. If we say there is a value here, it's called H ij of k, this value is one for, for winner and zero forest. Now, we didn't do this way, now we actually assign various values to the, to this neighborhood function. And it's a, it's like here I had an example of neighborhood being a Gaussian presentation. So let's keep with that, and say that we will calculate the square distance of something, and divided by a sigma value. So let's take this value here. So the distance is between the winning the weights of the winning neuron. And all data points as long as belong to the neighborhood. Which means if you are close to the center to the winning neuron, then this value goes up. So let's, let's have an example. Let's say that it's what wi minus wi the same winning neuron and this value is zero, then this becomes what. So, it starts with one all the way to zero and starts to degrade, and the further you are from the central point from the central point, the less update you get. So, that is number one, all right, if you are way out, then your delta w is zero. The other aspect here is sigma, which tells you how far or how big is your neighborhood, this is an important aspect. If your neighborhood is you know, sigma controls the width of your neighborhood here, that's how big your neighborhood is. So, the value of sigma if it is big, then it covers a lot then you know you reduce it to explain it looks like this, then you keep reducing it then you keep reducing it until maybe just central becomes one pulse over the winning neuron. So, the value of sigma controls this the weight of the neighborhood. Now, since we said that, we're constructing a neighborhood and we want to progressively stop updating a relevant neurons to only make sense that sigma two alpha is reduced by some calculation like this as we said earlier, alright, sometime sigma should also be reduced by a similar calculation. So, over time, the neighborhood starts to converge around the central point, so you're only rewarding the central points. So, this whole concept of neighborhood means, as a beginning your generous you cast a wide net a lot of neighbors you have and then over time, you you go smaller, smaller, smaller, smaller, smaller, until you you you end up with your core neighborhood think of an of maptive as a heat map, what's the most if darker means means more presentation and the edges are lighter, then then then the central point will be the darkest and the edges will be the lightest and maybe you have transition from one region to another. So, what we will end up here is basically a function that decreases the change over time naturally and has a decreasing size neighborhood over time as well naturally, as all input starts to converge to core regions. So the this these borders that are overlapped depending whether they are actually border of closer to a centroid they get dropped. So if you're if it is a porous border of what it is a certain square, then gets dropped. out very soon. So the squares don't update this border. But we have, it's closer to the central point of the circuits that gets updated for much longer. So over time, you are updating the neighborhoods, as well, all the way up until you're only updating this in 10 Point anything by that time, you've ended training, your your, your self organized map. So again, the steps are six steps, initialization, let me go back. Now six steps of learning. Step one, initialize, step two, choose input pattern, step three, select winning unit, step four, update the weight. Step five, the learning rates and the neighborhoods are decreased. So it's updating your neighborhood size in a learning rate, and neighborhood size. And step six, you know, keep running until you reach a threshold of sensitivity. So those are the six steps of teaching self organizing maps. Now, I said six steps. So I'm going to add another technology, this is very important. You have six practical steps. And three practical stages, stages initialization. Competition, and cooperation. So sometimes when we talk about stages, we talk about these three stages. When we talk about steps, we talk about the steps that represent these three stages, I know use stages and steps, they are not the same steps are these steps, these stages and steps are these four mentioned steps. So what are the application for Gohan self organizing networks or self organizing maps? Well, that many applications, it's basically a clustering approach or clustering algorithm. So you know, if you have a clustering problem, it will work for you. If you have also dimensionality problem, it will work for you. Now, I'm sorry, I've mentioned dimensionality. But I've, I haven't explained how you do dimensionality reduction. This example, you'd have a lot of inputs. So you have a lot of emphasis, you have a million inputs. And four features, all of it will be represented by a three by three matrix. So you take for a million by four, and it ends up being represented by a three by three matrix. So that is the dimensionality reduction at its finest, whether it's two dimensional, or one dimension, like this example here, we reduced this example here, we reduced four by three by four right? So it's four by four to one by three essentially. I those aspirin neurons. Okay, so this is the first part of today's lecture that discusses Kohonen, self organizing networks or self organizing map. The second part that we'll be coming to, we'll be discussing Hopfield networks. And how this this interesting class of networks had opened a much better association between bio neurology and and machine learning by tackling the concept of memory, the concept of memory essentially. So see you in part two


ECE657 Lecture 5 Part II
Fri, Apr 07, 2023 9:06AM â€¢ 56:35
SUMMARY KEYWORDS
neural network, weights, network, energy, states, memory, neuron, recurrent neural networks, equals, minimum, feed forward neural, input, activation function, update, calculate, arrangement, guarantee, output, remember, turn

So hello, everyone. Now we talk about the second part of this lecture, which is Hopfield network Hopfield network belongs to a certain class of neural networks of that is the recurrent neural networks, what you've seen so far was the class of feed forward neural networks where the data moves from one direction, all the way to the output. And although and what we needed to figure out with back propagation, what have you is how does our knowledge of the output impacts the way you update the weights, however, the flow of information has always been in one direction. So when you go to recurrent neural networks, it's a different topology, that data could go from from the beginning, then they go to somewhere in the middle, all the way to the end. That's fine. But you could go in a weird direction where you go here, and then you go back, from which you go again to this node, then you go back to where you were, before you go to the end, it gets you back, it gets you back to where you are, and so on and so forth. Because of this weird arrangement, not weird arrangement, because of this uncontrolled arrangement of recurrent neural networks, many many problems have cropped up. The neural networks had inability to settle into a stable state can just go in any possible trajectory, chaotic or otherwise, if you do not know too extreme precision, your starting point and your initial point, you don't know what's going to end. So there's even case in its final destination. So this inability to control recurrent neural network made them made them and attractive as a way of implementing artificial neural networks all imagining how the human brain operates. So that led us to have more reliance on the feed forward neural networks. But again, everyone who who knows anything about neural network knows that most likely we have not even scratched the surface, and approximating how the neurons operate in our brains and definitely feed forward neural network. Isn't that so that made it a little bit upsetting that there is a whole class of neural networks that we don't have access, that was up until 1982 When Hopfield found out that the neural networks in the current chip on their their operations at that time there are a few things that you could do to them that can resolve the challenge. So, this is the ultimate neural network. So, the first one the neural networks are a direction of so he figured out if we make the neural networks are bi directional or or cyclic. So now start knowing state. And if we tackle the issue of having multiple having going from one neuron to another, by sets of weight, then coming back by a different set of weight, this may be Ole Miss this may contribute. This may contribute to the case. So an idea that he came up with was basically how about actually we make the weights to be bi directional. So instead of having two sets of weights connecting two neurons, we'll have just one set of weight that connects these neurons. And then we have this one here, where a neuron could feed itself could have a feedback loop or or self reference loop, which can also be problematic, so Hopfield figured out if we assign this to zero then we may end up In a situation where we have a stable network so the original typography or the original architecture of neural network where we have an input and output a this whole source of arrangement, if we optimized if we change it to something that's like this then the first value that we're gonna get right out of the gate is that a stable the final state. So, the network that was unstable suffer from oscillation may end up in a random end up end up in a random state and predicted can become stable can have guaranteed convergence and obviously, you can model it either conversion. So Hopfield had discovered that and that was a moving or changing point in recurrent neural network. It now can be used, the question is used for what so it's very interesting to understand it's useful to reiterate the features of the new of this recording unit. We said that the weights are bi directional and there is no weight from one neuron to itself there is no activation function that's new. If you remember our feed forward neural network we had activation function the network for it to achieve stability it has to operate on the concept of being energy based network and that essentially means lower energy consumption or the demand is better and neurons represent states. So, in the past neuron will present breeze present an output that is a function of the input. So, there is a processing here and there is squashing function activation function of source that produces an output that was the whole job of a neuron in and of itself isn't Other than that, in this particular case neurons do represent states which means and your own has a neuron in Hopfield network has to states on and off, so neurons could be turned on or could be turned off. Okay. The more we're going with this direction, the less this recurrent neural networks look like the traditional ones. So let's take a look at how this looks like just just from from visualization perspective. Let's say that we have you know, multiple neurons, you know, you have this is j and this is our this is you. So, you have w j r II w you are this AI is on or off based on some presentation, remember this is representation This is not an activation function or that a presentation says that if the energy if the energy of the neurons exceed certain thresholds then the neuron is turned on otherwise the neuron is turned off on here being one and off being minus one. So, if the energy coming into the neuron from you know from the different connections that it has if these energies X exceed certain thresholds then the neuron fires that fire some sort of fires means activation then the neuron is activated is on So, on your own could you know be representing of state one and could be representing of state minus one both states are determined to optimize for global minimum I'd say global here at Liberty let me rephrase that because global has a meaning for minimum energy consumption so, if we're thinking of some mathematical presentation, we're going to say the summation of the weights of any node of any submission of weight of energy I'm sorry, if it exceeds threshold in one it is less than the threshold then you have minus one okay. To better state what I've just said and network and network like this has states that are one or minus one sometimes they are one or zero. So we have states that are one minus one or one or zero this is more common and they have weights and the energy calculation would be the summation. So, 123 the summation of the weights between any two nodes multiplied by the states of the nodes itself. So, for you to fire not fire, the state of this the other states are important. Now, we are interested as we said in the past and minimizing we're interested in finding a minimum function. So, we add a negative here and this is a binary a binary state that goes from minus one to one so, we have here and this is what our energy if threshold equals zero. If the threshold isn't equal zero, then a general equation will look as the fourth and a general equation of the of the energy would be minus half same as everything i or j plus All i times is too short. So that's your general energy function. So let's take a step back and talk a little bit about this configuration. Now we know that we have states which we described, we have weights, which we have not described. And we have energy, which we've described. So when you have a network like this one, the goal is to define what kind of states so the question is find the states such that the overall energy is minimized. Let's take an example. Here's an example that I took from some material from U of t think, by Geoffrey Hinton, I found it to be very expressive of what I've just said. So let's say this, this, this network has zero on one states, so one is turned on, and zeros turned off. Okay. And for whatever reason, we have an assigned weights. So the weights he are pre assigned. The goal here is first to know what is our energy business. So this network has no thresholds or thresholds is zero. So the energy is basically as you said earlier can be calculated as such? Someone asks, where's the half? It's because it's zero on one network, it's not one or minus one. So all of these are zeros, all the states are zero. So other than the multiplication of these two, every r ij is here. So the energy of this existing network is minus three. So we have E equals minus three, we have the states being one or zero, and we have the weights fixed. So the question is, is this the optimum energy? Remember when we spoke about the neural network? About Hopfield? Network, we said it has a stable outcome. So if this is the initial state, what is the stable outcome? What do we want to do with this network? We want to make sure that this network has a minimum energy, whether its optimum or not, local minimum or not, at least it's a minimum energy. So how do we do to get to a minimum energy in this kind of network? Well, you actually start by synchronously synchronously changing the states. In the past, we used to update the weights to optimize for the network. And this particular one will just change for the states, and not change for the state at random, will change the states in order with a specific order that we'll have to follow. So let's say that this is one here. And we want to keep this as first as the first representation. And this gives us an energy of minus three. So this is our starting point. So can we can we change the states and see what comes out of it? So let's change the stage the state here to make it one. So, three, e equals minus e equals minus three times one times one, so with three times one times one, plus minus four times one, times one, so minus four times one times one, three times zero times one, two times zero times one, minus one times zero times one, all these are zeros. So we end up with, you know, minus three minus four equals one, one is greater than minus three. So this arrangement is that, so we go, and we say, leave it to be zero, we try to change this one as well. See what comes out of it all of it is zeros. So you end up with an energy of zero and zero. So this is one stoop to hear that gives you energy of 00 is greater than minus three. So that's not good. So we will put it back to one. We'll change this one next, and we make it one. And we'll see the calculation. Again, three minus one is two. So E here is equals minus two minus two is greater than minus three. Wait, wait, wait, wait, wait, wait. Stop, my step is to do this problem. E equals minus three times one times one plus two times one times one minus three times one times one. So three plus two is five. So this is minus one minus one is four. So he is minus four minus four is better than minus three. So we keep this to be one. Okay, so the last change is this one if we convert this to be one and do the calculation. So a minus this whole sphere is equal minus four added to it. Minus one do it minus one because this is so gets us to minus three minus three is less than minus four. So this remains. So this is the ultimate configuration of this neural network given its weight. So if you've noticed, when we started, we started with 110. And we ended up being 111. And this is the configuration that gives us the LI the minimum energy for our starting point. Now a question might be is this is this the best is this Is it the best assignment of of states? And the answer is no. So what is the best assignment of states? Well, I went ahead and did the calculation for possible outcomes found that the past the best assignment This is actually the complementary assignment. Which means you have 00111, which has an energy of minus five. So same network has, if you start from here, if you start your arrangement from where you are, then no matter what you do, you're always going to end up with minus four. If you start with different assignment of stays in different initial states, then you potentially can end up with a equal minus five. So it turns out that although it reaches a stable equilibrium, in energy, that is not necessarily the best equilibrium or the best, not the best energy. So what's the value here? Well, the value here is that if you throw any state here at random 010. No matter what you do, you will always be able to recover the two state either of the two states. So no matter where you start with this network, you'll find the state assignment would be either this one or this one. Which is impressive, because that means the network given its weight, remembers the states. And it can recover them even with corrupt signals. This is as a neural network that has a memory it remembers the states we've never had any tool that remembers states before, we've never had a network that actually remember stuff. And that made it interesting because now we can associate neural networks with an important aspect of the brain of the biology and that important aspect of aspects of biology is memory. Remember, in feed forward neural network, what we were able to recreate is the ability to distinguish to discriminate between objects. So, the thinking the recognition aspect of thing was the thing that made us excited about feed forward neural network it distinguishes between a cat and a dog and Max Hopfield network and recurrent neural network by extension, now introduced us to the concept of memory remembering, and not just any memories, associative memory, reconstructive memory, if you have bits and pieces or clues about your memory then there is a great chance that you will be able to remember your neural network, you will be able to recreate your your your state. So let me give you an example of what I've just meant. So I'm gonna read redraw the neural network that I've just had in a way that that might get you folks interested. So this is my so this these are my neurons, okay. So there are five I'm redrawing them why am I drawing them? Well, let's say that they represent pixels in in an LED so so Wait is one later on, or it is zero return off. So this is your initial memory something like three lamps that didn't on and two lamps to turn off. Let's say that I am to some corrupt memory that looks more like this knowing the weights between my neurons I will be able to recover the state most like I will be able to recover this state or another state or this is what would be the art this is essentially amazing. Because now no matter what's your starting point, you're going to end up recovering the patterns of interest for you. Now, if you complicate this if you complicate this network and make it lots of pixels representing numbers of letters and characters, if you assign your network your, your memory to remember the state of every pixel, whether it's on and off, and the weights between the different pixels, and you memorize number 1232, there is a good chance that no matter what kind of initial starting point, you are going to end up at two states, well, one of them is going to be the number that you saved. So this is a neural network that remembers interrupt inputs and can get to them giving giving the assigned weights and not just that they can actually you can actually save multiple weights for the network. So you can save multiple configurations. And you see an input and you try different. So, you you you you save for input x, you save weights, for input y you save another waits for MPJ to save another weights. And then you know and then you have input all and you try with this weight and gives you an energy you try with this with this way it gives you another energy you try with this this weight and gives you a third energy minimum, I mean. And the fun part is the one that gives you the lowest energy would most likely be the successful input. So with if you enter all what you didn't know, what is it, that's just a request, you know a clue, it may tell you know, your actual input should be x, or your actual input should be y what your actual input should be said. Engine. This is how it behaves. Now, is it correct all the time? No. It is not correct all the time. Why is that? Because it's fairly insufficient when it comes to stores. But we'll talk about storage later. Let's talk about it. I've now say I've now said that because it guaranteed to converge, you will always be able to get your output correctly. So why am I saying it guarantee it is guaranteed to converge? Well, let's let's do some a little bit of math here. We said for any network our our energy is calculated as such. But it doesn't equal j or i or j w ij plus for one input from one input, this is what I have Okay, so, if I change if I fix as I did here, I need to fix one oh and calculate the energy for the entire network. So every single time I fix one neuron and I calculate the interval. So let me approve that if I do that I will always arrive at the minimum interval so This is a math now, for delta E, I need to do E nu minus e OLT. Which means this term does not equal j, for all j. Those are facts. So this is oj, oj, oj OJ all these are fixed. So, there's nothing difference, all I knew. So, w ij plus i new theater, minus center. But now I am interested in Oh, I Alt plus, I alt fit. So, a new minus e alt is gonna give me it's gonna give me delta eight. Alright, so if I simplify this term I'm going to end up with minus half W ij OJJ doesn't equal i or R I knew minus or I Alt plus or I knew minus or I alt theta we are going over all J's the R is fixed. So I can take it as common. And that will give me wi J OJ over j, while it's an equal high minus theta i. New mines old. Okay, how do I guarantee it converges? Very simple. The all new is either one or minus one. All right, you're either going to switch it to one or minus one. That's basically it. So if this one is if all new is greater than or old, this will be positive. And this will be positive. This will be positive because the new is positive. So it's fires it isn't on. And for the function to turn on, this has to be greater than zero. All right, for it to be on, this has to be plus, and this will be plus. So negative times plus time plus equals negative. And so that's an improvement of the energy Remember, we want to go down. So II, when you add to it a negative value. It goes down further. So that's one possibility. The other possibility is that all new is this then all alt, so negative, so this will be negative, this term would be negative, obviously. And this term has to be less than zero. Again, if you remember this equation here we see the few if this one greater than theta is positive, this one is then theta is negative. So this term will turn out to be negative. So negative times negative times negative equals negative. So whether the news is one or minus one, you will always end up with an improvement of your delta E. And that proves that the network they say that's the proof of convergence, then network will always converge to a lower to a minimum energy Okay, so now we have a memory that remembers all the time, it will always be able to recover the memory or something like it. if presented with conditions, which mimics the associative memory in brain what else do we need to examine before we go into a scenario? Explain why don't we use it every day for the rest of our lives? Well, I haven't I think I haven't explained. Why do I go in order here? Why do I have to go? In order? Why do I have to go from 01? to three? Why is it asynchronous? Like one of you might say, Why is it a synchronous? Update? Why do I have update states? Asynchronous? Well, let's take this possible scenario. Okay. And let's see if we can, if you have the option of updating them synchronously, right, let's say, like, let's say that you have the option that you can simultaneously update, update multiple states. So let's say that you have this neural network and you have zero, and zero and one and one. Okay, so you have plus 10, here, plus 10, here, and you have two. So the energy of this network is minus two, right? One times one times two is two minus, if I turn, only this one on, the energy would be minus 12. If I turn that the second one on, I will also get minus 12, if I tend themselves will Tensley on and I have minus 50. Here, I will end up with an energy of 28. So I will go from minus 228. This is obviously that. So I do I end up turning off then I come I individually inspect that if I turn this one on aggregate minus 12, I individually inspect that if I turn this one on, I'll get minus 12. I turn them on at the same time, and I get minus 28. I turn them off, they're turned on. And I go on and on and on. And that would cause oscillation. So turning on more than one state, at the same time, will result in oscillation, so you end up with an unstable network. So as a matter of fact, you have to turn your network to change your state one state at a time. And you have to respect the orders. You don't go back and revisit your states until everything else had been changed. So we had so far an examination of the network and you said the network is good. And you know, it remembers and all that. Now we have a question of how many memories can a network hold? How many memories can a network hold? Well, not a lot. I mean when he can, and your Erica Hopfield network cannot retain a lot of memories. It's very, not efficient when it comes to storage. That's why we never use it as a storage. Why would you use something is storage if it only is able to retain point 50 And in square n is number of bits. So that's highly inefficient. You're only able to retain a fraction of the bits used to create the neural network. So is there any way to improve that will someone have come up with an idea and that idea was basically given the knowledge of the states and instead of updating finding the states that have the minimum month weights? Can we not just update the weights? And that was a while? Can we update the weights? Yeah. Will that improve our stores? It will improve our stores? Somehow I think it is. I think it's log two m plus one, one m is the range of your weights or number of weights, times in square. So it's it's definitely an improvement over this number. So how do you update the weights? Well, we have many ways of updating the weights, we see the status update is based on the weights. So it makes sense that the weights update based on the states. So how about we do something like this? A delta or ij, you know, to get you a minimum energy would be all odd. It's with basically the multiplication of all ij. All right, have the multiplications negatives in just have a negative delta and hopefully, that will give you over positive weight, right? If the if it is positive, then add more positive? Well, you don't have much of an options for the weights, the weights are still going to end up being either one or an increment of plus one and negative one. And that's my that's, that doesn't give you much of an efficiency is there a different arrangement? Well, a different arrangement would be that the weights themselves get calculated based on this equation. Or this is your state's. So, think of your states looking like this b one, b two, B three, the end, they get multiplied by themselves. Half of the y half was because summation right one times one, or minus one times minus ones will be one. So that will give me something like this or it's p one p one, p one p two now notice the I'm gonna get p two p two p three p three p n p n here. This is always one and it is representative to W IR. So I don't need this particular weight. So, instead of saying that my weights are I take out the ones you just just just I take out the identity matrix, and I make this divided by n instead of two, because I have many of those additions. And maybe I want to introduce some randomness here. So that will allow me that means if I know my initial memory be able to calculate the weights what does that mean? It means for the same network you can have you can have a lot of memories. All you need to do is to save the energy and the weights isn't even need to save the energy. All you need to do is to save the weights for every every memory will have its own weights and just you need to save the weights associated with them. So let's take an example of this operation. So here's to go all the way we've discussed all that Here's an example of fundamental memory. Okay, so we have 111 minus one is a fundamental memory, there are no thresholds, so threshold equals zero. And all we need to do, we need to calculate the weights based on the equation I've had. So the fundamental memory is calculated minus the identity, and this gives me my weight. So this is the weights that I have for this neural network, so fully connected. My initial memory is minus one, minus 111. And my weights are one minus one. Oops, for the connected one, minus one, one minus one. So this is my neuron. Okay, what do I get out of this one? Well, I get a lot as a matter of fact, if I start if I start with any state, if I could interrupt my input, if I could interrupt my input, so this is my initial memory. Let's say that the input is not correct, right? Because I lost my I lost my memory. So I lost one minus one. But I know my weights right there, it's, if I enter something like this, I will be able to get either to the memory itself, or its complement. So the complement would be minus one minus one minus one. And here's an example where I had as an example, if I start at minus one minus one, one minus one, I arrive at the actual memory if I start from here, which is also random input, and also be able to recover my memory. So this network allows me to successfully recover my memory. Regardless of which point I start with, recover my memory or the complement of it. Because I have the concept that no matter where I start with, I will always reach out the minimum energy, which correspond to either the memory or its complement. Now, some might ask me, okay, if you can do that, can you use this for classification? Okay, because now, if you save the recognition, I mean, if you save a bunch of weights, right, if you save a bunch of weights that respond to a number 1-234-567-8910 10 numbers, they will have their own unique tin weights, can I be able to use this for digital recognition to recognize the numbers? And the answer unfortunately, is no, you can't because some time the the minimum energy costs if you disturb if your input so if your input is a corrupt if your input is a corrupt image of number seven Okay, so this is your wish it, it being number seven, there is no guarantee that if you start from here that if final outcome might be nine, there is no guarantee that because now if you start from here, the weights for nine will give you many less energy than that the weight from seven there is no guarantee that it will work because it's about converging to minimum energy and base and as we saw in this example here, that it's not guaranteed that the the ultimate weights you have are the ultimate word that always you have will give you the minimum energy for anything that looks like it. Not sure if I'm making clear is that it's good at retaining memory but it's not good at distinguishing between memory memories and that's, that's the biggest problem of of, of Hopfield network. Now Hopfield network is liked because it was revolutionary. It showed us that neural networks artificial neural networks can mimic brain in attaining and retaining memory can mimic associative memory. It was the precursor for the full fledge computer network because the concept of memory is proven correct and, and it has been devolved later. So it's an interesting, it's an interesting neural network. It's it has a limited extremely limited storage capacity as shown by how much it can remember. And the cost that you have to pay to remember a lot. It was just a revolutionary neural network that that had shown us an entirely new aspect of neural network, which is just memory and remembrance. So that's it for today's lecture. We've we've covered self organizing maps and Hopfield networks. I, this is the map this is going to be the material for for the exam, the next the first exam. So everything I've covered is in the exam. Please study diligently and see you in our discussion session. Thank you


ECE657 Lecture 6
Fri, Apr 07, 2023 9:09AM â€¢ 2:10:32
SUMMARY KEYWORDS
neural network, convolution, input, layer, features, weights, output, parameters, filter, image, pooling, network, works, called, neurons, activation function, problem, deep learning, picture, convolutional neural network

Hello, everyone, welcome to our sixth lecture today we are going to be covering the subject of deep learning on there are lots of areas that we need to talk about, before we start talking about the interesting stuff we will be discussing why do we need deep connectionist models? Why Well, in the the model model deep models popular before, as we've discussed in the past, neural networks have been there for around if you want to start counting from from 1943, um, there have been a period of some 70 years where, you know, where we could have gotten into deep learning, especially when it comes to the 80s and 90s with the the pseudo pseudo maturation of neural networks, and we still had to wait some 30 years for have gotten into a popular deep, deep learning models and it's important to know why why took us this long, because some of these things still do impact us too. Today, we will be talking about we will recap multi layer perceptron as well as convolutional neural networks as as a way of discussing deep learning we will be talking about recurrent neural networks and auto encoders but that will be left to next week as well as natural language processing as an application of you can call deep learning or as an application of recurrent neural network. In general, once we cover these subjects in we should be in a good shape. A has to be done with neural networks or with the biology based imitation of, of human intelligence, ie the artificial neural networks, whether it's feed forward recurrent, supervised or unsupervised. So, in theory, shallow channel models are either non linearly separable, classifiers or universal function approximate errs. So, in theory shadow models, which we've what we had learned in the past, you have few few hidden layers between inputs and outputs, recall the shutter models should be good enough. However, they do usually require a large number of units to mimic any deep structural behavior and they do tend to suffer from from overfitting and generally in general they have they have been proven to be very difficult to train and doesn't have that we actually didn't know we cannot three deterministically know what the output would look like. So, shallow models in and of themselves, although they do somehow a good job of of separating between different classes. They have been shown to be quite complicated when we want to apply deep learning on them. And what made it even difficult is that they do have a host of problems either had gradient flow problems. They do need large datasets as well as large computer memory resources. And and these aren't insignificant issues. So, I'd like to take a step I'd like to take some time to explain these problems and explain why do they exist and explain why they impact why they make In our traditional configuration of what layer perceptron not workable for deep learning. So let's start without with with some traditional traditional structures characterization of feed forward neural network. So you have the input layer, data moves forward to multiple layers. And then after a while they reach some form of an output layer. So that's basically how start starts with an input, you have multiple layers. And the layer l minus one hit enter L, L. And Delaire n minus one and the final layer. If I want to take this and make it a very simple challenge shadow shadow model I would say, let me do the following. Let me take only two layers, the input layer and the following layer as it's just following layer. So the input layer had number of features, let's say we have five features four features. And the hidden layer for simplicity has four neurons. Okay, four inputs, your input has four features. And you have four neurons in the middle layer on the first hidden layer. And as usual in our traditional feed forward neural networks, or multi perceptron networks, we have fully connected model. So all inputs, every feature is fully connected to all neurons to the output. And those give us some preliminary output which is basically if you think of it an application on X fi, Wi Fi. If it is sigmoid function that it will look like this. And that's for every for every neuron. So that's a scalar that is basically this calculation. The weights here are four by four. So four inputs, four neurons fully connected. So you end up with no four by four and this model has some good quality the weights happen to improve based on output based on the output performance. So our delta w is a function of our performance given the weights here. Because of the activation functions here every output is normalized either between zero to one or between minus one to one depending on your activation their activation function but regardless it is normalized. The weights here are updatable. And what we've never mentioned before, it does have features election So this is a feature. And this can be also a feature, right? Every layer presents host of features, you transform them, you produce another class of features. If the weights here are zeros then you're muting your features you're saying this features aren't important. So just by assigning zero is doing see, just by having the network adapting to zero weights, you do feature selections naturally. So these are the the the good things about our our, our neural network. So what are those things? Are What words do things go wrong? Well, let's take our our simplest neural network that we've discussed in the past one then you have your target here. So we said if you want to calculate, if you want to calculate the change of this weight all you need to do is to given your performance function is to take the derivative derivative performance function with respect to the weight. But which happens to be as we've shown in the past to be something like this and if we want to update the weight for w one, we have to take the derivative performance with respect to the way that the derivative has been shown to be something like this and we said no matter how deep you are this equation will hold. So what we can do is basically we'll say let's assume that we have in layers let's assume that we have in layers and and, and the derivative of the activation functions is one. So effectively, all these values go to be one. That means if I want to update the weight of w two w one, all I need to do is say x i times W times W three, W four, W five all the way to W L times t minus l. So what I did, I just made all these you can see that if you have copies of these ones, these boxes here, replicated every time you put it it's a replication of a layer. Then you end up with this term repeated over and over and have this mystery Better simplification says one two L minus one W E i times t minus L and that would mean my delta my w delta. Okay? Now, let's assume that I initialized my weights to be the same. So that means we will be calculated like this and that opens up to scenaries. If W is greater than one, for example, looks like this that's the initial, then our first delta w one, which we something like this one. So, let's assume you have 1000 layers, and you can imagine how big this number is. And let's Asou and in case it is less than one maybe much, maybe way less than one for example, something like this you will delta u delta one will look like this this multiplication is called exploding variant gradient. So, basically this devil delta W will be extremely large, what would happen your network will become unstable. And you know, it's literally explored, not literally, it was very much explored and you run out of memory. And this is the opposites, this is called vanishing gradients. And vanishing gradient is basically your delta your w delta w one here goes to zero. So, what happens when your delta w goes to zero? Well, this is your performance. It starts by forward propagation where you calculate your performance. And then you go in you do your backward propagation. So, you could create your delta w here and you update your weights, you can create your delta w here, you update your weights, you calculate your delta here you update your weights. And then you come here and you calculate your delta to update the weights. This delta is zero. So, the weights in the first layer never update. They just didn't update. So, the weights of your first layer never update then there is no learning learning curve that means, those one the features here will remain as is. And that is the problem of vanishing gradient. And obviously, the more layers layers you have, the more chances that you may end up with weird or small W's in between that will lead to the earlier layers not being updated at all. And that has been observed actually quite a lot. What's not just The weights that that cause your charge. So it isn't only the weights. If we come here, we notice that we made a, maybe a naive assumption that your function C and have derivative of one. In reality, your functions will have different value for derivative. But let's assume that still stick mistake mistake, let's look at the anatomy of the function. Let's say that this is this is our function. If the output happens to be here, or happens to be here, the derivative would be close to zero in both areas, because it's one minus y times y. So if y one, y goes to one, then this term becomes zero. When y goes to zero, this terms also goes to zero when it comes to the derivative, so when you're here, or here, you'll end up with zero. So in this example of multiplication, there's a good possibility that you end up with zero source, as you're calculating your delta wn, it might not be a bad thing per se. If you want to kill the feature, the problem here is that the feature was firing. So the feature seems to have have an excitatory behavior of firing, firing lots of neurons. Lots of aspects. So this, so this is basically the gradient eventually, the gradient flows problems. And it isn't that there aren't problems. To these sorts, there aren't solutions to these problems, like there are solutions that you could use to solve the vanishing gradient in the context of multi layer perceptron or traditional neural networks. For example, adjust your weights, your initial weights to be around to be around you Around one at the beginning. And then some the weights will increase, some of the weights will decrease and you want to do the multiplication, they'll even each other out, I can add some weight is 100 some weight is point or one you multiply 100 by point or one you end up with one. As long as your starting point is fairly uniform around one, you shouldn't worry about starting on the wrong foot. So that's one solution. Another solution is choose an activation function which derivative whose derivative is close to one so the assumption that we made here that it's assumed Swan, let's make it a reality. And one of the examples of functions that allow you to do that is Rayleigh function. So that's a function, you know, as a function goes 00 If you if your input exceeds a certain threshold, it fires so the derivative here is obviously zero and the derivative here is around one. And that means the issues here which don't have to exist, especially this area where it is quite problematic derivative this one zero, because it shouldn't the function is excited. So these are two solutions that you know they exist. I can deal with the vanishing problem as caused by weights activation functions. But these aren't the only problems that we have, when it comes to the traditional feed forward neural networks. We said here that they do require large datasets. So what do we mean by that? What if you have an traditional problem, you know, think of if you have a data set like the Titanic data set, or you have something like the the movie dataset, traditional problem with with with a very defined data set small one, then in unilateral quit work, but every other technique would work. So there is no necessarily any advantage to neural network and those particular exercises. And if you work with other exercises, let's say that we were interested in image recognition. So here's an image. This is a very simple image. So this is an actual image when it has, it is 256. And 276. Images are usually presented by as you know, a two dimensional matrix. And that's the simple one a great image. So let's say that this might impact when it comes to an image, I can't input the image as is to a classifier, I have to flatten it, which means I have to take these rows and put them next to each other. So the first row here, the second row here, third row here, so on and so forth. And this would be one input vector, and all these are features. So in a way, all ended up having to input something like this for for this image. My input would look like this of x one of x 2x. Three. And I can't write all the way down because down is literally x 70,225. So 70,000 teachers. Okay, now, let's assume and I'll be generous. Let's assume that we're connecting this fully connected to a hidden layer that maybe only have 100 neurons which also fully connected to an output layer for classes. Now, you will never connect 70,000 to 100 to omit the layer or the layer of 100 nodes, that just didn't happen. That's a huge compression. Unless you're trying to do something like autoencoders, you wouldn't be doing something like that. But let's assume that this is the case. Well, we need to learn all the weights here which believe me, happens to be a happy large matrix those weights have 70,000 times 100 w one, w 100 w 70k One. W 70k 170,000 times 100 means you have a little bit more than 7 million waits to update you. And here you have 100 times four which means you have 400 parameters to update. This one should finish shoe. I mean, again, you will never see this configuration, a real life because it's there will work. Even if, if, if, if you can learn 7 million parameters, but one layer here may require us to learn 7 million parameters was second, five want to learn 7 million parameters? How many data points do I need to have? You have a really, really good learning exercise? Well, let's think about it. Every parameter here affects your output. So I need to, I need to change its delta. And see how this parameter will change how this output will change how this output will change how this outputs change, or this output will change. Right. So if I change this wait, for example, let's say w one one, I will affect three outputs four outputs. So if we do forward propagation, we calculate our performance function here. We get our derivative for each one. And then we're going to have to change it. But also, once we change it, we are changing everything else. So we need to know the impact of w one one over the outputs, we need the impact that they'll do w one, one and w 5050, for example, together having the output. So think of it as solving an exercise was 7 million and knows how many inputs do you need to do to get to these to solve for 7 million unknown? Well, the more that the higher the bid, we know that anything that is less or equal than 7 million is not acceptable, it's too limited. Okay, what's the minimum? Well, the minimum is 10 times the number of features. And that's not scientific number is just the traditional exercise that is found when you have training data set that is 10 times the features, you start seeing results. So at least we need 70 million pictures. To learn the parameters for the first layer, we have lots of layers, then we have lots of parameters. So just by looking at it as is you're faced with a major challenge and the major challenge being you do have whole lot of parameters to learn and you need a lot of data to learn these parameters and that can be a challenging exercise. What else can be a problem? Well let's say that you have 100 times you have dataset that is 100 times the number of features in this case 700 million pictures how much storage how much storage do you need for 700 million pictures and to what is the computational requirement to run the training exercise and again, sometimes it is not a lot so right out of the gate even even for Doing a decent amount of building and image recognition via the traditional feed for new network, you're stomped by a lot of requirements. Also, this network is fairly complicated when you have a network with 7 million parameters, you have an extremely complicated network. And when the complexity of the network increases, or the complexity of the model increases, the chances for it to overfit also increase. Because you have so many weights, you could theoretically tune your network such that it can memorize the exact boundary between 1000 class memorize, not figure it out, not learn which which features separate a cat from from a dog, it is just calculate the actual borders within your training data. And that leads to a big problem here. Having to do with overfitting your wizard of overfitting is a major issue. So it turns out that existing models once they are changed to be deep, and deep again means you go as deep as possible, given the number of layers, if you do that, then you're making a whole lot of myths that are going to be extreme and extremely challenging exercise for you. And that is what made what putting your network into a tough position before 2012 So I remember before 2012 The sentiment at University of Waterloo was basically and I've been told that by professors is that it is only fancy we don't know how it works our waste of time. And we generally had a dismissive attitude about neural networks because for smaller problems, other solutions performed better support vector machine is notably one. And for larger problems, where you know, it seems that the concept of deep learning works quite a lot. A neural networks fail. That was up until 2012 Where convolutional neural network was you use successful to classify around 1000 objects. So the convolutional neural network has been there for a while by the time but has not been used successfully. Not to a large degree. So 2012 kind of jump a little bit we had an interesting neural network that's it. That had 60 million parameters. So 60 million weights. Remember here, I set for this small picture with one layer only. It needs 7,000,004 classes by the way. Okay. And that's for a picture that's two 456 by 256. If your picture is one meg by one make it say one kilobyte one kilo or one meg Why would make then you can only imagine how complicated this model will be look like. So just just keep things into perspective. While you examine the work that's been done here, we have 60 million parameters a 60 million weights value to calculate for most We have 1000 classes. And this network that's been designed in 2012 has 65% accuracy for first option, first choice. If you're choosing the first response, test 65% accuracy. If it is the top five, it has more than 80% accuracy. So it was pretty good, given how given, you know relatively how low it was in complexity, and how high the number of classes needs to get. So this is an example that they had of for successful, our classification failed justification. So this is a picture of a mite. And the first guess was a might. So just think of it. This is what all could see. This is a picture of, of a container ship. And the first guess was a container ship. This is a very complicated picture, but we intended for it to be a picture of a motor scooter, and was actually correctly classified as a motor scooter. This is a picture of a leaf part. It was correctly classified as a new part. And the other options was Jaguar, future snuggly part and Egyptian cat. So even the top five, the first is accurate, but even the other four were not far from it. This is a grill and was classified as a convertible. I honestly believe it should be convertible regardless. This is a mushroom, and mushroom is the second option here. But the first one and the other ones are some other sorts of fungus. This is a picture of what was intended to be cherry. And the first option the first suggestion was then Mattia, this the machine. So not sure is this an error. And the other ones will read either very, another source of things that are closest the chair. This is a picture of Madagascar cat, and the first. So it had failed to recognize it in the top five, or the first one is a squirrel monkey. If you use search of the internet a picture of a squirrel monkey, it looks really close to the Madagascar cat. So this neural network was a breakthrough neural network. And that it has proven that deep learning what was called deep learning as presented by the convolution neural network works and works to an extra ordinary degree. Now between 2012 and and today, there had been lots of improvement improvements over this particular neural networks. In our first lecture, I've shown you how Tesla uses image recognition in real time to recognize obstacles to recognize pedestrian to recognize traffic signs and other things are for their self driving vehicles. So there was a major leap in the past nine years. But but the impetus of all started or was the paper published to 2012. So that was the impetus. Okay, so what did what happened? That all these challenges have been resolved, you know, the challenges of all the over complexity of a neural network that charges that you have 10s if not hundreds of millions of parameters up on parameters that you need to learn. The complexity that comes with that the extreme demand on on on training data are How did convolutional neural network resolve the challenges? How did CNN resolve the challenges? By answering the Here's how we'll also answer how it works. So let me take you through one small exercise, let's say I have let's say I have an input that looks like this 1234567 8/8. And I have a hidden layer that is of six neurons in a traditional exercise for me to have my weights here are the weights here are going to be eight by six, so x one 2x, eight is it one to six, fully connected, dense layer, so I need to learn 48 parameters. So that is that is traditional fully connected neural networks. What convolution took did they said, Let's do the following let's connect this note with some of the outputs. And let's connect this note with some of the output let's connect this note and this knot How about those ones? Well, we are not going to connect to them, maybe those four will connect to those two. So that's what this effectively means is that every every note will have only four outputs, or four weights coming out of it. So instead of eight times six, we'd have A times fourth write every note out of these eight notes will have only four words. So instead of needing to learn 48 parameters, I'll need to learn 32 parameters. So the first solution was basically move from fully connected on architecture to sparsely. sparsely connected architecture, some from fully connected sparsely connected. Okay, so an awful connection. And that took me from 48 weights to 32 weights. Brilliant, I didn't need to layer 48 weights. But then there's another idea that came and that basically said, this bundle of four weights doesn't have to be different than this bundle for weights, this bundle of four weights, this bundle for weights in this bundle of forwards. So, in essence, the value of this link, let's call it w one is exactly the same as the value of this link as the value of this link as the value of this link. So every link that comes to this I'm sorry, not that the bundle itself is equivalent of a bundle does have to it doesn't have to go to the same neuron. It just that those four weights are the same everywhere. So instead of saying eight times four were only going to learn fourth I only need to learn follow it, those four. Now some of you folks would say, Wait a second, how would you learn these weights? If they act differently on the art I will discuss that. But just humor me. And we say, we want to have parameters sharing between the weights between the neurons. So what does this mean? If feasible, what means that I need only is I need only point one in this particular exercise of the of the training data that I needed for 48. Right. I didn't need, what I need to learn for this form is not what I need to learn from these 48 weightless exponential curves. And that allows me to have scalability. What do I mean by scalability? Now, let's go back to our exercise, let's assume that you have an input of 70k. Features, right, this is what you had here. And I said, the assumption that you only can use 100, as a hidden layer is very preposterous. Because no one needs no one can use 100 layer neurons to represent 70,000 features. But with this parameter sharing, because I didn't have to have to be fully connected, I could have a hidden layer you know, that is maybe 60k. of size 60,000 euros and I didn't need to learn 70k times 60k weights. Because it's not fully connected, I would need to learn only number of parameters here it could be four, could be nine, it could be 25 could be 49. It will be within this range. It wouldn't be within this range. So this amaze, amazing ability to scale up my midi lips will allow me to do crazy stuff. So before I go forward and tell you how is this actually done and show you the architecture and design and the the relevant math that is relevant math. Let me address the concept of deep learning deep learning as identified and indeed had been identified as the very beginning. It's basically having a lot of layers. So between the input and the output, you have the path of connections. So deep learning you're going deep. This design is not deep. We'll call it deep learning. But it is not deep. It is wide. So if you're thinking that deep learning because some some students are challenged by the fact that we call things deep learning, you look at the network. It doesn't seem deep work. The depth all depends how you look at the depth maybe with is a depth, maybe a wide network is a deep network but in some other direction, right? Think of it as a valley. Didn't think of it as a mountain. I don't know if I'm using that metaphor here. Just think of it as deep down, not deep for so it's a wide network extremely wide network that we are able to create. And the question is basically, what are the mechanics? Usually you're asked or expected to explain the mechanics, how does it work, how it's all done. And by understanding the mechanics you demonstrate that you understand the subject, so the mechanics is in the world convolution and convolution is basically when you have a signal like this that is subjected to a signal like this, or this signal is slit, you know you slide the signal through, so let's call this F, let's call this g f convolution g is g being taken and getting moved through F. And what you do you multiply it by whatever you have here. And you sum it up and you draw the next connection, I have a nice, I have a nicer picture. So, if you see it, you will be able to understand how it works. is So, I forgot as a matter of fact, if this is G, then you have to reverse it as well. And then slide the reverse message signal into it. So, here's an example that's f s GE take your G you reverse it and then you multiply it by f at every point and you take the area you sum it up and you plot it and this gives you f convolution which sets basically an a signal that is slid through another signal and changes the way it behaves. Changes also in its magnitude. So that is that is convolution. And the way it is mathematically represented, it's basically convolution it's have f of t convolution g of t equals this is the summation or integral so this is this is a mathematical representation of confusion. Okay. I've said a lot. It's time that they show an example. So here's an example of an input. Now, I assume this to be an image that is that is six by six. And it is convoluted. But another signal, another signal Ma'am, this is g and this is F. What you do is basically you take this one, and you slide it, so you take it here, you put this signal on top on top of this one, you multiply, and you sum. So one times one, plus zero times seven, plus three times eight, plus two times 10 plus zero times 12, plus four times 30, plus four times two, plus zero times four, plus six times six, and this would equal 141. And then the signal gets slid here. One, one step. And you multiply the same values, and you sum them up. So again, if you're interested seven times one, plus eight times zero, plus 11, times three, plus two times 12, plus zero times 13 plus four times 50 plus four times four, plus six times zero, plus seven, times six, that equals 182. And again, you move it one extra step. And you multiplied with this arrangement, I ended up with 266. And 323. Once you're done, you go another step below. And you repeat exercise. So this signal G, it goes through your entire input and scan through it. And whenever it passes, the impression that you apply is summation of multiplication. Summation of multiplication. So what does that mean? Well, lets me go to my initial example here, where I told you that the connection is all you need, you only need four connections. So we have we said we have eight teachers here. Let's say that this is a picture that looks like this. X 1x 2x 3x 4x 567 X eight. So four times two. That's the picture convoluted by those are four ways w one W two, W three, W four. This is exactly this. As a matter of fact, if I were, if I were to better represent to mathematically describe this relationship, I would say that for X 1x 2x Three, and x four right? For this one here, it would be x one times w one, that x two times w two plus x three times W three plus x four times W four. So that's why area has said different connections. So this is w one. This is definitely To this is W three and this is W four and then after that you move this one step below and your calculation again is now x three times w one plus x four times w plus x five times every three plus x six times every fourth and go on and go on and go So, this will give you the fact that we're using this filter or kernel or function, you will end up in a position where you're representing a sparsely connected neural network like what you will be doing is is is an architecture response to connect a neural network one other note because of the structure as a matter of fact, not every new note needs to have for connection coming out of it as you see, x one only appears one and x two only appears one as well. So, it doesn't require to be fully to have more than one neuron one connection come now to it doesn't need that just needs to be connected to the first neuron. So, when you decide that you have four weights, you're saying every node in the hidden layer has to have four weights connected to it where that are coming from that is not necessarily a systematic connection. So, what do we call this? Well, this is usually called filter or can I say does it you know it convolute the images and produces a new image that is of a smaller dimension. So, this one is basically you would have an input of 36 features connected to a hidden layer of 16 features mature weighting matrix here is three by three which is this one so, just by doing this one you have adopted you have adopted a is parse connections between the input and the output again this is the input layer this is the output of the input layer they're the layer this is your that one that two that three that four all the way to that 60 okay to do on the to the three although it is it 16 And these are the connections that these are the connection that you have between something like that anyways, so, these are your connections. Okay. So earlier we said we have a promise of scalability. Now, before I got sparsely connected, I believe we have explained what what Does it mean to be supposed to connected parameters sharing here, if, if we haven't been clear about it, these are your parameters. And for every neuron here, the output is a product of the multiplication of the input by these parameters over and over and over and over, see your W's are, as you see here, the same W's. So this is the parameter sherek. So what aspects do we have we have scalability and scalability here, depending on the size of your, of your filter here the output size can be controlled or can be defined. What do I mean by that? We can in this one. We said F convoluted by G gives me this one is six by six, this is three by three, and this is four by four. Okay, so how do I get four here, four is here is basically, let's call this F. So let's call this n by n, f by f. So n minus f plus one gives me the output, output size. So my n is six, minus three plus one gives me four. So my choice of my filtering side controls the size. So let's say that we do two by two here comes six minus two plus one gives me five. So when I go back to the concept of scalability here, I would have an input that is 36. I have a hidden layer that is of 2536 25 fairly close to each other. Okay, I didn't need to be restricted by being worried that I have to learn 36 multiplied by 25. As a matter of fact, I only need to learn for parameters for now. So it allows for scalability, and I'm not necessarily worried about how many parameters I need to learn to get to my desired output. Okay, ah, we said so far, that this operation is called convolution. You say this g function is applying a filter. So, think of it as an image and you apply a filter on an image and, or an input matrix and you apply a kernel on it. And you produce an output image. Okay. So what are the problems that we have? That we need to be careful about? If you remember what I said, you need to reverse the mirror signal for convolution. So, convolution, a signal has to be mirrored, which means the input before I do the multiplication doesn't happen with the signal. It should happen with a signal that looks like this 643 it's mirrored so you're almost like flipped 000 and four to one. If you're doing convolution, you have to mirror your signal before you multiply in sum. This is the convolution. This is your original G. You have to mirror it. But we aren't mirroring the signal will just be you know, multiplication and summation. So we end up with a different signal. This is the signal that we'll get out of this process just multiple Find some. It's the mirror this one for convolution, f convolution g equals g convolution F. Alright, so f convolution G looks like this D convolution X f looks the same, and D convolution. See if he gives me this shape. f convolution G gives me the mirrored of it, this process called cross correlation. So what we are actually applying here it's not called convolution. It's a cross correlation. So why do you call it convolution? If it is not convolution? It's cross correlation. Well, it was a mistake. People made the mistake at the beginning of the competition your network. They did cross correlation, and they called it competition. I mean, this is the simplest explanation. Reality cross correlation is way easier to calculate. As a matter of fact, if we have this demonstrated, this isn't. The only thing that this has to do with cross correlation is basically the concept of parameter sharing because the same signal is passed. So the entire images can stretch. We don't need to flip it, there's no use in flipping it, or there's no value flipping it. And this thing that we call a filter is basically a weight is a weight matrix. So this is a weight matrix. So the convolution operation isn't convolution, and the filter isn't definitive. But somehow we have in our hand convolution unit that works by applying filters or kernels on the inch, okay. Do we care that the name is wrong is not correct, or doesn't do exactly like convolution? No, don't care what I mean, you know, it's not convolution, it's good that you understand it. If it comes in discussion, you'd have an understanding of the historic behind it, but there is no practical need for us to worry about it not being a correct description of the process the process of convolving a signal with another signal. So what are the things that we need to learn when we're doing when we're working with convolution network? Well, the first thing is this think this? If so, if I were to write a policy or say no, you felt what do I mean by know your filter? Well, how do you calculate the filter size? How do you calculate the output size? We said well, the output size is in minus f plus one equals the new N Okay. So, that is my filter run that how I know it controls are my output, I have to also be careful about because of this equation, I have to be careful about the dimensions and deciding what are my dimensions. The problem that I've seen with some of the students is that they basically ask okay, how do we define the filter dimensions? And the question is, well, I you know, you have to try a few things here and there and see which they mentioned were to you do understand that. So, given what I have taught you, so far, the bigger than a mention of the filter, the smaller the dimension of the output of the convolution process or the cross correlation process. So, but also the bigger the filter, the more parameters you in your learning, the more confidence you have in your learning process. The or the more sophisticated your model gets, that is the filters that is size the filter is the less parameters you know, and the more simplistic your model is. A too simplistic model, usually under fits doesn't live. So Do understand that there is a palette and a balance that you need to strike by identifying your filter value. The other thing is, know your desired dimension What do I mean by that? Well, I'm sure many wouldn't be happy with this four by four, like, I've sold this hope of going 70k by 60k. And once I start explaining the filters, I said, Well, you know what, there's a good chance that as the filter size increases, your damage zero will decrease. That's a problem. And there's also the aspect that I've shown here is that, for example, the feature here x one, and x two only appear once and the appeal in this note, which means the feature is only represented by one hidden feature. So this process is mapping an input to an output mapping the input feature space, to a hidden feature space. That's, that's the whole thing, right? If you are doing the convolution as is, then maybe you're not doing the mapping correctly, let me explain. This is very important. And this is one of the important thing of deep learning. You have your input space, you have your connection. Say this has features. And those are your new features. And I genuinely mean new features, like if you have a face here as a scary face, you somehow map it, to maybe look like this do something like this. So you abstract the face in another aspect. Or maybe you abstract it by keeping, you know, some aspects of it more prominent on different ways, like the face size, when you when you apply the filter, as is, some of the features in the images will have less impact in the new feature space, so maybe the nose will disappear. Just because it's not represented correctly, is represented a lot so it just disappears. So you end up with something like that. So it's very important that you know your dimensions are you happy with four by four, knowing that this feature will only contribute once to the calculation? Well Are there alternatives to deal with this problem with one alternative is called one solution or one possible design is called padding. So what padding does is basically says how do you want your dimension to be? So let's say that I want the output dimension be equal to the input image same damage, okay. We said here that n minus f plus one equal Nuun. I want to rephrase the equation and say it's n plus two p minus f plus one anyone this entire term t equal n instead of in hat equal n, okay. So what is the unknown here? P is unknown, which is the padding. So, P the padding can be calculated to be f minus one of two So based on the filter size, obviously we'll choose the padding how much padding we have. So for example if I want this to be six by six so it's six minus one divided by two 5.5. So five divided by 234 gives me two so all I need to do is basically is to Pet Pet this signal with with Xience. So all I will be doing as I'll be multiplying these nine think with the filter, and then I'll be I'll be moving and multiply now these are obviously zeros so it wouldn't matter. But what happened is that the inputs here will contribute to the to the to the output much strongly so this will become six by six. So the mapping allows for an output fully demonstrable output of the same dimension as the input so the noes get to come back if you are programming with Python, and you're using Karis, because on TensorFlow then you have the option of padding of two options when it comes to that pattern. The first option is called same valid and valid means you don't know patenting you have the option of same which means same input damages so if it's if you do valid as a hyper parameter for padding, then nothing's going to happen if you choose sim it will calculate how much easier it needs to pass an error will padded with zeros it will do it for you. So we said no your filters we said Know your desired dimensions and I will add know your stride so here we assume that that we stride by one. We said earlier you stride and the assumption is that you stride by one. Now is the assumption that's not the silly doesn't have to be that like that. Doesn't have to be like that. You didn't have to stride by one. Right? You didn't have to be three by three. Oops. I know just technology is very weird. That's fine. So you didn't have to. You didn't have to lock to go by one from one step here to here to here one step at a time. You could jump by two. You could you could you know the First representation will happen here. And then after that you go to here. So, first, you do these three, then you stride by 230, these do these three by three, then you stride by two, there is nothing here. So you stop here go down, but also go down with you. So you do these three strides, why to do these three by three, you cannot go this way, you cannot go this way. So you stop. So you have an option of actually moving, changing your stride. So, but if you change your stride, your calculation for the new dimension will change. So in the past, it was n minus F was n minus f plus one. There we said, Well, yeah, if you have padding, then it's n plus two p minus f plus one equals n. Now if you have a stright, it's n plus two p minus F decided what divided by the stride is the float plus one. So the stride like in this example, this example has a stride of two. So you do this, you do this and nothing happens. So you do this. And then these send up with 123 and four, so six by six, three by three, two by two, and no padding. And padding equals zero. Okay, so we said no, you know, you know you're then instance no use padding, you know. I know you're straight. So this one is six minus six plus zero minus three divided by two plus one. So six by three is three divided by two is plus foot 1.5. What is the floor? So one plus one equals two, that gives you two by two. Okay, so so far we've we've gotten lot we've, we've done bunch of things. And we discussed that that just by applying a filter and kernel you may end up with a good representation of your output. And we say that the most important aspect of deep learning is the fact that it does a lot of feature transformation. So far, we've looked into a two dimensional image of looked into a two dimensional array into two dimensional images. Now if you think this is a gram, right, it's half something like this. That means you have one channel it's a good it's a gray image. So the outputs are the big image goes from zero to one. Zero means white and one means black. And you know you'll go between the white and black by different shades of color. But what if you have an RBG image, you know? So, so this is alright 1234 Let's do this problem. compromise as long as it's close enough I'll be happy with it so RBG is three dimensional so six by six by three so you have the red you have the blue you have the sort of three dimensions here and so far I've only explained a one dimensional thing so how do we do with a 3d images? Well, it isn't that difficult it's the same concepts that explained so far. You know, firstly decide on the size of your filter. So let's say that we're going to stick to three by three but against three channels, so three by three which means you know, we we do three by three in terms of damages so three by three in terms of damages. Okay, that gives me around 27 values here. So the convolution is basically one one to 27 If everyone this is pixels alright WTF. So, I'll take this filter. And I will Oh, all superimpose it this way so it will be multiplied. And then I'll sum it up. And that will absolutely contribute to one out and it will strike its musical stride by one. So I'll do this do this I think this way and that will contribute again to the second so as a fourth. That will give me for my fourth All right, so three by three by three. If I have three channels here, we're going to have three channels ease, but that will give me exactly one champion. So let me go back to my horrible examples here. When it comes to features, here's the reality of the match. So far, we're not getting any value out of deep learning because we've been conservative when it comes to how many parameters which creates deep learning is about extracting features. So if you have if you have something like this, score the face what you need to get is to get a multiple pictures are not a representation of this image. But maybe you want to do this. You want to do something like this. And also you want to see something like this Maybe you want to see something like this so there's different ways of taking this face and, and getting some features out of it. Different representation, different slices of the image, right, they have a depth, you have directions, you have lighting of multiple things, if you're gonna present an image. There's lots of information already, because three dimensional mean loss information. So if you end up with something like this, you're not getting a whole lot of value, this is just one image. This is a slice of a rich input. And there is no need for it to be this way, we could actually, we don't have to use one filter, we could use multiple filters. So the image will another filter and another filter and as many filters as you want. And that will effectively mean that this image, the output image, you may end up with lots of them, you may end up with a lot of dimensions here. Depending on how many features you decide how many filters we decide to use. So still fall by four. But those are different filters. And, you know, you may end up with 100 images. And that means you take these images, and you stack them on top of each other and head of each other as a representation of an input. So so that's the true value of deep learning deep learning is learning a lot of Allah to features or a lot of feature in presentations of your input. And if and again, it's not expensive. Because this one is six times six times three. So normal presentation, it's 36 times 336 times three is 108 inputs. Okay? So for you, if you're using a traditional network, in order to do 90 For example, here, let's say let's say you want to do 16 will be 108 times 60. So now you're already going to adjust this one is 1600. output by learning eyes in nine times 100 900 900 900 prompters so right out of the gate, you can be as extra visa extravagance, as poss as you want. Obviously, this is too low that you wouldn't be able to extract 100 This one absolutely allot this one up to your decision. But if you want to go crazy, you're still still need to learn some 900 parameters so it's, it's it's essentially it's essentially control. So there is nothing much in terms of expense you need to do. So let's let's take an example. That will tell me how we're going to do things. For example is remember, we convolve. We do padding and we use strikes. So those are the things that we control. So let me say that we have an image Sounds good that is 50 by 50 by three okay. And I want to start doing stuff I wanna I want to apply convolution. So I decide that my, my filter size will be three, three by three, I have no padding, and my stride is one and I'm going to use 10 filters. So my filter size is three, so 50 minus three divided by one plus one equals 48. So I end up with and then I have 10 Damon's have 10 filters. So I end up with something like this so 48 times 48 times 10. So let's first I want to do another convolutional layer on it I want to use a filter size of five on my stride to be three I still don't want to do padding and I want to double the number of filters. So my filter size is five my stride is three so 48 minus five divided by three plus one equals 15. So, there is a reduction here. So I go 15 by 15. Mark they have 20 now so times 20. Okay, I still want to add another layer and in that layer i i still want to use five fective size of five by five strides three no padding and the dimensionality is 40 Okay, this means some calculation here 15 minus five divided by three plus one equals four so this is this is my presentation have the input and it's gonna be it's gonna be interesting because now I'm gonna have four by four okay, go all the way inside to Fortune I started 50 by 53 channels, and I was able to go all the way to four by four by 14. If I were in normal case, I would have I would have 7500 features that I needed to fully connect to a hidden live reality I have here three by three so that's nine nine way parameters times 1090 So I need to learn 90 here. I need to learn 25 by 20 I need to learn 500 Maybe here I might I might mess up the math To get my point, same number of parameters, I need to I need to learn here as well. So overall, I need to enroll our parameters, although I'm doing whole lot of feature extraction so on and so forth. So this is what happens typically, when it comes to your network, we start with an image, and then start extracting multiple features representation of the actual of the actual image. So, so far, we've shown that we've shown that we've shown a construction of a convolution your network. But this is not all the story, actually, there's big bits of the story that I have intentionally missed a bit numb, because I'll have to explain few things. Myth number one, if you folks remember these neural networks they have an activation layer of sorts. And they do a good job they do remember here. They normalize your inputs. They show excited excitingly, like, if the input is a neural new neural network is excited or needed. There's all value of the activation functions on the nonlinear transformations. So what is it here? Well, as a matter of fact, normally, you do have some sort of a nonlinear transformation applied to your input here. So you should have some sort of nonlinear transformation. In most cases, we're looking into a real a real function oops in most cases, so, after you do this calculation, you know, this 141 It gets represented, it gets passed by the activation function. So this, the actual value here is activation function 141 This one will be represented with an activation function of 206 Six, this will be presented with activation function 243 102, you know, like, depending on your function, if it is sigmoid. And that's would be the output that you get here, something like that. So that's number one. And that gives me a perfectly understood explainable function, you know, you would have your output somehow and you could train your parameters Eve right with backpropagation there isn't a big problem, all you need to do is to calculate delta for these particular weights with with backpropagation it works and works just fine. So, is this everything that we need to know about convolution neural network as a matter of fact, no neural network all this is explained by what has a an interesting layer here that is called pooling length that comes sometimes in between convolutional layers. So the pooling layer is is is a contentious term. So first, the whole the word pooling layer is not recognized the word lave. It is not recognized as ill. So before I start explaining why it is not recognized and so forth. Let's see how it actually works. So if we take this example. So that's input and this is a convolutional. This is the implementation of convolutional layer, which once you get there, and then you pass it into pooling, but pooling does you choose a pooling size, a filter size so similar to this and you start going, it says three by three. Or let's say it's two by two, three by three to say three by three. And you go here over these three and choose an aggregate of the signal signal aggregation. What are the possible aggregations, Max? Min average, all these are aggregations, right? The most commonly uses max. So for example, one, two, these nine variables, which one is the max was 207. Okay, then you slide and let's say, so the filter is three. And the slide is one, you could choose different slide value as well. They say the slides is one. So you do this one, you do this one, and and the and the the the max value is 323. And then you go one step off. And the maximum value here is 295. Think. And then you take a step here. At the maximum value here is I'm sorry, this one is 333. And this one is 333. So, you take this fall by four, and you make it into two by to apologize so, four minus three divided by one plus one equals two, so two by two. And that's called pooling. Now, if it is mega max min average, it's just a calculation. So why, why is there an issue with calling this process a layup, or it's a downsampling the sampling process, it has no learning there isn't a filter you learning all it does, you decide, you know, you filter size, you stride and the function of the filter, which is an aggregation. So you're not learning anything, you're not learning any parameters, so there is no learning. So it isn't a layer because layers usually neural networks have have a have a description of of learning. It's also problematic in the concept of Neural Networks. As we started, we started artificial neural networks by saying well, artificial neural network is mimicking the brain function mimicking the brain function by mimicking the way neurons operate, and then we say it will the neurons aggregate the chemicals they eat, they get to the brain, the neuron gets excited and it fires or inhibits. Okay, good. Okay, where does pooling come in, in this particular exercise? Is it aggregation in the interest of act of exciting in neuron, that's this process. So you're not exciting and also the new we need to learn what excites the neuron, so there is no alert. So doesn't contribute into exciting in Europe. It doesn't contribute into firing or inhibiting a neuron. It doesn't get it doesn't change. With respect to the output, there is no learning. So what is it? Well, it's all in all intents and purposes it is it is a sub sampling. You just reduce your sample to allow them and it's dimensionality reduction in an interesting way doesn't. If you replace it with dimensionality reduction. You don't get you don't get the same performance. So that had made it a challenge for much of the result. shares to figure out, well, why do we have pooling in convolution neural network if it doesn't present a biological function. But it works. So convolutional neural network works with pooling, every alternative of pooling doesn't work as well. So if you add pooling, the performance of convolution, neural network improves a lot. If you replace pooling with some agreed upon the machete reduction algorithm, say PCA, it doesn't work as well. So without it, it doesn't work as well as alternative to downsampling. It doesn't work as well. And we can't explain why it works. From biological perspective, so pulling works, and we didn't know why. So that's why although we represent it, and we talk about it here. As as as a function, we generally don't know why it works. And and the best explanation I've heard about pooling is that it allows for the stronger signals to stay. So that's after the fact that's people trying to explain why it works. So here, if you're taking a max pooling 207 is the strongest signal if an image, so you want that signal to be retained, all the signals are weaker, so they didn't present much information. But then average should be better, maybe maybe mentioned the better. Wi Max works better than these two. So that's one of the explanations. So anyway, so that's the pooling layer, we didn't know why it works, but it works. Okay. So we have an image, it goes through a convolution layer, it goes to a nonlinear transformation. It goes through up pooling. And, you know, it starts with maybe with three damages, zero for damages. And after a lot of things, end up with something like this one. So remember, we're doing classification. So this one looks good, but how do you classify the output? Well, you have to take this one, actually, and flatten it. So you have to actually unfold it, all of it, and flatten it into a victim. So for example, this one is four by four by 40. So four times four is 16 times four is 64. So 640. And then you may do neural networks, which becomes a shallow network. And then you get connected to the output. And then you have your performance. And then you do your back. You do your back propagation. All the way like no remember, the weights are here. The weights are here, the filters, so all you need to do is to update the weights based on the in the on the back propagation. And if this looks weird for you to understand that, in fact this is how the network looks like. So you didn't have an issue with backpropagation. It is just a physical representation or logical representation. Okay, even the three dimensions is just more connections to this more connections to the same note, that's all. So, the flattening yield is an extremely important concept. So that's a victor. So this one is Victor. At the present presents this one and here I know we have a shallow, shallow neural network. You could have other trees I could have support vector machine, you could have it logistic regression, whether the goal behind this entire exercise is to do a proper feature extraction of an image, and you transform the image from its current feature space, to something that is more representative, something like this. So let's take a look at so the history of CNN. As I said, it's been suggested, for a number of years the first model was inspired. The first work was in the 50s and 60s, Fukushima had a new cognition in 1980, that inspired CNN in 1998. It had been applied with some successful to a larger problems are all the way up and not to a larger problem space all the way up until 2012, where Alex Krishna Wysocki pre shift ski. And different Hinton's and others had published a paper that have shown a eight layer again, not deep white, eight layer of confusion network that had successfully classified 1000 classes later, some nearly two exclusionary to cut deeper layers like 1000s, hundreds of layers that had higher performance. But the first one was, by all definitions, a shallow, almost a shallow network, and this is the, the neural network. So you see it started by a small image you had destroyed value defined. And then so instead of instead of of, of three channels, we become 48 COMM 128 192 192. And we started adding reducing the larger dimension to something that's smaller 13 by 13, stuff like that, all the way to 13 by 1300 28. And then we just flattened the input, and we're on. We're on a normal Cheju shallow neural network. So this, I see here, max pooling appears as well. So here you see all these things in place, and and input layer, and bunch of other layers, and you have nothing much. And again 1000 plus. So that's that's neural network. One last thing that we need to note about your network is that it has these following parameters that you need to work on defining. Because some of you will ask me, how do we define the filter size? I don't know. How do you find the stride? i We didn't know? How do we define the pooling mechanism? Or was it No, or its filter size? Or its stride? Do we do padding or not? I didn't know all these hyper parameters that you as a practitioner need to figure out to solve the problem because notice here that an Alex neural network we had a stride of four for example, that was a pipe parameter. That was decision. Alright. So again, convolutional neural network is an interesting exercise test lots of work that needs to be done. In general, it's, it's valuable and it is has been fairly successful. And and and and it's it's currently the de facto tool for image recognition, voice recognition texts. revision bunch of other applications. Next week we'll do autoencoders. We'll do recurrent neural networks, and we'll do natural language processing. If I finish all that next week, then that will include all the parts of the course that is concerned with neural networks or with connectionist models. Thank you and see you in our discussion session.


ECE657Lecture 7
Fri, Apr 07, 2023 9:09AM â€¢ 1:54:01
SUMMARY KEYWORDS
input, word, recurrent neural network, network, features, auto encoders, output, present, neural network, represent, function, encoding, state, prediction, meaning, apple, weights, monarchs, activation function, similar

Hello, everyone, welcome to our seventh lecture of, of this course. Before I start today's subject, I'd like to go over a few things that I haven't had I either had failed to cover or covered in non clear way. So for the first one is, is the the first one has to do with the padding in convolutional neural network, the padding and convolution your network, the way we've presented it is basically related to how much padding you need to add if you want to maintain the output size. And I said, if you have one, then you have to pad by two. Which is correct, but the way you pad is basically you add one here, you add one here, and you add one here, and you add one here. So if padding is one, that translates to adding one on each side, so that that was a point, I didn't think I have clarified last week. And I wanted to make sure that it is clarified here. Another subject that I think I have glossed over and maybe not even covered is auto encoders. Auto encoders is an interesting subject in that it deals with emission reduction. And when we say dimension reduction or really mean compression of sorts. And it deals also with what you called what we call latent representations or presentation of data. So you have large, large data set, you know, have your features, you have the data set itself. And in one or present this this data in a way that the intrinsic information in it is maintained, what you usually do is you create a network that maps the data somehow into them into a space or a presentation that maintains its intrinsic knowledge of intrinsic value. Think of it as you know, the distribution of you know, the function that represent the distribution of the feature giving given the, the class or the feature given the input. So the way auto encoder does this is basically it takes the features. So let's say that you have four features. You build a neural network. And then you connect the input to a hidden layer of some size, that size could be less than the feed number of features, or could be more than the number of features. Both cases do actually work. And what you do is that and this is the difference if you train the network to recognize itself. So your targets are going to be the same features that you didn't put it so your input x, you train x against x one, and over and over and over you try to minimize the difference between the input which is x obviously, and the output which is x as well. In reality, you're not interested in this part of the neural network. You're only interested in the in your ability to create a whole Last have latent features that capture the intrinsic knowledge of the latent knowledge of your input. So this piece is the encoding piece. So this is your encoder. And this is your decoder. And what you're interested in in is building a successful encoder that takes the data from whatever they mentioned it is and maps it to another damage. Now initially, they said there is dimensionality reduction component to it, because the initial implementation of auto encoders included a much smaller number of neurons in the hidden layer than your features. Obviously, your features are not like for features, your features are usually it's a large feature space. But there are implementation of auto encoders, where the hidden layer has much more neurons than the input size. And it does work well as well in terms of encoding. And what works is basically your ability of extracting hidden features that aren't necessarily captured by only the input feature. So if you want to think about encoders, if you have 100. Features, auto encoders might map it into a space where we're 10 features are good enough, which happens to be those features. Okay, to capture all that, and could map it to a space where you know, 200 new features a mesh, that better represent your data. So it's it's two things and and both of them surprisingly, do work. There are variations of the auto encoders that are being represented or described in the literature. The auto variational or variational, auto encoders is one of those variations. So that's auto encoders. In a nutshell, today's subject. And by the way, this concept, the concept of not caring about the output, and carrying what about what happens here, we will reveal we will revisit this concept later today. So, today's subject is about recurrent neural network. And so far we've discussed feed forward neural network. So we discussed a neural network where you have an input and you move it forward, you have a hidden layer, you moved forward, you have an output layer. And the only case of recurrent neural network was an example of associative memory with Hopfield network. But for classification or regression, we basically looked into multi layer perceptrons. We looked into radius, radial basis functions, networks, we looked into convolution on your network. So essentially, those are the ones that we were able to use for prediction. Today, we are going to look into equally strong class of networks that does do predictions, or forecasts for the future. And those happen to be recurrent neural networks. So before we will explain why because recurrent neural networks are how they work, let's ask some logical questions. These networks do work, multi layer, perceptrons, rpa, RBF, convolution neural networks, they do work and they present value. So the question that may come to mind is basically if you have networks that do actually work, and work rather well, with commendable performance, why would you try to examine other types of networks? Like why is your feed forward neural network not good enough for whatever application that you have in mind? And that's a fair question. We'll have to understand why feed forward neural network wouldn't work everywhere. Let's examine a few cases, a few scenarios. Let's say that If you are interested in creating a box that predicts an output based on an input however, this output is not just based on this input, it's based on a previous state of the input think of it as xt minus one and maybe an A, a much further previous state of the input. So, for me to predict an output, I need to understand what happened at the same time of prediction what happened yesterday and what happened the day before, you know, this is not an unheard heard of that whatever you predict is not just a function of today, it's also a function of yesterday and the day before yesterday and so on and so forth. And maybe you go back maybe 30 steps are in the past. So, how can we represent that with feed forward neural network? Like do we enter the input in this format to some sort of a hidden layer and then we hope that we can predict the output. So, how do we embed the sequence explicitly in terminal so, how do we tell the model that there is a sequence or there is an order with which things do arrive right? How do we do that and there are many applications where the order of entry of the order of arrival of the data points matter. An example of that one is language. Language is the most sequential thing that you could think of language is a sequential sequential or maybe secret language is a sequential process in that the order of arrival four words impact their mean exempt we could say that the bowl came out came out of the blue you know, someone is complaining that a ball hit them in the head. So they say well, I was hurt. A ball came in hits me and the ball came out of the blue okay. You could also say the ball was blue, when it came out. Blue here doesn't have the same meaning. When you hear something, someone says out of the blue means sudden, unexpected. When I say the ball was blue, you mean that the ball has a color that is conventionally defined to be the blue color. So you have a case here where the order with which the word blue and the context defines the meaning and changes the meaning of In a drastic in a drastic way. So if I were to predict a future word. For example, if someone says the ball came out of the I shouldn't be able to come here and say, blue. And I didn't mean the color. Because I know the context. I know the order. So let's not worry about the context. And let's worry about the time the order of arrival. So where do you see this successfully being done? Well, an example of this successfully been done this search that I've done today on Google, I wrote, I want to buy did I didn't finish it? And the answer was Teddy bear, a teddy bear puppy, a two teddy bear. So it understood, basically, I want to buy that Teddy, that it is a teddy bear. And that was the autocomplete of Google. So it didn't make any mistake. Based on the words that I have, and based in the order of arrival, it did not make a mistake about the next prediction when I change the context and I said, write a book about Teddy, as I just was Teddy Roosevelt. So somehow, you need to train a machine that ingest time series input to predict an output based on such time series, I wanted wasn't as important as but so bi was very important. To qualify what Teddy mean here, rate was very important to qualify with Teddy mean, so about you had no value. It's read a book. So those two words that so if we say this is x t x t minus 1x t minus 2x t minus three, let's say we are neglecting a those two words that came, you know, two instances before the prediction were important for the prediction. So, somehow you need to create a system that allows for this sort of of of of prediction. And as we said if I want that system to be a feed forward a feed forward neural network. This whole sequence of arrival, while Ge will just be gone, and that is an example where sequentially sequential arrival of data is important is the stock prices. So again, this is today's stock prices. Let's say that, you know, you want to predict tomorrow's data point. And your prediction, you need to understand that these data points come after each other. Why is that important? Maybe you want to model some sort of seasonality. Alright, so today's June, maybe it will grow and typically, towards the end of the year, Apple prices hit their peak. Alright, so maybe when you predict them, these are Apple You know that you hit your Valley. And now it's going to be like this. So the order of arrival is very important, because you want to learn patterns about seasonality. And then you want to learn where you are within this pattern. So here you have two patterns, you have growth. And then you have seasonality. So here, you need to model the growth, as well as the seasonality if there is any. So that's fairly important. Also, when you do time series analysis or time series prediction, you cannot just put the data as is in any order, and you hope that the network or the predictor would actually be able to sufficiently recognize the data being bien bien un on a time series format. As we said, most existing learning models are not designed to remember. key word here is remember, keyboard use memory. I'll take you to this example here are the model did remember two previous inputs for the prediction? So most existing solutions don't have a function of remembering into their design, not explicitly for them to predict the future. So that's one thing that that makes us say, Well, this model wouldn't work. Because I have nothing here. That tells me there's a memory with which I can remember the art. There's nothing here that tells me that and not just that. I sit here I want to buy Teddy. So that was 123454555 inputs. How about this 11234566 inputs? What do I do with them? Let's say that they have a review rating. And there's review 20 words, there is a review of 30 words, someone likes to write a lot so you have 100 words, that's about all these somehow all these I need to map them to a number one, star two, Star Three, four, and five. So the input is variable length, and the output is fixed length. None of the existing models tolerate that. Again, I'll go to example of multi layer perceptron it does expect fixed length input when you create a multi layer perceptron network. You do define how many neurons you have in your input layer and it is usually the number of features and that's fixed and predetermined as well not just fixed. This is not from the parameters that you can control. So if you have an input that varies in length, then these models don't didn't work. Which brings us to recurrent neural networks well regarded your networks are designed with memory in mind are designed in a non conventional or non committal way when it comes to the definition of inputs, outputs and connections. As a matter of fact, the first successful implementation of recurrent neural networks happened to be helpful fields network. And how fields network, if you remember, or something like this one What did you find states. So there are no input, there's nothing here. And somehow based on the configuration of the network, you change your states here. So sequence obviously matter in terms of states. Now, that's not sequel of arrival, but the way they're positioned in your network matters. So the positions impact the overall energy. And if you remember, in the example that we gave in Hopfield network, the first example, we had two configurations. And based on the arrangement of the states, you may end up with two different end energy output. So Hopfield networks had memory. Because the weights here are built to remember. So here's the concept of remember, is honored. And they, and the positioning of your states impact how you calculate your energy. Now, that is not to say this is time series or the arrival. But in fact, their order, and the network does matter. So that was the initial success of recurrent neural networks where we've, we had a stable, functional neural network. But if you remember what I said at that time, that even though this was presented 1982 and 1982, this was just good for research value. But there wasn't much you could do with it. There isn't much you could do with it, because it's an efficient, it's about storage, and maybe you're not interested in storage, maybe you are interested in storage, but it didn't address prediction questions not in a good way didn't address forecast questions not in a good way at this is none of that that became the case remain the case up until 1986 When David Roman Hart et al, and others present presented an ingenious idea by the way built on on the on the light not on the basis, but inspired by Hopfield network. If you read the paper, you will find that the reference Hopfield network I think more than once and explain the inspiration. So David Romo has presented a recurrent neural network that has the concept of of things that come together or has has has a j are adjacent to each other in order of presence have some sort of relationship that we need to care for. So you know the logic says if a comes with B, the A and B come together then the connection between them the connection between them should be strong. And that's in particular particular applies to language for example. Now before I get example, This means if a is present and B is present, if you go and you read a book and you find that a and b are present near to each other, there is a strong positive connection. If A is present and B is not present, this implies strong, negative connection. Alright, when is there B is is there, when is there B is not there, for example, fury at home or flood of text, apple juice Jews have a strong connection so, if Apple comes first X t minus one, then there's a good chance that Jews is x t. Apple there, for example, although they may come, you may find them existing I'm sorry, not enough of a teddy bear also have a strong connection. Because they, you know, you find them a lot find that they, they they come together a lot. Now, if you have apple and car, then that implies we connection because you didn't usually see these two words together. Now I'm quoting the paper, the paper was written in 1986. They didn't expect that the company Apple is most likely going to launch a product called Upward car. So this is the network that that was designed. This is this is a simple network that resume represent some of the constraints on involving Eric current connection between bunch of words I do. I do honestly suggest here that you folks go read it. Because it's one great paper that explains the genesis of new recurrent neural network. But even the implication of arrival isn't it's the biggest, great thing about this paper. The biggest, great thing about it is basically in the paper we have the first representation of saying there's states where the new state is a function of the old state and some sort of a network connection where you have to network configurations, and depending if the network fires or not. But here it presents that is there is something called state there's something called previous state and there is a network connection that map's the output of the next of the previous state to the new state, if you want to think of it in terms of imagination, it looks like this. So here we have some sorts of activation. Here you have the output. Here you have an input. And here you have hidden states and this is powerful because as of 1986 We had a good imagination of how a neural network recurrent neural network should look like as of 1986. But you know people look at this one, they try to understand it, they try to model it It's confusing. It's how do you program it? How do you envision it, so that it had presented some challenging in terms of concepts. Now, the paper itself reads very well, the paper reads fairly good. It just that this imagination of this concept, it's roughly, it's tough. So the solution, if you want to understand neural recurrent neural network, is to unfold it. So I know I'm saying a lot of things, and many of these things are an abstract the concept of regard to network is not easy. And the best way to understand it is to understand that we have this initially device relationship, that gave us something like this one, where we have an output of one input, so this input leads to an output, we have a state. And that state is function of the output and a previous state. For us to imagine this in a good way, we need to unfold this network. So how do we unfold? Well, it's fairly simple, you always have a starting point of some state zero, could be random value could be zero. And that state is entered into a hidden layer, it's upper layer. It's called the hidden layer for now, where you have bunch of neurons. And you have an input. Yeah, but now if we didn't have this, this would be a normal. This would be a normal feed forward neural network. If we didn't have the input state, if we didn't have the state, then you're looking to you're looking at a feed forward neural network. But now, we do have the concept of initial state. So what's going to happen we have an output for an input. And we're going to denote the output to be one and the input to be input one. By the way, not this is not a feature. This is a full fledged input, you know, if you have an if you have, if you have an Excel, if you have a CSV file, this would be x one, this would be x two, this would be extremely. So the input leads to an output, but also leads to a new state a hidden state. And that hidden states goes to another layer. And that has neurons, obviously and receives this second sequenced input at least to an output. And that gives us another state you got all the way to when you have the final outputs that correspond to the final sequenced state and you didn't have sequence input. And you didn't have a state coming out here may have a state that goes back in doesn't really matter. We're not calculating that value. Okay, so unfolding this network, if I were to rewrite it we have unfolded this network to look like this network, so haven't changed much. I have only unfolded network. Now what are things that we need to observe? Are there are few things that we need to observe? Or the first thing that you need to observe is basically do we have weights? Well, we should have weights so So, you go from an input to the state, or the hidden state part, this is think of this as a hidden state, kind of state. So this is, you know, think of it as the weights between the state and the input to them with NGOs contribute to the states contributes there, you do have a weight between the states, obviously, a one, a two, a two, a three and you do have a weight between the output and the state. Now, in convolutional neural network, we've said that we're interested in parameter sharing, because we don't want to learn a lot, we carry this logic here as well. So we say the weights between all states are the same. And the weights between the input and the stakes are the same. And the weights here are the same. So, here, we see a re emergence of parameter sharing. So my dad, as you remember, last time explained parameter sharing with atomic sharing is really us not wanting to, to have fully full connection between our between the different neurons. So here, if you have a bunch of inputs, bunch of inputs, they share into the hidden neurons, of sorts. So that's the parameter sharing concepts. Now, having all these things can we simplify it, can we write a mathematical representation of this, where we have a good understanding of how, how the math works. So, let's start again by saying I am to be examining this part only this part then I am looking at Y one equals So, y one is basically a function of a zero. So, as the recap comes here, and contributes to the output and x one comes in and contributes to the output via and then whatever contribution they have has to be multiplied by y wy. So, y one and that implies some sort of an activation that implies some sort of an activation between some sorts of activation function before y comes so, there's mix of data, but then that goes into some sort of an activation function. So, we have an activation function here of why that processes wait the weights so, I think I want to do it differently. I'll explain why. So, we said the Y is a function of the input and the previous state. So, before we go to the input, what is a one a one is also a function of the input and as you write it So anyone does just the input and a zero. And then you end up with a one and a one is then digested by one. It's the same math, it just makes it simple because we want to carry you, I'll explain, I'll explain why. So a one is a function of a zero. Plus, it's a function also of the input, plus some bias. Now, why one is a function is it's, it's, it's the digestion of a one plus some bias value. The reason why I did the math this way is because I, it's because I want to be able to reuse a one for a two to be something like this one. So, this math allows for reusability with the output as well as with the new state. So, again, the output here is a function of the input as well as the previous state, the input and the previous state together represent the present state. So, the output is a function of the present state and the present state is a function of the previous state and the present input where the same token y one y two here is a function of the present state a two which is a function of the present input x two and the previous state a one which is a function which is a function of x one and a zero. So, in a way, a zero a one a two all the way to a n plus one produce a n which in association with x n contribute to y and so, if you think of this example this is x, this is x 1x 2x Three X 5x Six. So, those get entered to a neural network where y six is a function of TD but also with of the other ones, and whatever state they had produced. So that's the ingenuity of the of the recurrent neural network. So, to better generalize, a t plus one is the activation function by the way, I keep seeing the activation function, most of the time it's 10 h of W A of the previous state plus w x of the present input plus some base value and y is another activation function that deals with the present state and some ways we can further simplify this one by saying by taking these two terms, so we say think of it as See a t and X t plus one and you could say no to get explained W AE w x 80x t plus one these are weights. So, I can collectively refer to them as W A. So, this equation this is the principal equation that we depend on becomes something like this So, again weights, these are weights, these are trainable weights, so, we don't very much worry about them, we'll find with them and we can train them. So, the question is how are we going to be training this network now we have parameter sharing, we have hidden states we have all things all reality is not that much reality as we said this is the state so, whatever happens here represents the state. Alright let's use back propagation. So, for us to use back back propagation, we first need to define our loss function. Right, so, we have multiple outputs, which means we have multiple loss functions. In this particular case, when we have multiple outputs, our loss function can be thought of as a cross entropy function. So, entropy itself is p log p. So, that's entropy, you know, if your output is a probability of the next word appearing. So, an interview would be summation of P log P A binary entropy would be y log y plus one minus y log y. Again, you didn't even have a range of probabilities as they are one and cross entropy with b y log, I hope I'm not doing this wrong y hat plus y minus one y log Y minus Y hat. And obviously, we want them to be exactly the same so we always get our loss being zero. So, if y hat equals y then this gives me zero anyways, So I calculate loss for this function, I calculate the loss for this one, I calculate the loss for this one, and I calculate the loss for this one, and then I sum them. So it's the loss is basically a summation of the different loss functions. Once they have that, all I need to do is basically depends where I want to improve. So for example, so I take my input, the input comes in, it gives me a one, and gives me y one, two moves here, a sec, second input comes, why to a to, and this way, all the way until I finished my my forward propagation, and that gives me the different ELLs they have. And then I start minimizing by going back. So I go back here, I calculate a Y, I go down all the way here, I try to calculate delta x, for example. And then I go here, and my goal is to calculate a. Because I am able to go back from one state to the previous state, i e, from t to t minus one to t minus two, to T minus three all the way to one. This is seen as going back through time, that is called back propagation through time, it's back propagation, it just goes back goes down different routes. So it may go this way. And this way, then here, delta WA, so, what impacts that delta w x A here is a function of these two changes. And then maybe you take that, and you could get something different here. It just updating your weights, because of the different weird or interesting connections. Now, remember, recurrent neural networks and the easiest to imagine, because you have parameter sharing. And you have the different paths that go through the same parameters, but goes to different places. But do remember even feed normal feed forward neural network, you have something like this one where you do have the parameter sharing, confusion or network or not even profit sharing, what do you do have reusable calculations for the feed forward neural network? In regard to your networks, what I presented so far is was just one configuration of it. And that configuration happens to be you know, that configuration happens to be many, to many configuration, or many, where you have the exact same out number of outputs as the number of inputs. There is another arrangement where you could have many to one. Remember my example earlier about the sentiment analysis, given one star, two stars, three stars. So that is another example of your network, a recurrent neural network. But instead of having multiple outputs, you'd have only one output that correspond to the stars of your assessment. Now a reality that doesn't change much other than we'll just calculate the loss here. And then you have to update your weights this way. So that's, that's the only difference here, there is, there is another arrangement where you could have so this is called many to one. You will have an arrangement where you have many too many to someone else. So, you could have many too many. Where if you want to think of it you could think of it as as as in the form of translation. So, if I translate from English to French for example, you may end up with number of outputs that are less than less than the inputs. So, you could have many too many, but with different number of outputs and different number of inputs, you could also have one too many is not common, but it exists where have one input only and you have multiple outputs. The active the matter is that this is only triggering it outputs will be that will become the input for the next one. And that will become the input. And that will become the input. So, one too many. The way to break is we have one input that triggers an output. So anyways, these are some configuration for recurrent neural networks previously, especially when speaking about sentiment analysis said, Let's have an example where someone had a feedback and says this place is great. Okay, I don't want to do sentiment analysis, some sort of rating based on this feedback. This place is great. What I haven't mentioned is basically first, this is word this is a word this is the word is called this th is, and this is another word. And this is another word. And this is another word. I haven't stressed this. But machine usually deals with numbers. They don't deal with words. So the question that comes to mind first is how does the machine digest these words? as input? Right, how do you have this place is great as input? Well, there are many ways to represent words. There are many ways to represent words. So first, let's, how many words do we have in existence? Well, Oxford Dictionary shows around 27 230 73,000, headward. root word maybe of which, like 171k in use in one way or another? Okay. I'll be generous. I'll say all variations amount 1 million, it's definitely not one week. This is a very, very limited number of words. It's not like the images where every day we produce a new image. And with different variations, you do have a limited dataset when it comes to words. Which brings us to natural language processing, processing. So the two things that we have the need to represent words with numbers for the machine to digest and the fact that now numbers in any given language is limited or limited. The number of words in a given language is finite and limited and known allows us to think how about we go, and we take the entire dictionary, let's say we have a corpus of 10,000 words, I'm just simplifying. And we create a 10,000k vector when every number here is unique corresponds to an equal, say, if it is the letter A. The first entry of this vector is one, everyone else is zero. If it is the second war word, which is maybe Aaron in the second word is going to be one and everything else will be zero. And maybe if we have home to be someone like this house or house do something like this. So every word in my dictionary has a unique representation. And it's fixed, that doesn't change. And, you know, I ended up with something like this where I have 10k by 10k. And it goes diagonally for the word as pair the representation of the dictionary like all zeros except for the diagonal, and so I know that every word here correspond to evict to one call. I can do that. And that's actually you know, there's a name for this one's called one hot encoding, I encode every word uniquely to a vector of numbers. Okay, what so how can I use this one? Well, it's very simple let's go to this example so this play place is great. All I need to do is I'll go and find the vector or the you know the vector of numbers of values that will present each of these words and you know, I train my model this is the input I just trained my model that was the problem with that one was now the model actually works. Though every word is unique and uniquely represented, but if I want to say this place is great, or this place is awesome, or this place is good. Do they mean the same thing? Let me rephrase this. Should they result in the same rating for the restaurant? This is a restaurant so if I train my network to recognize that if someone says this place is great thing, give them five star Okay, so I map the input to the output if someone says this place is great give them five star they give this translates to a five star rating okay and then an input comes to my machine and says This place is awesome well would that be five star awesome was like great should be five star, but will it recognize that also men great are similar misplaces bat so, this may be one start with it recognize that bad and great are different again this place is remains to be the same word the final word he changes so that's a question Question number two if I have two books if I have two medical books how do I know that they are similar with this arrangement is the one hot encoding the only way for me to know that they are similar is by counting the occurrence of words. So I have here my words for 02 or n have the documents document one to document in I started counting the actual words and you know, I see if this count here looks like this count document to see if they have the same count then they are similar but that's if they have the same words. So what if they don't What if I say that I like talking to the monarchs are not alike enjoyed. I enjoyed NSA, I loved conversing with the Royals, it's a this is document one and this document two. Okay. These two sentences are exactly the same, they have the exact same meaning I enjoyed talking to the monarchs, I loved conversing with the Royals. If I do the one hot encoding, I find that these two words are the same. These two words, these two words are the same. And everything else is different. Which means if I were to ask what similarity between D one and D two says similarity of D one and D two is maybe point one. So two identical whoo st sentences in terms of meaning in terms of the value that they can vary and the sentiment that they convey those two different words, different sentences. Or if we, if we, you know, generalize that to documents or stories or articles, they didn't look similar. Language isn't about the semantics. It's not about the words. Language is about meanings. It's about conveying some contextual information So, although the number of words is limited, you need to somehow represent them in a way that you know preserves the different qualities, the word has, conserves the value that the word has. When I say love that enjoyed they need to look similar to each other. When I say monarchs or Royals are these are synonyms, token and conversing. These are synonyms. one hot encoding doesn't care for that just cares for word this word exists in the calendar and therefore that location in calendar will get a one and everyone else is zero. Same goes with this one. It's location we'll get one and everyone everywhere else zero conversing start with a T so it's at the beginning of the calendar talking I'm sorry conversing starts with a C. So it is the beginning of the calendar talking starts with a T so it is at the end of the calendar so to similar words that don't live at the different sides of the dictionary. So, the question that comes here with natural language processing given the word natural here is that is there a way Is there a way to encode the words meaning to encode the words the words meaning the words is meanings the way that we encode so when you look at the acid as a numeric encoding of a word you're not really reading a numeric encoding of a word you reading and numeric encoding of of of meaning of quality of sentiment or maybe feeling scores feeling here maybe attitude at it attitude, I feel dread this word attitude you know great and awesome are the same that and unqualified could be the same happy and ecstatic are the same you know these kinds of things. And this brings us to the subject of feature representation so, if we want to qualify what words mean then maybe we should look at the features of a word. You know, the word has features like Is it is it about feeling is it about quantity is it about is it about description is a word about an animal it's about an object okay. And then based on these features, we should be able to know force are similar or synonyms and stuff like that. So here's an example of words or these words and please forgive me if they have my understanding of the language is limited. So man say man, woman King, Queen, orange, apple Monique Royal we say here that the the the features could be you know gender could be the status of royalty could be age could be instant object is an animal is the word and does present an animal is it sweet you know Is it edible and we start putting numbers. So, you know gender a man all say the word man who presents you know to a certain to some degree the word woman also represent a certain degree agent in the same token, King in many ways is associated with ginger and soy is queen I mean culturally speaking, and again this this acids will be also limited to English because that's not the case this is not the case in other languages. So be careful orange maybe not Apple maybe not monarch well could be could be maybe maybe not let's say that in our context when monarch is associated somehow gender their context when they aren't so we'll say just point five as royalty well I get royalty is not associated with gender royalty is very strongly associated with the notion of King and Queen orange I haven't imagined it to be royalty nor is it an apple monarch. Well say it's by definition royalty. Age, you know, does man and woman associated with age maybe if we're looking into adulthood? So maybe kink? Maybe there's an implication there that kings and queens happen because of age somehow. And if you hear a king and a queen and you think of age, someone is older the notion of age has a meaning. Orange maybe there is something there ripe apple ripe orange monarchs while assumed has the same association as king and queen objects in a man and a woman king queen and maybe nothing is an object is an animal you know humans are animals maybe so kings you know like the OF THE LION KING you have queen bee I don't know if this monarchs royalty comes with that sense what maybe maybe not. So yeah, like I think there's animals that have the same notion of monarchy suite. I didn't see anything here. Maybe apple and an orange have something like that. Nothing here edible, so that we don't eat kings and queens. Say there's point nine here something like that. If we somehow ended up with with having a presentation of words. So this is a word by some features alright. And the representation is meaning driven is not a trend. We may end up with interesting finds in a women find that that that the relationship between men and a kink is similar to the relationship between women and equi. So a man to a king is what's a woman or queen, and the distance between a man and a woman is the same distance between King adequate, right. You know, if if if if man if we say man minus woman plus King Sorry, man, you cannot do that you can say minus minus one, you say King, logically minus man. So you take that gender term plus woman should give you a quick, right you take the gender out of King, and you had women the end up with the Queen, so, a king minus the man here, so it gives you minus four plus our minutes gives you minus 99, that's close to quit. Same goes here. So, if you do the math, then this relationship will become true. Again, this is linguistic. And we'll talk later about the linguistic bias. When we wrap up the subject, we'll talk about how some of these things wouldn't work because of the cultural bias in the language. But anyways, let's assume that we don't have an issue that so you end up with something like this. Well, that's fantastic. Because that also tells you that royal is exactly as monarch. So, when I go to this word, I find that royals and Monarchs are the exact same word and talking and conversing will also be the exact same word and enjoyed aloft will be close to each other in distance. So, that is from from a language perspective, or from from from linguistic perspective, given our goal is fantastic, because now we have features that are associated with words and those features somehow do represent meaning. And we can derive similarity if I have an example, on exercise when you say optimize for a ward, where so so give me the maximum similarity. So find me a word that has the maximum similarity with King minus man, plus woman. That word will be queen. So if I do the math, I'll find something like this one. So this work was presented by Thomas Malkoff. And three journal publications. So, he demonstrated in the three general publication, that if you do the, of if you do the formation find that a man to a woman is an uncle to an aunt was a king to a queen, and this is between King to kings and Queen to Queens is exactly the same. And the distance between King and a man is the same distance between women and Queen. And the distance between a man and uncle is the same distance between women and act. So, it is shown practically, that doing this particular conversion of words into feature space gives us meaningful similarities or meaningful relationship between different words. And not just that it's not the man and a woman, the queen, the king. It's also places and locations you know Portugal and Lisbon, you have Spain in Madrid, you have Greeks and Athens and Italy in Rome and you have France and Paris. So, you see this is the country Yeah, the countries here. So you have the countries here, and you have the capital cities. And the countries are also aligned based on the geographic closeness. So, in, so China's very far from Portugal, but China is close to Russia, and close to Russia and Japan. So, as Sam goes with the capital of China, Beijing, it's close to Moscow, I mean, somehow and talk you what is far from this bin image. So, what we were able to do with this one, I mean, this whole presentation of the feature presentation of words that we convey geographical meaning, we convey like literature meaning, we convey conveyed cultural meaning, we conveyed all sorts of meanings and the future of presentation. So, to reiterate, if we are successful in presenting words, based on a host of features, you know, how many features Well, according to the research done by Mark of and others, it's between 205 100 features, usually, you find yourself doing 300. So, based on a successful feature of presentation, there is a good chance that you will do a very successful word embedding. So, what this is called feature representation or word in embedding you could say also word vectorization. All of this is the same thing. You embed meanings, you put the word or victimizations is general. So, I want to be aware of it, you embed meanings or your present features. This is contrasted with word representation. Like the one hot encoding. Okay, so the question that you may ask me is, how likely are two questions that I expect to get the first one is who decide those features? The second question is, how do you get these numbers? Right? who decide the features who decide what are the features? Because he said he has ginger oil and age and objects in this from the example in the paper. But, like, who comes up with these names of features? Who says that gender plays any role in future presentation? Well, in reality, this is just an example. In reality, no one decides in what are the features? So let me stay say a few things. One we don't know the features. Later on, decide the features. We don't know or decide the features to the future values resulted from and I'm gonna say unsupervised but that's not entirely true because the unlabeled learning process I'll explain this one this one might seem weird, but I'll explain it so, for me to explain to you how this how the embedding is done I'll start by the first work by Monica of and others on feature embedding a feature representation. So, what they had done is basically they presented a Cartoon Network and they say that the input of the recurrent neural network is the one hot encoding so you feed in words via one hot encoding and you hope and you train them against the probability that the output word is a word that has an affinity to the input what do I mean by that? Well let's say that to train a network First you go to the internet collect law large amount of text right like take all the articles on the internet take all the ebooks take all the transcripts of interviews take anything that you can get your hand on that is in English okay so that's number one construct an affinity matrix or a co occurrence a co occurrence matrix so what do you mean by that it say that the internet has only these two sentences in English I I like the sky I like the chocolate water so, let's say that the whole Internet has really these two sentences What do you do you build your corpus and your corpus is basically every word that is in your dictionary or in the internet. So either word like is a word the sky and in chocolate we you don't repeat the word Morton's I like the sky chocolate and then you do something called wine Graham words one gram. Basically, you look at the word and see if the if the other how. What is the occurrence of of of any other words in the dictionary? Right after for example i How often does AI comes after I zero? How often does lie or did like come after I to house it in my day. This is my entire corpus. This is my entire everything I know about English. How often does that comes after I see house in the sky comes after 900 How often does it comes after like 002 000001100 all zeros, all zeros here. So this is CO occurrence matrix. So, when you build a neural network, you're saying wait a second, I'm gonna I'm gonna see I'm gonna predict this recurrent neural network x at minus one, A, T, this is y t, x t. So I'm gonna say if, if, if, if if x is i, and y is, is bad, so let me do something else. If x is VA and y is SKY What are the chances of sky come after that? I would say half so that's the probability of sky coming after that, that's that's how in the dictionary the CO occurrence of them so that comes first and Skye comes after is one divided by the summation of this one age right. So, now, I take the one hot encoding of the Navi WX wa wa and I start trying to get y equals half okay, I start trying to get y equal half let me expand this a little bit and say it isn't just one word I want to know if this sequence comes what are the chances sequence? So if I have something like this one so I like the again, one hot auto encoder, one hot encoding here. One Hot Encoding here. One Hot Encoding here. And I train against sky okay. So if you see here, I like I like I like that could be sky could be chocolates, it's half as well. So I'm trying for Sky the probability of sky appearing which is half, so that's my target, my target is half right, the probability of sky appearing after the sequences have based on my co occurrence matrix. So I build something like this one. And I train I train my W's here x and this is a zero, a one a two, a three here and I start training. I see how it goes. Now mind you, if you do that, then you're doing few other things. First thing you're doing. You're inputting a vector that is 10k into your network, so that will have to be multiplied by w a x. So for this one to be multiplied by w x. W A x has to have the same am compatible dimensions. So has to be multiplied by think. So what does this represent? What represents how many neurons you want to have here, right? Reality represents how many features you want to have. So let's say you're having 300 seats okay so I want to flip it let me flip it because it's unlike this one so, let's say that I have 300 So, this one is thinking oh wait this one is 300 Sorry So 300 times thinking, so, this is 300 and this is 10k multiplied by 10k times one. So, if I want to have the word of a man that word is represented by source of this row this column. So, the first word is say the first word is is say the first words is a just number just letter A okay. So, a zero which happens to be one and all zeros This is randomly this one is randomly initialized to do all of us to get a you have to multiply every element of this 300 by this one so, you multiply row number one with this one and you add So, multiply this row first row bye bye the one hot encoding vector and you some to make it like this, so, multiply this by this and you sum the multiplies a second by the Hutton coding and you sum so, if you notice your old souls multiplying by one so, everything else in the auto encoding is zero which means you're keeping only this column to represent the letter A now, if you have the word yeah the word King for example which can be represented by by the hot encoding of one here it turns out that King would be this victim. So, whatever numbers here in this matrix of weights will represent the kink. So, if we train this network somehow to maximize the likelihood of half happening this will change your waiting your weights of w x here to reflect that reflect that for AI to reflect that for like deflect that for the fact that for every word in your input, and if you do it enough then you will end up with a representation where you have a matrix you have a somehow a feature embedding. Now, I will explain next week two algorithms work to veck and love to better explain how this works. So don't worry if this is not clear yet. But before I finish today, I would like to explain the notion why said earlier that this is unsupervised or unlabeled. Similar to the example here waste similar to the example here, these sentences I didn't, we didn't get them from training from from labels. Right, as I said, you go to the internet, you collect as much corpus of words as possible, when you use these words, to understand the probability of certain words coming after certain sentences or, or word after word, and that is what's used to train this network. So, in a way, no one is doing the labeling, there is no labeling that says juice has to come after Apple, no one's saying that, it just that it is naturally hence the word natural language processing. If you read if you process enough text, then it will be naturally it will naturally emerge as a way of representing which words come after which words, and what does that mean, in terms of the representation so it's, it's it's more of scouring the internet and collecting all maybe English text and building this feature matrix. So that's it for today. As you've noticed, most of the material Oh, this is presented in the whiteboard or the blackboard, very few material is presented in the actual slides. Some of it is. So if you want to write after what I wrote, If you want to put down some summary to my explanation, you're more than welcome to do that everything is said or I did is part of the course material. We will meet next Wednesday, we have an evening session. That session will be recorded as well, which is a happy coincidence after today's lecture, because I am looking forward to many of your questions that I will be answering real time I will be recording the session and posting it as part of the material for this course. So anything that is recorded as part of the material. So if you have any questions about recurrent neural networks, or the introduction of natural language processing, I will be more than happy to answer all these questions. So until we meet next Wednesday. Enjoy the rest of your weekend. And have have a good time. Thank you and see you on Wednesday. We'd like


ECE 657 Lecture 8 Part I
Fri, Apr 07, 2023 9:08AM â€¢ 1:07:38
SUMMARY KEYWORDS
word, output, input, context, 10k, matrix, corpus, vector, calculation, features, co occurrence, softmax, probability, weighting, function, called, target, solve, encyclopedia, presented

Hello, everyone, welcome to our eighth lecture in this in this course, today we conclude the neural network the subject of neural networks. And the last of of this discussion will be basically on the applications we have on on on natural language processing. So, last week we we discussed the point where we have an input of source that enters some sort of a process you have an input there's a process, there's an output. I will say that, if the input is a word all or it's the one hot encoding of a ward and the output is some other words then the outcome of the process itself is a feature representation of the word I will give example as a desired feature presentation is when you say a king, mine minus man plus woman gives you a queen. So, a victory, a victory is a victory. And this is the result of lecture. Or even better if you want to maximize the similarity, you want to find a word that is the most similar to the outcome of King minus man plus woman. throughout your entire corpus, that word would be quick. Because you don't have exact, you don't have an exact, it's not going to be exactly 100%. But if you run maximization of similarity, there is often towards me. And many other gimmicks like distance between man and a woman the same as distance between King and Queen. So we were presented with a challenge is that how do we form a corpus? of maybe 10,000 words, how do we end up with a with a feature within a presentation that is, let's say we have 300 teachers the number could be anywhere from 200 to 500. So it's your choice, but it saves 300. So how we ended up with this presentation, we know how to get 10k to 10k. It's one hot auto encoding, one hot encoding, right? Every word here is encoded by one and where the rest of the words are zeros. So we know how to get to this point. We didn't know how to get to this point. And today we are going to be discussing two algorithms or two methodologies that are going to get us to this outcome. The first methodology is word to veck. So you're taking a word and you're converting it to a vector. And to be very clear, here it's a vector of features. So, the idea comes from from from, from from from from linguistic logic on words. Meaning meanings can be inferred from context happens to me quite a lot. Sometimes someone speaks to me in English, I listen to them, I understand most of what they're saying, even if I don't understand some words in the, in the middle. And the reason why I'm able to understand what they're saying is because I am able to guess what the words that I've that they don't understand. I can guess what they mean. And the reason why I can guess what they mean is by looking at their context, there's an actual form formal definition or formal statement. And that is you shall know word by the company it keeps. So, this one tells you that a word can have the first the first statement is you whether the statement is by John Robert Firth, a great linguist of the 20th century. So, the first statement tells you that, depending on the context, you can infer know the meaning of the word. For example, this is pretty good, pretty in this context means very this is a pretty back in this context, pretty means beautiful. And you see both current both meaning meanings used in the, in the literature quite a lot, pretty good, pretty object, or pretty opticals, something like that optics. So, the first one, the first statement here tells us that depending on the context, we'll figure out what pretty means beautiful or pretty means. The second statement can be understood as a word may come in many, many positions. Or many, many contexts. By looking at all of these context, we can infer some intrinsic meaning to it. So, to be able to differentiate between pretty good and pretty optics, you would need to go over a lot of literature to know that pretty carries those two different meanings. Well, how would you know that by looking at the different words, they come with them, that come with them? And then what other words that the company accompanies with it? So pretty good, what else comes with good, very, okay, pretty a very might be synonymous here. A pretty image, what other word comes with image beautiful. So you can understand the meaning of these two words by looking at the context but because you are also looking at the meaning of the context, you'd kind of assume what kind of words they should come with. So that's a larger concept of usual no word by the company keeps. So word to veck, or word to veck, which have been described over three publications or three papers, at least by Thomas Malkoff and others. adhere to this logic and know that there's the logic is by two architectures. The first architecture is called continuous bag of words. And the second architecture is called skip graph. Now, I'll describe both of them as you would see them both in the literature and then I'll draw my conclusion, content. So continuous Bag of Words says if AI is predicated on the concept of AI in know the context can I know the meaning of the word? And now meaning isn't really meaning isn't that isn't that pretty means beautiful or good or very meaning is, what kind of features that a word has. Right is the noun is it's an adjective. Again, we don't know the features, I'm just giving an example of what meaning means it's what kind of features or embedded features or intrinsic features a word. Has. If, if, if I go and examine it, given its context, and the architecture looks like this, let's say that I have the following word Example. Here is a sentence I want. So this is the sentence to buy an automatic car and I want to know what automatic means or what are the features of automatic and I use the continuous bag of words to do that. So I go and find a bunch of sentences where automatic appears. I choose context words of example, in this case, I want what is the context? Why is a Context Card is a context and I would say even n can be a context. Okay. Now the ultimate not the optimum, but let's let's consider that so the my output that I'm trying to predict is if I get these context can I predict can I predict the word automatic as a hot one hot Audio Encoding, okay. Like automatic, my again, my corpus is 10k and automatic happens to be here. Okay, so I know my output on my target output. Okay. Now so it is it's a word of thinking or it's a vector of ticket I do have my hidden layer. And as we said before, hidden layers are best for extracting hidden features. We saw this a lot in CNN, and in somehow in ordinance, so we're gonna say we want to represent every word by the dimensionality of here 300. I'm gonna bridge this gap. So I'm gonna say I have some neurons here I have 300 of them. And then I have my input which happens to be the one hot or to call this is to then I have my input, which is these context words. So I have the first context word want the hot the hot one hot encoding for it. The second by the third. And the fourth being caught. And I would say, car is comes after automatic so it's, it's the word after. And and is the word before. And boy is two words before and want is going to hear for simply say three words before and I'm going to enter the data in the series or sequence 12 So I'm going to enter want fully connected to the hidden layer. So remember, this one is 10k. As we said in the CNN, this means you have 10,000 neurons as an input layer. So the from one to 10k, each one of them is fully connected to the hidden layer so on so forth after I enter this one, I enter the second one also fully connected, I enter the third one, also fully connected. And then to the fourth one, also fully connected. So, I want to ask, so this is the order to which in which they are entered. And I'm trying to predict the word automatic so, you feed the first word you tried to predict automatic, if we just feed What if we read the word want, then the word by then the word and, and then the word caught. Now, let me take one of these and break it down and see how we're going to do it. Because if what applies here applies for the rest of it, obviously, because they're getting in sequential order. So I would have one word that is 10k. It's one had longer term coding, let's say it's an app or whatever it is. And it's fully connected to a much smaller delay. So it gets connected everywhere. Obviously. Now, just by looking at it, you think Well, only this one is activated truly. Alright, because everything else is just multiplication by zero. So anyways, because different you have different words coming in. At every iteration, one of them is activated. So it's very sparse weighting matrix. If we say we have 300 hidden neuron here, it would be 10k by 300. So that's your weighting matrix. So you have your input, which is the word want it's entered into a weighting matrix thin. So, this one is one by 10k. It gets interesting the weighting matrix, what comes out of the weighting matrix is the calculation here and again as we did as we said in the hot in the in the multi layer perceptron every neuron here is a scalar you have 31 300 of them you have an output of 300 here one by 300 the worry about the difference between this way and this way just just worry about the dimensions. So you get one vector of 10k it passes by the weighting matrix in depth to your one to the output of the hidden layer which happens to be one by 300k. And then you have your output which happens to be also one hot auto encoding as you target right. Which should be similar to similar to the word automatic. On we'll say automatically, it's just a target. So that means you have again fully connected from from one to 10k arpt and so on and so forth then you take this So one, this output. And you normally you, you pass it through some sort of normalization. Remember when you have activation function, so you normalize your output to be between zero and one. So this one, we pass it through a function called softmax. y it is essentially something like this one the output is maintained between zero and one, and the summation of it is equal one. So, it's not just between zero and one plus summation of the 10k is equal one. So the probability of every output emerging, so it passes by a softmax we'll end up with something like this and this one is measured against the target that again happens to be automatic, so, the target automatic So, this is your output, this is your target, and then you have the difference between your output target and then you do back. So, this is your output kind of layer, then you do a back propagation, say update the weights here, then back propagation and you update the weights here. And then you enter the new words, you run it against automatic and back and forth back and forth and so on and so forth. So, the output here this one by 300 gets passed by again multiplied by this W which happens to be 300 by 10k. And that gives you one by thinking. Okay, so, at face value seems like you know, a an integer like a feed forward or normal artificial neural network, you have a host of defined inputs run against an output. And you try to do it in a way where the while you're maximizing the chances of the outputs being one here. So the probability of it being automatic is one and everyone else is you. Okay. We sit here our interest is really in, in finding this matrix. Right, our interest is we have a corpus, you have a corpus of 10k. So every word here, every word here has three. Every word here has 300 features. And that mean that represent the tarsi of your corpus from the word app, which is the letter app all the way to the final word. And it says judo. Every one of them is represented by in a way of features. So given that this is what I want to get a feature representation of my corpus, how do I get this, that by this architecture? Well, actually, this whole training process the interest of it is to produce this weighting matrix, because this weighting matrix is stinky by 300. So does satisfy this need. Right. And it's more so because it maps an input. There's a word here. And that word is mapped by this matrix into its feature representation. So this is the feature representation of the word, aunt. So I take want, I process it at past I just multiply it by this matrix and gives me its feature representation. So for every word, I want to get this vector and obviously 14,000 words I'm gonna get 10,000 of these vectors, which happened to be in this matrix, again, because it's one here and zero everywhere else, it will only choose the proper the proper, the proper column that corresponds to the word that's always going to do. So I need to have W, which happens to be the matrix that houses all of my all of the neat feature representation of my corpus. So how about all this? Well, it turns out if you're training your algorithm to inquisitive to understand the word, given its context, what you're really doing is that you're training your algorithm to understand the hidden features of your input. And this is what we've learned in in in multi layer perceptrons. And convolution neural networks, what you're doing is that you're predicting you are extracting the hidden features. And that's it, this this is a matrix of the hidden features. As only and this is only being the case is because the input is either zero or one. So there is no multiplication, that happens when you produce this one other than one being applied to a column or a row, multiple times. So you train your your network, over and over and over until these weights are mature. Enough, and that becomes your embedded matrix. So that gives you a transpose here. Embedded matrix Chavin, p 10k. Might be hundreds every word here. So this is the word that corresponds to a, I said the words that corresponds to Aaron. And this is the word that corresponds to Zulu. This is feature one, and this feature 300. And if you need to get the vector feature presentation of any word, all you need to do is to know what is the index of that word. And you get that row. And that's it. So that's how continuous Bag of Words operate. How does keep grandmas operate? So skip gram is another algorithm. That also does this work. And the way it operates is the opposite of this one, let's grab by the way is the one that is more common. or, more commonly seen, referred to in the literature when people explain how word vectors and skip Crom go to an example. I want. So this is the sentence that I'm using for training, what I might have, I might not what I might have not explained clearly, this is one in one input, you have to go through your entire but you've worse, I mean, let's go you take all of encyclopedia print Britannica, Encyclopedia millions of words there. And you start taking the different sentences, you just go and you take one word at random, you find the context, and you input it then you go to the next one, you find the context and interrupt and you go all the way until you finish everything that's is digitally found in the encyclopedia. So you take the encyclopedia, you create your corpus of unique words, you present them all in order was 100 Auto encoding, and then you start with the first sentence and you go all the way to the final sentence of the encyclopedia. So I'm just gonna use a word that exists in the encyclopedia is I want to buy a home in the city. So as Kip Grom you define the context And the targets. Now again, both of them are going by the logic, you shall know the meaning of the word by knowing the company it keeps. So this word where the word is home. And the target could be launch or home and the target could be sitting home the target could be I'm on my wish, if I use this word for could be that so skip gram, the way to operate is basically you have your inputs. Again, one by 10k you pass it to your hidden layer, let's say 300. And then this one is passed to context. Again, you have your weighting matrix here that is 10k by 300. You have different matrices here are the outputs calculated. At the city different matrices just same matrix gets up this differently. It's called y hat, which happens to be 300 by thinking this is the input. So this is the input word. And the input word is projected somewhere here is projected somewhere here. So, we're still interested in mapping these input words towards their projected. So the emphasis here is on the context itself. The word is used to predict its context. Again, another way of training, as I said earlier, the whole goal is to have this matrix here. And, you know, depending on how you want to train your network to extract those hitting meanings, one might say, we want to fix the word in which we're interested and throw a bunch of different outputs and see how the word behaves around them. Or we through a bunch of inputs and see if they are indicative of, of the world. So different philosophies, but then game is to predict the world to find a good feature representation of the input. We don't care about the accuracy of the prediction here. We don't care whether it's it predicted correctly or not. We don't care any of that. What we care is that if we run this long enough, in with one of these two architectures, and smart enough, we'll end up with our embedded matrix. Now there are things that I've mentioned earlier or glossed over area that I would like to visit back. The first one is basically I said you have the input that goes into the matrix, you get your your input to presentation. So this is the one hot encoding of the words you get to watch a presentation and then you multiplied by the output matrix and then it gives you the target. So this is essentially what what I mentioned earlier. I think there's a process of softmax Applying soft max here to achieve get your actual target, which is probabilistic and you compare that one, I'm sorry, you get your actual output. Or let's leave it at that. And you compare it against your desire to adopt. And, and the softmax thing is not an easy one, you have 10,000 words here. So you have to calculate the probability of an output emerging for the given the input. So this is probabilistic, right. And the way you calculate is basically have the vector of the output to experience your vector of the input, output an input here, divided by the summation of the exponent of the victor of the output given every other input appropriative, the input reduced resulting in any other output. This isn't, this isn't, this isn't an easy calculation. So, remember you're doing this equation for for the corpus, and your corpus happens to be. So, it the probability of other outputs given the input image, so, for the same input, you're creating 10,000 Other potential outputs. And that's how you calculating the the, your softmax. So you have the initial calculation here, that's good. But also you do it 10,000 times because that's how you're gonna get your your your your holistic output. This is very expensive. If you're examining every other word, the potentiality of every other word in the corpus merging given a new input, this is very expensive. extremely expensive. So how do we deal with this? How do we deal with this expensive calculation? Well, there are two ways to deal with it. The first one is sort of it's it's a hierarchical softmax. It's, you have you you have your, your input words, and you know, and you kind of see, given this one, what are the potential outputs that the most frequent ones to appear. So you go to your corpus, and see the words that are not necessarily frequently associated with the input and you exclude and keep doing that. So that you can put your probabilities the probability for the word appearing, given the input, not the softmax, and then that becomes your output or your softmax output that you calculate. You calculate against it's a much more sophisticated, sophisticated, faster way you didn't have to do it. You didn't have to do exhaustively every calculation another potential implementation which I think which is the one that's been most used anyways, is negative sampling. So for skip gram, if remember you have the context. So I'm gonna write in another example here sampling An example is I want to buy a big break house in the city in the city, okay. I'm gonna say my context word is Brick. I would say I'm interested in in and in fourth grade arms so there's a context. And then I'm gonna say I have a word, I have words to choose. Now those words, choose them as I try and choose one true word, that's house. And everyone else says just go to the corpus and get around the mall. So I use lion here. So lion doesn't appear in this sentence, I use Mac, it doesn't appear in this sentence. Or maybe because I'm doing things at random, I may end up with picking the word big, which does appear in the sentence. Anyways, my definition of the target would be if the word is house, then the prediction is one of the one is lying or bag or big in my output is here. Now all I need to do is go and grab the word brick. So, same calculations that we've had earlier you have the word that you want to work on, you pass it by your your embedding matrix and that gives you input word and then you have your output words these are your output words. And what you do is that you classify the probability that the two of them will come out that two words will appear. So the so let me say, so the input originally, we said the probability for every word in the corpus was the probative every word in the corpus appearing with the impact what we are going to do right now is a slightly different logic. What we are going to do is that we're gonna say this world correspond this output correspond to the word house this output corresponds to the word line this output correspond to the word bake, ah sorry. And this outputs correspond to the word back. How are those ones? I don't care for them because they are not part of my calculation. So what do I put here? Well, I could do logistic regression. When my input is that is the the input word and one of the output words, so this is my input. This is my logistic regression calculation. Input Output. Alright. And beta, and beta zero maybe. So this is my kind of my x for this definition. And, and I'm trying to optimize the stat of the input is housed in the output of this classification is one, if the input is line or bigger bag, the output of this classification is zero. So I train my classifier such that I get one here, and 00 and back propagate. So you don't have to worry about solving the softmax for every prop for every other word, you just have to worry about those particular contexts tools. And if I solve for that one, then I've solved for everything else. Essentially. It's, it's, it's making it faster. Solve the problem, given given the limited sampling that they have And that's how we're to Vectorworks. Earlier on is it as two approaches to solving, extracting the meanings or the features of the words from the corpus of the context, the first one is called local context when do are a class of local context window methods, and you know the continuous bag of words, skip cram, they belong to this category. The second category which is the earlier version called Global global matrix factorization class of methods an early example of it is latent semantic analysis pause as early as 1990, it's always always 2013 routes. So, this is the earlier methods. The difference between these two methods is basically this, the this class of methods is localized, as we saw here, just localized to the words that are in your, in the vicinity of your existing word. So, you have a sentence and then you go with this sentence, and he tried to work it out. So, it's more of a local context. It's made even more local here without looking at the overall appeal appearance of the words in the in the language or in the literature. Like the example would be the CO occurrence matrix where if you go to Wikipedia, for example, and find the word smart. So, you create a n by n matrix. So, let's say Wikipedia has 1 million words. So we have 1 million by 1 million, and you go to every word. And you see what is the CO occurrence between this word, and the other ones, all of them. So, you start building to obviously, this is going to be zero. But you start building the CO occurrence, this this CO occurrence, this matrix is global, because you're looking into your entire body of text, and you're examining it, examining it all of it. At the same time, this is what I what I started talking about last week before I went to work VEC because that's the logical thinking, right? I want to see i and have always thought always, in many, many, many case, when you have the word Adi, what comes after it? Or have, right? So how do you make sure that you capture that modify the entire corpus, but again, it's very expensive, 1 million by 1 million and how do you create the embedded matrix? It's, it didn't work. And that's why when the continuous Bag of Words were proposed, some 20 some 30 years later, that one has gotten traction. So anyways, after the continuous Bag of Words will present it a group of researchers at Stanford presented an alternative to the local context when do approach or methodology and that is the algorithm was called law love. Say stands for Global, obviously, vector for word representation. So while the presentation is one hot encoding, for example, encoding and now we want to have a global vector of features So let's start with an example again, I want to buy a historic Castle going big this time. So I've said here we're looking into CO occurrence of words. So I have to find two words. And they didn't have to be adjacent like begin history, for example. I'm gonna say I'm interested in those two words, x ai being big. And x j being historic, and a one, I get the feature presentation. So what do I do? Well, there's a lot of calculation that not a lot of characters, there's a lot of logical journey that you need to go through before I show you the calculation, which is extremely easy. So first, I want to have the word historic here. And the words big here. And then co occurrence. But also, I want a third world, to connect them to each other to connect the targets. So big in house and home, for example. So what a might have two targets and one context word. So So let's say that they have W, J and W. K, let's say this is my context. Okay? So but I'm still interested in the CO occurrence of those two words with their context. So I'm not interested. So I'm interested in in the, in the in the CO occurrence between big house or large house or big castle, Marcus. So the probability of it being of the koechers have begun house is calculated by the probability of you know, bigger house coming. And the probability of j&k is large house. So give me a function that represents the relationship between these three words in a property segment, I still don't know the function. But that's the beginning of it. And now I'm interested in the context, so I don't want to touch it. By but, of those two words are related to the context, maybe the distance between them has some value to it. So I take them and I convert them to one new Victor. So the distance between them matter and understanding my target nothing's changed. It's still same calculation. And I still needed to represent the probability is two words coming together already for it. Now, this is a scalar, obviously. So I might want to model the relationship between all these three vectors to give me a scalar output to give me an output in the form of a scalar. Okay I quite honestly, I mean, if I'm doing that, if I'm imagining a function, and still imagination. I might as well say that p i KMPTK are also functions that looks similar to this one. So reality, I only need the probability of two worlds coming together. So I don't care about this one. I honestly don't care about this one. I don't care about this one. I only care about the relative towards coming together. And whether it's i and k LGA kids. So I ended up saying well this is the relationship I am interested in So once I do that, I can assume many things. So we can assume that function f is in fact, an exponent function which means that f I'm going to lose the Delta because it's annoying is pi k or the exponent equals pi k and this is the probability of A appearing given A and K appearing. So, this tells me it is the CO occurrence This is the CO occurrence of i and k divided by the colons of i. So, let's say this I and this k and this is between after so, I appears with zero to 3457 reverses. So this one is four divided by So, let's make it a six six and four is 1024 by 20. So, pi k the cooker the coconuts between r and k is the CO occurrence of x i and k which is fully divided by the call all of the CO occurrences for x i Okay. So, this is an example of how the CO occurrences is calculated. So, now, that's the case can I calculate can I simplify stuff. So, exponent of i and k equal the CO occurrence of AI and K and given the data co occurrence of xi, I can take the log of both. So, the word representation of AI and k is equal to the log of x i k minus the log of x i. So, if I want to solve for this one I need to solve for this one as well. Now, this has k this has k and this hi I says I this one is almost constant. So, can you present it in a different light by saying Remember, I didn't have these equal equals log x i k plus or minus some bias value for i This one is the log backside so, in a way I can say WIw k plus the bias that comes with i equals log x ik now, I know that our target is k and we said this from the beginning our target is k and we had two words just to get us to K but it doesn't there is nothing that prevents us from finding our giving K as much as we can find K giving up there's nothing prevents us maybe because we have the bias here for AI. So, it means we're trying to find the caregiver and I but reality of the matter could say, for all four symmetry Ay ay ay we can, if we take the derivative of I given care or derivative of care given I You always want to have a bias remaining. So what you can do is basically you can say, well, we are going to add the bias for AI, and the bias for K, and that equals log x IK. So now I have this equation, I need to solve for it, because I want to get these two vectors. So what I do is my goal is to minimize the error n squared because the minimization problem, so all I need is to minimize the error here, that's because that is the input and that's my target that you want to think of. So, my goal is to minimize the error, I need to do it for all words in my corpus and my corpus size, let's say it's thinking. So, if you solve for this one, if you solve for this equation, you didn't you you've solved for these two values. Now, there are there is an issue we have with this calculation, which is basically this term could equal zero, the CO occurrence of i and k could equal zero a lot of zeros and ones is fight value. So, what we do is we upgrade this equation by having a function that acts on the Corcoran survival kit. So, if X and XI and k are zero, then you know this function is zero, we can also use it to get rid of of inflated core currencies, you know, the and if you take these words, the pokers is fairly high rather than other words, and the other words is CO occurrence with them as failure. So, maybe I reduced the empathy or the way to say maybe it's point when you and then in general, I have this function been increasing something like this goes from zero to one and after a certain value of CO occurrence it just becomes one. So, this one goes from zero to one at some point it is one. Now, you see that the bias here was added early on because of this particular term until we add another bias to allow for symmetry is finding a given key or finding caregiving, but the reality is no need to keep it. So, this equation can be further written not that it matters we know bi we know b k, but can further and further written be written to be FXI K wi transpose w k minus log x i k squared Now, the question is obviously, we need to minimize, we need to find the VI transpose Wk to solve this problem. So, how do you get these two vectors? I'll leave it to you folks. To figure it out. But I'll I'll give you a hint. It's called singular value decomposition Okay, so these are two different approaches, they have two different logics, they go differently about how to resolve the problem, but they tend to be solving the problem in a very good manner. Now, there are a few things that I need to touch on before I finished this part of the lecture. And that's basically the bias in natural language processing. As you see the natural light or as we've discussed, the meaning of the words is found by its company or by the context of that said word, which means if the context is bad or stereotypical or tilted towards one control, understanding that was the face and maybe 1015 years ago, the meaning could be impacted by that. So unfortunately, the features of the words that you extract or not, objectives are very much subjective to the culture that had produced the information at that time. So you know, adding negativity to thoughts and words of logic and stuff like that might be an issue of that waterlines ethicality in some of the use of NLP, you know, prime example is the prime example that we keep using King minus one plus k minus man plus a woman means a queen. These are fairly cultural references that are reported are imported from the, from from from the text of linguistic text. So there's, there's a great deal of bias that we need to work on to D bias. So, when you hop from one language to another as well, which is okay, we've gone to the next level of languages, you'll find that you're presented with different hosts of languages, that the host of problems that are presented, given the nature of the text is used for training, or finding your your, your embedded, future presentation. So that's it for this part. See you folks in the second part, where we discuss a totally new subject of, of this course. Thank you.


ECE 657 Lecture 8 Part II
Fri, Apr 07, 2023 9:08AM â€¢ 58:22
SUMMARY KEYWORDS
fuzzy, computing, fuzzy logic, fuzziness, systems, uncertainty, language, genetic algorithms, output, features, imprecision, medium, precision, reasoning, probabilistic, soft, wake, human, set, approximate

Hello everyone welcome to the second part of today's lecture and and now we talk about an entirely different subject of of our course and this subject is basically related to to soft computing so we've discussed so far neural networks and an issues related to neural networks and so forth but now we want to take a step back and think of this notion of computing so computing in general it's basically it is the process of producing a precise and big and ambiguous accurate it's a process producing a precise ambiguous accurate output, accurate outputs and accurate output that can be mathematically modeled. Example E MC squared is precise, it's unambiguous, accurate, and there's a mathematical formulation for it. So that's computing the notion of this course is a little bit different the notion of this course is basically you have an input you have an output and we work somehow to mathematically model the relationship between mathematically approximate the relationship between the input and the output it's very important to notice why are we not going after this form of computing let's call it heart computing. Why aren't we doing it? Well, for a number of reasons The first one is that the real wall the real world is pervasively. imprecise and insert so the real world is not precise and it's not search. Precision uncertainity. is costing so And then difficult to attain so for these two, you know, reasons, we can't be solving all of our problems using heart computing. So, we're only left with this form of approximate computing or we can refer to it as soft computing. So, what is soft computing or soft computing basically, so, this is from lottery Zed as paper in 1994. So, in this paper refers to soft computing is not a homogeneous body of concepts and techniques. There are many methods that in one way or another operates or conformed to the to the principles of soft computing, the guiding principles are that the real world is is is pervasively imprecise and uncertain, and that precision and society are costly and difficult to attain. So, there are many methods that operate based on that these guiding principles and the and, and the basic logic behind soft computing is to exploit our, our tolerance to foreign precision and uncertainty in order for us to achieve something that is tractable, robust, and cheap. The principal constituents of soft computing are fuzzy logic Neurocomputing Neurocomputing probabilistic reasoning which, as vizury record reporting, which I think that's not the case, but he reports that are subsuming genetic algorithms and belief networks and so on and so forth. But but those things have not been subsumed yet 20 Some years later. So, these systems are concerned with imprecision and approximate reasoning. So, fuzzy logic is concerned with in precision approximate reasoning, neural computing is concerned with learning and curve fitting, as we've done with the, with neural computing. probabilistic reasoning is with uncertainty and belief, propagation, genetic algorithms is considered with evolutionary approximation where survival is to the fittest or US mimicking, survived if it is. So an example of our tolerance to and precision would be basically convolution neural network. So let's say that we have a hand written digit of number four. So I wrote number four, this is number four. Okay. Now your training data, we'll have number four that looks like this. So let's say that this input goes to the network. And you know, the network's tries to extract different different features out of it. Just to figure out what is this and so on and so forth. And after it's crisp extracts, some features, you know, it has multiple potential outputs could be four. Could be one could be seven convenience of the other numbers. So, confusion UniTrack says, well, it shouldn't be point it could it can be point six to be it's, there's a potential 60% that is for 20%. It's one 20% itself. That's not precise. It is not telling you with absolute confidence that it is false telling you that 60% Possibility it's four 20% Possibility seven 20% Possibility is one And because 60 is bigger than any of the other numbers, we decided this fall sometimes it says four is 40% 20% for one and 1% for two and 10% or 20%. So, even though it's less than 50% it still tells you that the agreed degree of imprecision that your answer is for his for the right answer in this particular case is yes, but the fact of the matter although it wasn't conclusive here, the process was tolerant enough for this inclusive inclusivity and therefore, it can operate in a much much controlled manner acceptable of a man. So, in general, if you if I want to describe the forms of computing that we have our hands will have we do have we do have heart computing. We do have soft computing. Now, there is some overlap. Optimization usually lives here. For soft computing, as you said, we do have neural neural computing neural computing. We have fuzzy logic, probabilistic. Reasoning, and genetic algorithms. We've covered MLPs general n ns. CNN CNNs RNNs is EMS Hopfield networks RBF. Networks, of course, are the host of networks under neural computing. Next, we are going to cover fuzzy logic, this is today and maybe next lecture plus, and finally, we'll be covering genetic algorithms. Now before I go forward, I'd like to revisit the concept of imprecision and uncertainty. So there's, there's there's a little bit of difference, when we tackle the concept of, of uncertainty, or fuzziness. Here, we are uncertain about the output, but we're not fuzzy about it. We'll just we have 60% certainty that it is false. And it's probabilistic representation, it adds up to one and here uncertainty it's it's it's useful when we have random influence when we have non probability distribution. This is not a known probability distribution but it's it acts like a non probability distribution it's it's it's we know how to look at it we've know how to enlist understand it. And disadvantage of it is that it's not fuzzy enough that doesn't allow for incomplete information. Because we have to know the features and extract them and have all that knows for the uncertainty to be materialized and and based on our accuracy or desired accuracy. The results may change for fuzziness which what we will be striving to achieve in in using fuzzy logic. Sometimes we didn't have complete information we didn't have understanding about feature or feature extraction. up doesn't does. So it works well with that situation. It works well with our human reasoning. human reasoning isn't distribution. If someone tells me that they are. They think that Team X is going to win the competition for the Euro Cup. And I'd ask them, Why do we have that belief, it's not like they're going to go back and demonstrate some, some realistic distributions, they will, based on the Poisson distribution have drawn some analysis and found my reasoning as to why I think this team is going to win, say, the Euro Cup, that's not going to happen, it's going to be most likely gut feeling, you know, bunch of reasons that draw in personal insights. So you as like, you have to be able to describe that in something that that captures the uncertainty, but without having to have the need for the probabilistic outcome mode. So you need to be able to reason with language with terms. And, and and that's what fuzzing this gives you. It will introduce a degree of inaccuracy. If someone says, I think Portugal and Portugal T max is going to win the Euro Cup, or someone says Tim Tim was getting when the Euro Cup other than looking at the reasoning it's very difficult to say who's who's right and who's wrong. And their reasoning requires a prior knowledge and there'll be half. So, if you ask someone Have you ever do you do you do you fall they will cup and they say no? Do you know pleasant? And they say no. Have you seen previous games for them? They say no, then there is no proper prior knowledge. Personal prior knowledge and therefore it's very difficult to trust it and you know, if you want to actually model IT systems it can be very slow. So, so techniques of soft computing are powerful by themselves and achieving the goals of machine machine intelligence. They do have an appeal in view of biological analogies. They do attempt to approximate human knowledge and associated reasoning process. Neural networks for example, are simplifies the presentation of neurons structure of brain genetic algorithms follow procedures that are crudely similar to the process of evolution in biology species and probabilistic techniques can analyze random features, action of humans. So if you remember the categories I've described earlier, the fuzzy the neuron in genetic poverty commission AI, they have their own critic characteristics. So fuzzy rules and approximate reasoning will explain that network of massively connected nodes we have discussed that derivative free optimization we will discuss that incorporate uncertainty in predicting future events, symbolic processing information, this one remember the integral example that we discussed at the beginning of the class. So fuzzy logic, before got fuzzy logic, neural networks, then the brain, biological evolution, random action, symbolic language, and again, remember the integral example. Fuzzy Logic is about human knowledge. So let me let's say that I want to, I want to I want to create a system that captures the human law knowledge in in in in a SIM in a linguistic way. A one I want to be able to take my knowledge, my explain, experience, everything I've known and write it down. Linguistically. So like what like I was telling you if you wake up late and there's traffic outside you're going to be late. I want to be able to write this. What I have the antecedent I have the consequence I don't want to have distribution of what are these, I just want to say if you wake up late and the traffic is congested then you will be let out I did not have to draw in a probabilistic distribution, I did not have to train a system to learn that waking up late and traffic are related. This is the most beautiful aspect of fuzzy logic or fuzzy rule or human based experience in traditional systems and traditional systems, the newer network, for example, so you have your features, input features. And then you create new feature space. So, these are new features based on the nology how this feature interact with this feature interact with this feature. And maybe the three of them will contribute to a new feature. That's the way it's right that summation. That's W transpose X. It's like how the features interact with each other in different ways to produce new features. And, like what's two features are more strongly correlated to each other, which two features they didn't come with each other since fourth, I did not need to do an analysis to know that the feature that is relevant to you when you wake up or the time or the length of your sleep and when you go to bed and when you wake up and all that, and the features that have to do with traffic and roads and road sizes and other stuff. I did not need to go in extreme forces of feature extraction on ference to know that these two features in this linguistic description. If they come together with these values being led and congested, they are going to produce an output of you being late. I didn't need to do anything there. I did not need to do anything to justify this linguistic description. And anyone looks at this one. They think oh, wait a second, this seems logical. And most of us will look at this rule. And they will say if you are able to accurately capture when someone wakes up and capture the traffic on the roads, the output must be correct. So this logic, this essence is what lutefisk Zelda in the late 1960s used to create fuzzy logic or fuzzy inference systems. So let's visit Zarda is was esthetician so you have a big statistic as well and found that one of the biggest problems stat is there a need for precision, you know, you need to know the distributions you do the calculations, you need to know the actual distribution for every aspect of the analysis. And in math or on paper, that makes sense. But humans don't use statistical knowledge to make decisions on databases. That's not how we operate, what we use is our own personal knowledge to make decisions. So the challenge that taught me that I was faced with is basically Okay can I take this human knowledge that I was able to express in this example and and create a system of mechanics that allow me to program machines to operate and that basis, I II, can I take the human wisdom and write it down in linguistic fashion in machines, so the machines could act based on the human logic and that was revolutionary. So what were the challenges with this way of thinking Well, the first challenge is basically we don't have a system. We don't have, we don't have the mechanics to create this so that was like you could do if else. But we want also to say there's imprecision in late. There's imprecision, congestion. There's imprecision in arrival, like, like you could be arrive late by five minutes, you could arrive super late, a little bit late. You could wait wake up a tad bit late. Traffic might be not so much congested, but somehow there's so much in precision here that we'd like to incorporate we don't want it to be precise if else is precise we didn't we didn't like this precision. So what do we need to do? Well, what he ended up doing amazingly enough is that he created a system a fuzzy logic system or framework as a new mathematical and linguistic Oh, I'll do that draws insights from previously stablished mathematical systems, mathematical models. So he looked at previously established mathematical languages and use them to build an entirely new language. What we are going to be discussing in this part of the course, is the creation of this new language. What does this How does this new language operate? The inspirations that this new language had? And and and how do we use it to build a fully functioning machine learning system. So let's start by examining the existing mathematical languages relational algebra is a language. So you say A intersection with B. And when you say A, union B, this tells you something, this tells me the city intersect with set B set B, they tell you, you know, what's the output going to be you know how to act on the output, when you see when I see this symbol, or you see this symbol between A and B two sets, you know what the same symbol means, and you know, how to act on it. So this is a language with a vocabulary. And this is part of the language the vocabulary might be limited. But nevertheless, it's something that you can understand and you can act on. So, that is something that another language that we are all familiar with is Boolean Boolean algebra. So, you have a or b, you have a and v, you have a C Er B. So when you see this or sign or that a for you to get one and B had have either A or B needs to be one, so at least one of these two has to be one. So this can be one and this can be zero, for example, when you see a and b, if you Okay, for this to be one, both of them have to be one, when you see a and b, x or you know that a doesn't equal b. So, we see these things, you know the outputs, you can see what are the conditions for the input to have an output. So, it's a well defined language that you can read, understand and act on. So, that's another language, mathematical language that told me that I had looked at for inspiration. Another there's there are other languages another language that he looked at, to draw insights, predicate algebra and this one is a fun, so when you say for all x in x squared, is is great, that's a squared is greater than zero. That's, well, it's obvious, but this is a true relationship for all x belonging to our x square is greater than zero, you can read it it's linguistic, and you understand what the output here is an example of intersol for instance, that is in predicate algebra, algebra for all x, for all x belonging to r and. for all for all x belonging to off and for and for all y belonging city, there is a relationship between x and y that is signified by c. So, for all x belonging to our All righty, this relationship is true. We can write that in world by saying for any for any rabbit X, and for any torturous y, the relationship you stipulate that x is faster than y. So, this predicate algebra says that based on the two antecedents, or the the consequences predicates on the presence of the conditions of the antecedents and that's the symbol, that's a language that captured a form of freezing and you could use and you could use it to represent the relationship so that's an example of predictive algebra. There's another form of calculus or algebra called propositional. Calculus I need to say well, you have a premise and you have a conclusion. Example premise one, P implies Q, premise two, P is present, conclusion, Q is present or we can say p, if p implies q and p is present then Q is present pm last Q, P is present and q. So that's propositional calculus. It seems logical seems easy that our symbols here and they explain some language. But from here we can go one step and say, well, there are basic argument F four on propositional calculus. So from, from this format, I can create argument to format arguments. There's something called modus ponens ponents. So, it's a mod that affirms by affirming what do I mean? Well, if P leads to Q and P is present, so this is the language of p li, Q, and P is present, then Q is present. If P implies Q, if p implies q and p is present, then Q is present. So, it affirms that Q is present by affirming the implication. So, that's called modus ponens. There's another argument for that's called modus tollens. And it's basically a mod that denies by denying. Again, if P implies Q and Q isn't present, then P is not present. If waking up late implies late arrival, and you wake up late, then you'll arrive late if waking up late, so, this one if waking up late implies late arrival and you did not arrive late. So, q is not present, you did not arrive late means you did not wake up late. So, those are two different arguments of and you might not agree with them, like some might look at them say oh, yeah, makes sense. Actually, no. Some might say, Well, I'm arriving early doesn't mean you will complete you did not wake up late. You may have walked in a plate but you were extremely lucky that the roads were open the world at large traffic and you made it in time. So, some might say this is risky. Because it absolutely deny by denying. So, he says if you did not arrive late it means you did not wake up late. So some might look at this one and say well, we don't like it just because of the jump of logic that is happening. So you know another example of argumentative is the the hypothetical syllogism not sure if I'm saying it, right. It's basically says, if P implies Q, and Q implies R. Then P implies up If wake up waking up late upload implies that you're going to arrive late and arrival late implies failing in the class, then waking up late implies you're going to fail your class. And again, some might look at this and say, Well, this is an hour stretch. So and we didn't like that. But anyways, the goal is to understand that fuzzy systems, or fuzzy logic utilizes all of these languages, all of these men mathematical languages. To create a new and this is what we're going to be discussing. So, we talked a lot about mathematical models, we talked a lot of models, we talked a lot about languages. And I've been dancing around the concept of fuzzy the word fuzzy in fuzzy logic. So let me first address the fuzzy fuzzy logic. If I say is the exam or was the exam is? And you answer by, yes. This is a crisp answer. This is one or zero. So I know exactly what's the answer. There are no room for negotiation. And we call this crisp answer. If you say to a certain degree then this is a fuzzy answer. I cannot say absolute one or zero. I know it's positive, so it is closer to one than it is closer to zero. But at the end of the day, it is positive. It's positive, but like it is point six is point seven is it one is to a certain degree. So it implies that you weren't 100% confident that you say it's easy, but you do not want to say no. So you wanted a room for negotiation between saying yes and no. And that is perfectly fine. As a matter of fact, a lot of what we do is dancing around the point. Did you like your lunch? Sort of? Or did you enjoy your lunch? I kind of alright, you want to say yes, absolutely. or No? I did not. Yeah, it was sort of fun. So when I say it was sort of fun, then you're implying some fuzziness in your feelings about the user experience and you want to portray this fuzziness somehow and maybe the best way is linguistically by saying to a certain degree or perhaps or maybe or somehow those terms with which you're expressing you're hedging by that is what you're doing. So firstly systems for the systems allow you to express fuzziness about outcomes as well as observations. Why would you do that? Well, in the process of observation, if you have a sense of Gnosis there's 100% accurate, right? So, like it it fluctuates because of noise or whatever it is. So it's not necessarily a precise description of what's observing so You want to know for that news image so, a fuzzy systems start with with fuzzy sets, move to fuzzy rules, the way that sets interact, move to Fuzzy implications. And remember the modus ponens, modus tollens those are ways of expressing implications. So here we have implications and leading to creation of systems that are fuzzy systems producing an output that can be either fuzzy or crisp. So, we will be tackling all of these and see how this framework of existence or operation had been created. So, let's start by looking into sets we said here that we do have fuzzy sets. So, let's start by tackling this one. So, let's say that you're looking into your class and you have two classes class one and class two. And in class one, you have listed a list of people who have mark you have may have Li, and you have Rajnish. And you go to class two, you have no Hamid. You have John, John F, Julia. And you have yet so, these two sets are crisp, class one, class two, there is no student who belongs to this set also belongs to the other set. So, this is an example of a crisp set. So, how about the fuzzy set? Well, let's take the example of sizes. Small, medium, and large. Okay. So, I like these labels, class one and class two, these Words have meanings. So there's an opportunity. So let's say that you come and say small is from zero to 10. Medium is from 11. To 20. A lot is from 21 to 30. We say you have a missed opportunity of fuzziness. So, maybe you should have said that small is zero to 30. And medium is 12. To 23. And, and large is 20 to 30. I think of these as kilograms, just in case someone's asking. So, take a look at this example, from the same paper that have caught earlier from what he said. So, this is a representation of small, medium or large, what small is absolutely small, what's medium is absolutely medium and what slot, it's absolutely lush, there is no degree of overlapping there's no degree fuzziness here is a small here is meat you even have the differences point over when you come here. A fuzzy implementation of fuzzy representation says well this entire range here could mean small medium, this entire range here could be medium of life. So, a point in this space belongs to medium and belongs to large with maybe equal representation. So this example of one a draw it and when I say ABS Two 510 1520 25 and 30. Again say, well, from zero to 13, it's small, but at 12, there is something going on here. So we're gonna go go all the way and then at 12, you descend and you hit 30. And this one at 12, it can't exist. And then you go all the way at 30. You go all the way at 13 used to cooking and then at 14 you at 14, you become medium and you stay medium, all the way up until 20 Where in 20 Here 23 to become slash, so, you go all the way life is good, and then something like this so this is small, medium, I love. So there is a degree of overlap between the different classes are the different designation, and that has different implications. What that means, to me is that this these data points exist in two classes or two representation. These data points exist in two representations presentation, this is a major breakthrough in describing whether 21 is medium or large, because 21 could be the medium, it could be love. And so you're not committing to any to any necessarily outcome, the weather is beautiful, albeit a bit chilly, you're not committing to it being beautiful chilly, you can or you could say something is, you know, in the definitely in the upper medium terms of wed or lower love. Right, so you want to say both notions and you want to keep both notions. At the same time, you didn't want to have to commit to it being either large or small, you don't want to dis sharpness, you want to leave your uncertainty presented in the logic. So that is the fuzzy sets representation. So if we take a look here about difference between fuzzy and crisp, here they are there's a car falling and other car, I'm gonna say is the car close or not? And the answer is yes. Or not crisp, right? But that's the sort of traditional logic tends to give you 01 Or the says, well, it's there's a spectrum to things. So there's a range from no to yes. And therefore when you hit your brakes, you don't have to hit them 100% You don't have to absolutely stop. And this is what people do when you drive. You don't say whether you're close or far, you know, you you close to a certain degree or far. And based on how close or how far you are, you control your brakes, changes or varies. And that's what we want an intelligent system. We don't want to deal with absolutes, we wanted to deal with fuzziness, and therefore the actions are also fuzzy. So do I hit the brakes somehow hit the brakes somehow, like a lot or a little maybe a little? So it's it's it's our ability to have some descriptives without other fast clothes warm in a non crisp quantities are the subjective or approximate quantities, qualities, qualities. So we'd have a variety various degrees of truthfulness to any statement is the water is warm. The warmth of the water isn't true or false. It's a degree of something. It's an example that they want to go. You can you can go through it. So again has, for example, the definition of tall and short a good example. Well, that's a personal example for me, given that I'm not tall. But it's it seems to be weird to say, Well, someone is shows all the way up until a certain number. After that that person becomes your reality, it takes a while of things to happen until you, you're firmly either tall, or short, there's a degree of fuzziness and subjectiveness, between tall and short in our human description. So, fuzzy sets operate on universe, universe of numbers or context. So, if x is the set of contains every set of interest in the context of a given class of problems, students, then x is the universe of discourse. So in any language, you have a universe universe, that's x, sorry, that's x. That's the universe elements in it are called Set sets a set A to maybe, and so on and so forth. So a fuzzy set a, in a universe discourse, X might be represented by some Venn diagram. So you'd have values that are absolutely within the set, and you have values that are you know, may belong in multiple sets. So generally, the elements of a fuzzy sets are not numerical quantities, they are subjective, or descriptive qualities, you know, small, and like here, when we said, Here is it small and medium and large, your set is small, medium, and large. So that's your set. And that's fuzzy because there is overlap between the small, median, and love. We're going to cover membership function today or next week. So I think I'm going to cover membership functions next week. I'll conclude with this post today. So thank you, and see you next week where we dive in deep and fuzzy logic and fuzzy inference systems and what comes with these systems. So thank you and see you next week in our discussion session, and I'm looking forward to all of your questions. I will apply upload two sets for this lecture. So set five which covers a lot the material that I covered in Blackboard and set six, which is going to be the material for for the rest of the for the majority of the subject of fuzzy inference systems. Thank you, and see you next week.


ECE657 Lecture 9mp4
Fri, Apr 07, 2023 10:36AM â€¢ 1:59:21
SUMMARY KEYWORDS
membership, function, fuzzy, set, operator, operation, values, intersection, complement, norm, equal, union, point, element, calculate, dilate, properties, generalize, important, universe

Hello, everyone, welcome to today's lecture. This is our second lecture when it comes to Fuzzy inference systems. The full the first full lecture on the subject. So last time we stopped we stopped at the membership functions. And I said that although fuzzy inference system includes lots of full of theories about fuzzy sets and how the fuzzy sets are created. And, and, and, and the fact of the matter is that their creation allows for a degree of overlap, and so on and so forth. We haven't explicitly and on the fact that there is something called fuzzy the fuzzy sets as some sort of representation like this, like this, like this, we haven't discussed how do you come up with these shapes or values. So these shapes are called member membership functions. And what they do, they take the values these values here, and then map them to a number between zero and one. So those are what we'd call membership functions, they facilitate our ability to map numbers or the member values here to some degree of certainty, for example, if we say this is slow, then those are the ones that allow you to map 20 And this is medium, it is speed, this was allows you to say 20 is here, when it comes to slow, I'm sorry, it comes to medium and is he when it comes to slow. So those are membership functions, they give great or degree of membership within the set of every element of the universe, or the discourse. The membership functions, they do map the elements as we said of the universe of discourse into numeric values of intervals between zero and one. So for example, we have this function where as an example, so we have this funk, this membership function, here's an example where it allows you to model certain activity absolute says TT here and allows you to model fuzziness or uncertainty here. And that happens to be one of the function sets that's allowed the relationship between the values and the degree of of membership is governed by function mu here. So, for every element for x in the universe, and for set a for every element in the universe, x to be a member to be a member. And set a relationship is observed. And what that means, essentially, there's an ordered set of values. So A is basically x and its membership value. For every x in the universe. Now for most x's, let's say for speed 60 For example, and it is for speed 90 and a slow, the membership function will be zero So it is very important for us to understand that a set is basically an ordered pairs of, of the elements and their membership function. That's what says set, for example, and the values of those membership degrees are important. So if you have a value of one, then x is definitely an element of x. If the value is zero, then x is definitely not an element of A, and the value is a point to then there's a chance that X is an element of A, it's not the Cillian element. But there's a possibility of it being an element. Now, a crisp set is a special case of a fuzzy set, where the membership function can take two values, either zero or one. So if you set a has only zero or one, then it is a crisp. It is a crisp set. So before we go to the symbolic representation, oh, let's actually talk about symbolic representation. We said set A is presented as ordered pairs of X and their degree of membership. So what does that mean? How is it? How is it portrayed? Well, every element of the universe will be represented alongside their membership function value. So for a, this value might be zero, for one, so for x one, the membership function might be zero. For x two, the membership function y it might be zero. For x three, the membership function might be point one 4x, for the membership might be point three, and so on and so forth. If it is zero, it is custom that you didn't have to write it. Because there is no value there. So that's one important factor. One important aspect in understanding the terminologies, second technology, this sign isn't an addition sign, it just a sign that this is a serious of, of elements and their membership function. So this is how it's represented. And this whole presentation anyways, is for discrete universe. For example, for discrete universe, the value will look like this. So x 1x, two and the value is point 2.1. C one here, x three, that's point five, and sensible Excel. So that is a discrete universe. So that's how it looks like. For every element. of discrete universe, there is a membership, there is a value signifying the membership. If your universe is continuous, like this one, this is continuous. So it looks say the exact number is 70. And here, he there's indefinite values between 70 and 80. So that's a continuous universe. It's not anymore a representation of series. The function is represented as integral but integrally, again, it's certain degrees, it just means it's continuous. And this whole relationship here is represented by a function of x. So the membership function would be a literal function, where you feed an x and you get the membership value. So this was seven, the sigma and integral do not represent summation or integration, but rather the collection being discrete or continuous. So the discrete universe as I said earlier, looks like more like this. You have a less fuzzy set a He has point two, three, so three belongs to it by around point two, four belongs to it. My point three, five is absolutely NX. Six is possibly a part of a buy. Point two, seven is possibly part of a, you know, my point one, nine and 10, as well as one, they do not belong to it. So every element in the universe has a value when it comes to every set or fuzzy set, it's just that sometimes the value is zero. And that's why we didn't write it down. And that's very important to understand. And to not. For the, for the continuous universe, as I said earlier, it is more of integral of, of our x, but the reality of the matter, it just, you have your x value here, that's the member of the universe, and you pass it on the function here happens to be this function. And then you plot your values, right? So in this particular case, let's say that A is five. Okay. So for a equal five, when x equal five, so five minus five is zero. So here, you have one over one, and that's, that gives you one here. Now, as a value, as the difference between if the difference between x and a is less than zero, I'm sorry, it's less than one. What you get is bunch of ones here as a form of approximation. Alright, representing those x's. So six minds, a, you know, happens to be I'm thinking what's a, watch it AB, maybe 5.5 is five, six minus five is one, one divided by one is half. So you go, this is six cuts here at half, four, same. Cats, here's half, so half is here. Now, five minus four is one, five minus six. As absolute value is also one, five minus 4.5 is point five to the power of 10. It's almost zero. So one divided one divided by one plus a bunch of zeros here is equal to one. So that's how you get this representation. And then seven minus two minus five is two. And two to the power of 10 is so much have a large number, that one divided by two to 10, which is one divided by 1000 is almost a zero. So that gives you zero here, and so on and so forth. So that's how you represent a continuous space. Now there are multiple, there are multiple shapes, you can see it I chose certain shape. But Saturday shape, there are multiple shapes, you could choose triangular is one of them. And triangular here allows you to say that you're only confident that that's B is part of the further set. So the confidence you have everything else is maybe part of it, but you're not too sure. So this one allows you to be express confidence in only one value that happens to be an absolute uncertainity for any value between A and B and B and C. Everything else is fairly zero. This triangular membership function the trapezoidal, trapezoidal membership function strikes a balance between having absolute confidence in one value and says, Well, wait a second, I want to trust B and C and every other value among B and C, I know they belong to this fuzzy set. Set, let's say the versus the fuzzy set is school age, university age, okay. So you trust you trust that 19 to 21 Absolutely is in the school. Below that you didn't know, you know, maybe maybe under 19 is undergraduate. Maybe over 2921 is undergraduate, you're not too sure. But if anyone is 19, or 2021, and the art is cool than they are undergrad. And that's, that's as much trust as you have, in this knowledge. Everything else is kinda Maybe yes, maybe not. And this is, by the way, your membership function of Felicity for every x, this is the function. There's also the Gaussian membership function. And it's one of the most likeable function because you have so many controls over the width of the function, and the smoothness of the function. So the Gaussian allows you to control obviously, the width with sigma as well as smoothness, with C. So that's another example. And then we come to this one, which is absolutely the most commonly used, most commonly used the most preferred. membership function as preferred for different reasons. The first reason is that you have loss of freedom over saying that there are elements that you absolutely trust they're part they belong to set A and then then the smoothness with which others don't belong to set A is also something you could control. So it doesn't have to be like this one. Or you absolutely fall off a cliff could be more of overs of a graceful or gradual decrease of great of membership. And you can control most of it, you can control how many elements you trust on the set, and how long it takes to to create from that. So obviously, this is the significance of it. The fact that you can move it to become a Gaussian function, you can move it left or right increase its width, and change its centers. The triangular and trap from xojo functions they're linear, so they're cheap to compute. But they are as we discussed in the neural networks are not differentials. The Gaussian and built in membership functions, they are differentials. But they are expensive relative to this one's I'm saying relative because in this day and age, the whole terms of them being expensive is kinda overstated. So let's let's bring an example when we move from a fuzzy set that is from a crisp set of fuzzy sets, and the best example of crisp set fuzzy sets in the marks that we have at UW so if you go to grading system at UW you have a plus being in this range, and a in this range and a negative in this range. By the way, I'll bring it home why I'm using this example, for fuzzy and crisp Sorry. 60 And then you have an F here at 59. So that's a fuzzy set, if you want to present it you're going to say this is 1020 3040 5060 7080 90 and 100. And this is one and this is zero. So you're gonna say from one to six to 16. It is F from 60 to almost 70. It is C, so f here fe, C here from 70 to 80, it's B from a D to 100. It's a and then internally here, for example, you have you have three values for C, for BM, sorry. And here you have three values for A. But according to you w, any value in this number is absolutely in one in F, every value here. Is absolutely in C absolutely in B absolutely in a. And so on and so forth. Students didn't see it like that. Students have different understanding. So, for some students, they see, well, if the value some students, if you go on you have a survey, and you say what do you consider to be? Excellent. Well, anything that's just on equal 100, right? And then it depends who you ask. Some mightily will, following the university description is from 80 to 100. But that's not everyone, some would say well, actually up to 68, maybe that's very good. So from 72, from 75, to 86, it's very good. And good. Could be, you know, from anywhere from 70 to eight and bad is, you know, maybe from 60. To 75, and a poor and a poor showing less than 65. Because the notion of what's bad versus like some people 75 For them is bad. Some people you know 70 is good for them. Some people 85 is very good and some people 80 is excellent. So different people have different understanding of what they want to see. So when you want to when you want to create something that describes this, okay, so 65 to maybe 60 there's doubt so gonna say well, we're gonna go this way and that's cool and then you know 62 to 75 they vary. So, there was something like this and 72 ad and 75 to 86 maybe and then 80 to 100 So, first we took this crisp value with scripts crisp description where these value are absolutely belong to one set and one set only, and we made them fuzzy and then within this fuzzy some value that is do absolutely belong to only one set like this. And some values belong to multiple sets like this it is the you remember your choice of membership function, your choice of it's being built, shaped, or Gaussian. And then the parameters here allows you to control what becomes fuzzy and what doesn't become fuzzy for example, he you know, that 87 onwards only belongs to action because it doesn't belong to any other set. Here, you know, that 80 Maybe only 80 belongs to good, only eight, maybe, maybe not, maybe the whole thing, let's make this less problematic let's make this problematic. And consider this not to be to be less than 80 Not not a not 80 in particular, this helps us supposedly, so anyway, this description for this way of showing stuff should be able to help us understand the relationship between what's crisp set and what's a fuzzy set and why the shape is important and why the values are prompters for the shapes of important another thing that we need to note is is these values these values when we said that if function let's get something that is when we said here that that if the membership function is point to the possibility that x is an element of vase point to when we said that we didn't mean that this is the probability of it being in set A. So, this is probability versus possibility. The probability sums to one for any particular event. So, for any event, the probability of things happening to it. They as some of you when for example, we have a ball. In the priority of the ball being red this point to Blue is point three. Black is point five Those do sum up to one possibility doesn't sum up to one because a possibility isn't about isn't about the likelihood of thing happening. Given the number of trials, you know, if something has a probability of 75% means out of every 100, trial 75% Would be a success if if 75% in the chance of success. So that's probability possibility accounts for uncertainty. For example, if you go to a doctor and a doctor is going to perform a surgery on you or someone you care for, and you ask, okay, what's the How confident are you in in the success of the surgery and the doctor tells you all 75% that 75% means the doctor says tivity, about the success is 75%. What about the other 25%? Well, that's the chances of other things happening that the doctor cannot account for. Right, so the doctor can never tell you will 100% success for this particular operation. So they have to keep a wiggle room for other unforeseen circumstances. But 75% doesn't mean that the doctor had performed the 100 surgery 75 of them were successful 25% word failure. That is not what is the possible that's not a possibility. Possibility signifies the level, the level of selectivity, or the level of evidence that we have. When we describe the likelihood of something happening, it's a level of certainty. It is not a level of, of of, it's not a frequent frequent test based approach where you observe for a long period of time, then you calculate the hits and misses. So it's very important to understand that there are a few terminologies that we need to keep an eye on. And those terminologies involved involve the formwork core support set. supports that is one that for a fuzzy set a fuzzy set a the set of all points or elements, let's call them elements x belongs to x whose membership function is greater than zero. So for any function for any membership function, should anyone have this one. I want this one. For any membership function, all the points here whose membership function value is greater than zero, those elements are called support set. The core set on the other hand is the one that who's on fat. Who's whose elements is the set of element who is whose membership function whose membership value equals one. So those ones are your core, your core elements. So what you do here, when you manipulate the size, and you increase it and shrink it, you're manipulating in manipulating the size of your core set. Another terminology that's important is normality. Secular morality occurs when at least one element of A has a membership value of one which means that you may end up with them with with with a set when no element belongs absolutely to it across over value it is basically it is when the membership value becomes point five. So, here C minus a and c plus a are you cross over values. So, if I bring you this graph and asked you to identify the crossover values to be c minus a and c plus a and other terminologies that you may see is when you have some when you have this kind of fuzzy set of fuzzy sets when you have a function that keeps going to one all the way to the end, we call it an open left set when the other one goes to one all the time called open right and it looks like this we call the closed set. So, this one means, it will admit as many values as they are and they always do want to admit as many values as they are and will always give them a value of one of one. So, these are important technologies that we need to understand when we talk about fuzzy sets and their membership functions and values and descriptions. So, operations. So, what are the possible operations that a fuzzy inference system will undertake. So, he said fuzzy inference systems, or the fuzzy logic is a new field of study that has its own math, its own calculations, its own languages on operations, its own operations that act uniquely or an unique way that you really see in a fuzzy in the in the in the in the realm of fuzzy logic. What we are going to present right now is is number of operations that you will see in a fuzzy inference system. But bear in mind that although these operations have familiar names, the way they operate is a little bit different from what you're used to, for example, Operation union. So we all know what union means. A union B means if you have this set, and you have this set, this whole thing is the outcome of the Union that's that's that's the regular unit. In a fuzzy inference system or a union operates a little bit differently because when you're doing a union between two sets, you're doing a union between their membership functions. Remember set is an ordered pairs of elements and a membership values. So when you union between two sets, you're doing the union between their membership functions. So here the union between two sets is basically the maximum have their membership value at any given x. So for any x you'd have to membership values for A or B, the union between them is the maximum value. For example, if you have a and you have B here and you have point two for x one a You have points eight 4x 144 B. Now a and b are part of of universe x x one here the same as x one here. So their union is basically point it on x one. So we took the max of these two values, and we'll put it here. So that's union. So it's a bit different from what you're used to. Intersection. intersection is, conversely that the section of MP is the minimum that you that the membership functions have at point x. So in this particular example, the intersection would be point two, and X one. So there is no new value that's calculated it is the same value. These are the same values that are presented, we're just selecting some of them. These are binary operations, ie the involve more than one set, or two sets also have unary operations like the knot, or the negative operations or the complement, means same thing as the complement of A is basically calculating the membership function, which is minus than the original one. So compliment hasn't changed from what we are aware of. So let's see if you have any examples. So if complement of union intersection, and here's an example. So if we're talking about fuzzy set A, these are the values so far, we have three, we have four, we have five, F six, we have seven, oh, by the way, this is zero to seven. So we have zero, have one, and we have two, so the entire universe is 0274. According to this representation for this, it's a zero here, has zero here, has zero here, and has point three here has, sorry, point two here, point three, one here, point two, and point one, the complement, the complement with B of this function would be that at zero, you have one is to one minus the value of one here, and one here, you have point h here. You have point seven here, you have zero here. Yeah, point h here. And you have point nine here. So that's what you have here, when you take the complement of A. So notice in the past, we said we didn't try zeros, with zeros to exist. So keep in mind that zero does exist. So when I asked you as the complement of a do not only look at these values, look at the entire URI universe of discourse. And take the inverse for every value within this universe. So this is the example this is somehow making the discrete set look like a continuous set it is not obviously continuous because we didn't know the value for 2.5 for example, or the values here we have no idea what are they and we have no function that describes them. But anyways, let's go with this example. This is how you calculate the knot for the Union. So we have two fuzzy sets. One of them is Slow and the other one is modules, I want to take the union of them, you know, slow all model when think of it. So again, we think we know that the universe is between 40 and 100. So at 14, a is one, B zero, so the union's one, at 50 is one, B is point six, the union's one again, as 60.1 point 8.8. So it remains at 70, he is zero, here's one, so you get one at 80.4. And once you get one, at 90, you have zero on one, so you get one at 100, you have point one, and once you get one, so almost all of it is one, if you do the intersection, there is no 40 here, so you didn't get 40 the 50 the minimum was point six, there is no 70 here, so you don't get 70 The 80 is point the 60s point eight and the 60s point is remains the 70 again zero as I said, there it is point four and one. So you get the point for there is no 90 here, so you get zero and for the 100 you get point one. So, those are this is an example of the of the fuzzy union or intersection set. So, if we are drawing our tune Bucha functions, to do the intersection, you'll take the minimum between them the absolute minimum, obviously I have taken the union, you're trying your best to get the maximum. So, this is for a continuous universe, this is a and this is B the complement of A is the same thing one minus the value of a membership function. The union of A and B is basically the maximum values at any given moment, and the minimum and the minimum value at any given moment. So you'll end up with something like this for for the intersection Okay. Other operations include algebraic algebraic product. So, a dot P, the way you do it, it's a dot operation between M between the membership function of A and B you know, an example of that one is basically if if A is described as point 3x One and point 6x Two and B point 2x 1.2x Two then the dot product will result in 2.06x one here and point 12x Two here. So, that's the algebric product. There's also the scalar. product it's essentially when you have a scalar that you want to multiply by the fuzzy sets function or orbit is described as a scalar times your membership function you think of this membership value is point one and this scalar is to say end up with point two something like that question Should this be controlled alpha be controlled or not think about it. We have also the the sum operation so a plus b and that's basically presented by the following operation their membership function x membership function of a membership function of v minus the dot Product of a another another another note why do we have this term very important to know that another oppression so seven would be the difference between AMB difference is described as the following oppression A intersection of B with B complement OR A minus B WITH YOU BE A intersection with B complement, so the first you calculate the B complement, and then you calculate the intersection between it and a. So, that's how you do the difference between a and b then there's something called bounded difference where the difference between a and b is the difference between their membership function but it's controlled by this function. So the maximum between zero and this value is what gives you the difference so that's one way of doing difference as well. So by the difference looks this way normal difference looks this way equality that's another oppression that you could run. So if we say a equals b, then we're saying for every x the membership function of A equals the membership function of the calculating the power of a fuzzy set if I want to raise the power of a fuzzy set A to K then it's basically raising the power of my membership that I know that oppression it's sticker tz and product so A times B and to calculate the Cartesian product the rule would be for every x for every x and y we'll take the minimum of the two for every pair of x&y the minimum of their membership vary by by for every pair we mean that if A equals one over x one and one 2x 2.84x three and point four 4x Four sometimes again I say one over x one, I mean 4x one and B is you know b of x f x b y is sorry, point six four y one and point eight, four y two and one four y three. We have these two fuzzy sets and we want to take their Cartesian product what we do, we construct a two dimensional matrix so x 1x 2x 3x four y One y two y three this is one one point 8.4 And this is point 6.8 And one So, the minimum between those two values is point six the minimum between those two values point eight the minimum between those values one point eight one and point four point 4.4 Or is it one point 8.1 between point eight and one is is one okay all is good so, the outcome unlike all the other operations the Cartesian product produces a two dimensional relationship so, takes one dimensional representation and moves it to two dimensional representation. So, our function used to look like this if there's X 1x 2x three and x four and this is one so, it used to be like this one 1.8 and point four and you had to i that is y one y two y 3.2 point four point 6.8 And one you know you have this you have this and you have this you take these two and now you end up with a presentation what it's literally something like this when you have your x and y z and you start having some values something like this So, you end up with constructing some two dimensional representation so, that's the relationship what you end up with two dimensional representation of your of your fuzzy sets okay so properties, what are the properties of fuzzy sets? So, let's see if we were still still good. So, the property of fuzzy sets and first commutativity commutativity. Commutative, commutative commutativity. So, A intersection with V is the intersection on a A union B is B union A. That's a property. So any fuzzy two fuzzy sets within our system have to work like that associativity. Something like that. The reason why we're showing this, again, you have to understand this is a new way of building a system. So when you do A intersection B, it's not a and b, it's the membership functions. When you do this, it's the membership functions. When you do this, you're talking about membership functions, you're not talking about actual the normal faziz The normal set as defined by set theory, so it's we'll have to redefine distributed distributed hability this you will be tivity. So, A union B intersection with C. It's fascinating that it maintains that because the way it operates, the way fuzzy logics or fuzzy sets operate are different from normal sets. So the fact that you want to maintain these properties is amazing. Importance. So a union is A, A intersection with a complement is phi. A union finds a intersection with fine, it's fine. There's the involution involution. And that is the complement of A compliment, is there isn't a set set. And then there's the Morgan's law. So, A intersection with B complement is a complement union B complement and A union B complement is A complement intersection with B complement. So, these are the properties of the fuzzy sets. So we have fuzzy sets. We have put in sheet operations. We have the properties. So we defined the set, we defined the operations. We defined the property. Now what we'll lose it what we're missing is the operators. So that's what we're missing. So what's an operator, an operator is the logic through which we combine two fuzzy sets to get a new one. So that logic is what we call an operator. For example, you know, equality is an operator. Containment is a is a family of operators. complement is an operator. The intersection is an operator. So there's a far difference between operations, that's intersection and the operator. So saying this is an operator that when it comes into multiple fuzzy sets, it causes them to act as intersections and then union as well. So here's an example of of A complement operator. So complement as we said complement a is one minus eight, so that's normal complement. But there might be other operators that perform the normal complement. So one operator is called. So genius operators are a complement. So that's an opera later that performs the oppressions operation of complement. And the operator says the complement of A is one minus A no difference, the divided by one plus P A, or P is between minus one and infinity. It's never minus one. It's never 30. But it is between minus one and infinity. So that's interesting. So why is this equation exists? Why isn't this good enough? Right? This is our complement impression, why do we need a new operator to do to do complement? Well, let's take a look at how the comp the normal complement operation works. So this is a and this is complement of A, when a is zero, the complement is one, when the complement is one, when the complement is zero, is one. And it it's one, it's one, one minus a. So you know, it goes this way. So this point five, then this is point five. So that's the normal one minus A as a compliment operator. So genius operator actually press differently. It says, well, when p equals zero, then this is your operator. This is a compliment. But if p is less than zero, then your compliment will look like this. Something like this one. When P is greater than zero, then you may end up with something like this as like the complement calculation isn't 100%. one to one mapping. And the reason for that is when it gets closer to infinity. And the reason for that is basically, well, if I'm confident 90% that something is going to happen. Okay? If that's what I'm comfortable with. Sorry, when I'm out I want to change it like this A and this ca doesn't really matter. If I am confident that something is going to happen is not going to happen. Some zeros, like 8.1% isn't going to happen. The compliment can be one. Right? Okay, how much confidence you have, it's not going to happen, every 10% Confidence is not going to happen. Well, that means it is going to happen, right? Because the possibility of it not happening is so small, you assume the opposite is 100%, not 90 or 85%. So there is a logic in non linear mapping of the compliment. And, you know, it reflects our unwillingness to commit to a crisp value. Another operator again, operator that operates that performs the complement operation. So the operation is complement. There's another operator for it. It's called jaegers operator. Similarly, the way it operates is by having an equation that incorporates some p value, or P goes goes from zero to infinity. When p equals one, this is one mindset. So here he is where p equals zero, or P equals one. This is one minus x So like usual, you have complete control over the operator, it looks like this one p equal one. And then you have control over p value, which gives you different cebs of the operator, how fast how slow, the complement goes to zero. So that's another operator. It's an operator that performs the complement operation. So very important okay. So if discussed multiple, we'll discuss a, we discussed two operators that perform one operation or theoretically we have three operators, we have one minus A, that's an operator, we have one one minus A divided by one plus P A, we have one minus A two p one minus p. So, these are three operators that perform an operation which is the complement. So is there a better way of describing describing the operators are the logical operators in in in in fuzzy logic, the facets are there something called T norms and its norms sometimes called T corner. So, this is called the triangular triangular norm T norms either we go back to why these are acceptable norms or why can we consider them to be acceptable not operators T norms are used in different fields to generalize so, that a goal is to generalize an operation okay, like this is an oppression that's compliment and we use this one to generalize it by giving it different aspects of performing the complement. So, discussing generalized the original the original discussion of genomes has to do with triangular with with the with the triangular inequality. So, you have X and Y and z said well z is this then x plus y. So, that's the original triangular inequality. This is strictly correct for metric systems. So, when you move from these systems to other systems, the inequality will not hold. So, when you move from systems to other systems or other formatting systems, the inequality will not hold and therefore, you need to generalize the operator to allow for the unit to generalize the operators to allow for the admission of new systems to allow for the admission of new systems. Essentially, essentially, we don't care about an operation what we care is about the properties of the operation. So, the person itself doesn't necessarily matter the properties of it matters for example, for example, the complement operation has properties where the complement of phi is a the complement of A is phi. The membership function of a for x if the membership function of A is is less than the membership function of x then the membership function of their complement Our shouldn't be greater of A should be greater than membership full complement of the another poverty is the evolution, you know, the compliment of A compliment gives us the same value. So, if you have an operator AND operator that satisfies these properties, then this is good enough for us. So, one minus is that supplies them but sugeno and younger also satisfy this property. So, those operators are good to implement the operations, that the norms are basically saying, we are going on this norms we're going to do these operations, are there any operators, that is phi sets of properties and they've got So, the goal essentially is basically if it is a T node or Islam So, the goal is to make sure that one number one means truth and numbers zero or the metric zero means false or means, here means completely been completely belongs completely doesn't belong. So, those are the goals of having these knobs. So, since we said the norms are basically operators that generalize an operation as long as they make sure that the properties are maintained that means, we need to know what are the properties that we need to maintain. So, for for the tienen it is an operation that takes value from zero to one of two sets and maps into a new set that also goes between zero nor did I say both answer zero here means false and one means truth. So, both of them have to hold these facts. So, because between zero so, this is the operation such that the properties are maintained the first property the T norm of x and zero is zero the T norm of x and one is x. So, any operator that operates on x and any operators that is a T norm operator and operates on x and zero has to produce you and any operator that operates in x and one has to produce x and that identifies the identity of the Tino okay. This one's obviously seems to be the men. So, men, that's phi x and zero is zero and x and 1x. But the multiplication also sets phi x and zero and 01 x. So, x times 00 and x times one has one so not multiplication do satisfy that. So, you have the main operator and the normal multiplication operator seem to be satisfying being T norms another property that needs to be satisfied commutativity So, the T the T x and y is equal to T Y and X another property that we need to observe if x is less than x dash and why is less than y dash t x and y have to be less than T x dash n y dash. So, the the the monotonicity alternate key property the monotonicity of the function is maintained after at enormous applied and for the teen all of us have T naught of x and y and Zed is the same as the T norm of x and t norm of y and z it is associated CCD. Okay. So, those are the properties of Athena intersection is an example of the Tino the Cartesian product is an example of a T known the algebraic product is example of a T. So, those are operators and they are all considered to be a T known operative is none. So, we discussed the T now and now discussing the is known, which also referred to as T cor No, so, it's them not the inverse versus the well defined term is the opposite of Tino whatever opposite might mean as a word. So, as here is an operative that takes zero and one to two sets that go from zero to one produces a new set that also goes between zero so it maintains that zero is false and honest truth just means maintains that so, one here the first property that we need as far as s x and zero has to be x and s x and one has to be one okay. So, when you remember the T norm was dx is 00 and T x and one is x, this norm is s x zero is x and s x in one is one. So, the identity here is the maximization identity s x and y equal to s y and x there is no difference there f x is less than x dash and y is less than y dash in this norm of x and y is less than or equal this norm of x and dash x dash dash. Unfortunately, there is no list norm of x&y and it is this number x and this norm of y and set operators that can be that can satisfy or they can be considered to be as neurons are the union disjoint suns are some and bounded I think bounded difference also is it's not you can check it. So earlier I asked a question I said why do you have this tip? Well, we have this term to make sure that this value is between zero and one. So that's why we have this term. And when I said should you should this alpha be controlled? And the answer is if we want to make sure that the output is from zero to one then this should be controlled such that alpha is obviously greater than zero greater than or equal zero. And the mu alpha A x is the min of one alpha x. So this way, you make sure that the after the separation is between zero to one. So that's what I was alluding to earlier so it's important to know that T known and it's known represent do logic. So there's one lot so that it again didn't represent the core of the complementary aspect of, of the T and the T is the complementary aspect of, of this. So, the relationship between them can be described as the T norm of these two membership function is one minus s, one minus oops one minus the membership function of x, y minus the membership function of the So, that's how we describe the relationship can be better written in two ways. Ta x, b x is the complement of s, mu A compliment X membership function complement of x as well. So, that's one well, conversely can be written such that it's the compliment, this is a compliment operator T compliment x. So, the do logic between this knowledge genome can be described by these sets of equations. So, let's go and see our slides and see how we addressed some of the some of the limitations that we've had, and just a standardized as much as as possible. So, let's start by looking into the first the first intersection and teener. So this is the operation we can, if we want to represent the intersection, we can just apply a T norm on it. And that will give me the intersection. So, it's an operator that works on an operation that has that we've defined before. As as we said earlier could generalize impression here we have the we have discussion around a generalized intersection area, we described it to be like this. So, if we're talking about membership functions, in the notations are like this, for talking about the fuzzy sets, then the annotations reads like this. So, this is fuzzy sets. And here we are making sure that the operator that you've chosen satisfies the different conditions we have. So, these are two possible forms or genomes. And if you run them, if you run them by the conditions, you will see that they actually do satisfy our conditions and you can try them you can try them out on your own. So graphical examples of T norms the minimum the algebraic product, the bounded product, and the basic product, you could see that they do actually share similarity in terms of outcome so, As we've discussed earlier, because they have to be satisfying to the genomes. They're bounded a lot. Now, they've the very little bit internally. But similar to how the three t know, the three component operators are our new variable. This is an example, I think we didn't have to go through it. Sit set inclusion. So So I think collusion is an important subject. Because when you talk about the set theory, you're talking about unions, you're talking about intersections, you're talking about all these things, but they're also talking about the concept of a subset. The concept that's A is a subset of B. Now, here's a problem that we might have fuzzy sets by design have members who exist in multiple sets. And because they exist in multiple sets what can we consider to be a subset and what can we consider not a subset? Well, from logical perspective, let's answer these ones we can say that A is a subset of B. If the membership function of of a have a the values of the membership function of a for all x's are less than they say for all axes for some axes are less than the membership function of b or same axis. So, if I find axes, if I find elements in A and B, where the membership function for a is less than the membership function of v, I call these I call a a proper subset it is proper, because the membership function is always less or the same elements A can be considered to be a subset of B can be considered to still be considered a subset of B. If the membership function values or degrees for elements of x are less than or equal for the version membership function for B, so because they can be equal not less, it is a subset, but it is not a proper not a proper subset. So these are the inclusion rules. But because of the specularity. Here, we have the concepts of proper sub such now if you have it's fuzzy systems is fuzzy logic, everything is fuzzy. So we don't have certainties and absolutes and stuff like that. And that means we have degrees of things happening. We have grades, we have the inclusion isn't 100% there. So we have to start grading the inclusion. Again, remember the membership function is a grid of belonging. So b x one belongs to set a by a degree identified by a membership function. So if I'm going to say A and B, A is a subset of B, then I will say it's by how much and further sets we like not to be committed 100% and in logic, we have to have some grades to measure that So, for membership, if we calculate the membership function of a being subset a proper subset of B, this is the grade of of the grade of inclusion we can defy by saying this in for a proper subset, it is one when the membership function of a 4x Is this than the membership functional value, if before this MX otherwise just a bla apply a T known for those functions, I could choose any t norm you want. Men is a good example. For an for a subset that isn't proper, we can calculate the greater inclusion by saying one when the membership function here is less than or equal. It's calculation there. And again, otherwise, just choose a T known algebraic product, Cartesian product, intersection whatever it is otherwise, and that will represent the grade of inclusion. For example, I have subset A here, I have subset B, I want to calculate degree of inclusion. So, here A is a subset of B, a proper subset of B from at this point. So, I could go and say, Actually, it's not it's not proper, because it's equal here. So, I go and say, from this point on the grid of inclusion is one cause a and b, a is less than b in this range. Otherwise, I'm just going to take a a a t norm calculation. So, attain or calculation would be, for example, the intersection of these two values, which happens to be the main operator. So, I have these values I have these values, a is greater than b, so, I'm gonna take the mean. So, these are the degree of inclusion or how to calculate it this example set equality we discussed earlier the set of equality we say that a is equal b, if for every element of x i set for every element earlier, the membership functions is equal. So, this is how we can create the set equalities. But also, you know, it's fuzzy inference systems. We love grades. So, we don't have to mandate that you know, for every case, the calculation is the same. So, instead what we do is we can create the grid of equality. I will say well the grid of equality for this operation A equal V is basically it's one when the membership functions are equal. Otherwise, just apply a a t no So, in this case, we think I have an example but if you go back here and use this as an example, maybe, let's see if it works. And this particular one the grade of equality looks like this This looks like the grid recording should we have an exam. But anyways, just to make sure that I'm not missing things dilation and contraction dilation and contraction We said earlier that one operation we have is the power of the fuzzy set. And you know, we can easily say that for you to dilate a set set a all you need to do is to dilate its membership function, but mind you this key has to be the standard one for you to dilate for you to contract a search function same calculation occurs with K he is greater than one. So, the question that that that, you know presents itself Why would you dial it or contract the function like what what would make it a desired outcome? Why would you do that? Well, it's it's very interesting that creating fuzzy sets isn't easy. It isn't easy business. file sets are very are notoriously difficult to create. And by that I mean now you know the actual value of a set, so you want to extrapolate on that one to get something different. For example, let's say that we have this fuzzy search here. Okay, and we have all membership function values for every x. I don't want to die ilish want to delete the fuzzy set. Okay, I'm gonna say the dilation is not strong. Gonna say for example, more or less, or somehow, you know, strong, I'm gonna say more or less a strong, more or less strong, right. So I want to say are somehow strong, so why not dilate that. So what I end up with is basically the square root of these values. So for one, nothing changes. Cause remember, one is a core element. So there is nothing you could do to one to change its valued, whatever new subset you are creating the core elements will remain to view the core elements. And the non elements will remain to be the elements. So you're not changing the core elements, you're not including the non elements, what you're changing as the other support elements that are not kosher. And you're changing them either by making them bigger, like in this example, taking the square root of point five makes it a bigger number. Because for the numbers that are less than one as if x is less than one, and square root of x is greater than x, obviously. Right square root of point two, five is bigger than point two, five, but it's point five. So this is what you get. So you've you've dilated, you, you've dilated, your, your your functions, you've you've made it a little bit bigger than it already is. Alternatively, by raising it to a power that's greater than one, you could tract it. Right. Again, the core elements will not change. But the other ones, the other support elements will have less degree of membership. So for example, if we have a function that looks like this this is one okay if you dilate it so those are going to be one again, for those what's happening here, it's going to be dilated more. So, those small ones here that are slowly going to zero will have increase in their value. So, you will have more than just that in those ones will have an increase in their values only the absolute zeros will remain to be absolutely if you decide to contract it they end up with something like this. So, those high values here will go faster to zero. So, dilation increases the degree of certainty of possibility and contraction degree decreases the degree of membership This is a graphical example this is a and this is contracted a and this is dilated, a this is another example, where we have the continuous case is considered to be young. And this is considered to be all and these are their membership function. Okay. Now, let me go back and say okay, why do we dialate or contract mole incident how difficult it is to come up with this membership function. And to validate it and to verify it. It's hard. Right? It's hard to come up with this membership function to know that, you know, as someone who's 50 is as small degree of membership of old and small degree of membership of young. And to know that, you know, 80 Now is not necessarily all that all two arrays are 70 to validate these values, and to validate that this membership functions actually truthful is a challenge. If you get that if you get these two membership functions, you want to be able to use them to do other things to what other things we're talking about to create new membership functions. And that is the amazing part, you can create a new membership function. How well let's take all four examples. So we don't have to say all the same more or less old. So we're dilating this old to include more but now it's not all old anymore, it's more or less old. So we could do that. We could also take the young and old so this is contraction I'm sorry this is dilation. So this is dilation This is dilation that gives me a take on the old on the old membership function so as is I can use it alright so that's, that's what we can do with with dilation. What can we do also with the with the intersection because we've we've discussed intersection intersections and intersection is something intersection is something a wise intersection important because again, knowing these two membership functions that again represent a gentleman so they represent the same universe, I can start inferring other membership functions linguist OK, so I say I want to say something that is not young, and it is not old. So the complement of young, the complement of old was where do they intersect? So that gives me a new membership function. So dilation gives me a new membership function that represent the more or less old. So it's I'm increasing the membership of alt. The intersection and the complement are giving me an entirely new membership function that I haven't even calculated, then they're not young and not old. But maybe there's another membership function that says young but not too old. No. Young but not too old, what what could you get from this one, because member here, young goes all the way to 50. That's problematic. So when I get that aspect, I say, Sir, too old. So what I do first, I have to calculate too old and that's contraction. And then I take the complement. So the complement of the contraction to have calculated the as a new set, and then I took its complement, and now I'm taking the intersection. When I do that, it gives me wanders. It gave me a new membership function entirely new that haven't calculated. As you know, they're not younger, not all it covers whole of aspect. And gives me another membership function. The more or less old sorry. It gave me a third membership function. That's, that's very interesting. It's this one. She should if you can see it. This one says, young but not too old. Well, it happens to be in in this particular group that you have someone that is not what young but not too young, I'm sorry, young, but not too young. So now, even young is not one group. Even young is not one group because this whole thing is young, but it was just young, but not too young. This gives me this one. Give me this group here amazing. Notice that none of them is one. And yes, you could end up with a membership function with a set that no member is one and that's why we talked about normality earlier. So with only two membership functions here you ended up creating a lot of membership functions with only these two that are present only two extreme aspects of the spectrum. You've been able to create a bunch of membership functions. And you could try things young and not young or old. And but not all but not too old. And you have not younger not old, you could have not too young but not all as well. So not too young or not often maybe you cut whatever inclusion you have here. Alright, so linguistically speaking, as long as you can imagine the combined nation of things that you can linguistically obtain, just by imagining the human concept of young and all, young and old, you could do a whole lot of things, just by having the ability to articulate the norms or the social norms about age. And how you are how people view this aspect. And you could include any form of other things on By knowing the different operations, the intersections, the union, the contraction, the dilation, the complement, by knowing them, you could use them in many ways to generate new membership functions that are going to be useful for you. So, so far so far, we've done many many things. We said that you take data, you convert it to numbers, and then you have human knowledge comes in that defines fuzzy sets. Okay. And then, based on membership functions, you represent those fuzzy sets will present them to look like this. Based on membership functions, you can represent the shape, the inclusion, the shape, the degree of inclusion, what's called What support could do that. And I say, well, there are multiple lots of operations that you could use and lots of operators that you can utilize, and knowing the operations and the operators, we can do wonders we can create new fuzzy sets do not underestimate the ability to create inferences, so we know all that. Okay, what's next? Well, what's next is actually our biggest F Haytham is old and Haytham exercise then he is healthy what's next is to be able to go back and create a box that consumes the input and produce an output output the input being ALT and exercise and the output being healthy. We have an inference system here that allows this human experience is human knowledge to be written down. We have been now we know what all means look like. Now we know what exercises a lot means look like it's going to look like this. It's going to be like this and be those membership functions. This is what all looks like we know the end operator, we know how to take ALT and how to take exercise and put them together with a T known on an order or intersection operator or a main operator wherever it is, we know that so the question is then how do you calculate then how do you get an output. So next lecture will focus on implications or focus will focus on implications to different other operations that that we are interested in because they are an important value and for important values. So next week, I'll try my best to finish or to complete the subject of fuzzy inference systems and fuzzy logic fuzzy sets. If I can't in the week after I'll append it to the genetic algorithms. So thank you for for listening. And thank you for listening and see you next, see you in the in the discussion session. And see you next week. Thank you


ECE657 Lecture 10 Part I
Fri, Apr 07, 2023 10:01AM â€¢ 1:04:00
SUMMARY KEYWORDS
projection, operation, fuzzy, universe, membership, relationship, function, point, elements, calculate, extending, composed, max, inference, extension, set, composition, rules, cartesian product, values

Hello, everyone, welcome to our 10th lecture today we, we we progress on the subject of fuzzy inference systems and the different aspects of it. And the different notions mutations and operations that we can have executed as as, as part of this system of, of machines that machine systems have machinations and mechanisms of doing things. So, in the past, or in last lecture, we've, we've talked about, about the concept of the concept of dilation and contraction, we said, if you have a, a, a fuzzy set that represents a stage of being, say young. Or alt, we said that via via contraction dilation, you could say that someone is less young, or younger, more or less, or someone is too old. More or less young. And, we mentioned also that, by combining the two fuzzy set the two representations, you can end up with someone who's not young Moto, something like this one. So, within the same universe of information you can extrapolate a further knowledge about your pre existing fuzzy sets, you know, young, old, not too young, not too old, with contraction, dilation, dilation or just mixing just by defining operations, that makes the fuzzy sets together. So that's fine. But you know, what, if we were in a position where the, you our universe is perfectly fine. You have all of your defined data sets or fuzzy sets, verified validated with their you know, their membership functions as well. So, let's say that you are at this point, so things are looking good anyways. But then, there is another universe, where there's another universe that is related to the original one, like, let's think of this as for example, Celsius, and this is Fahrenheit or this is some factor x and this is x squared. So, there is a mapping operation between your current discourse or your current university scores to a new university scores, it is new in that you know, the values are different now, was also a a derivation of the Original Universe, you know, speed two, you have speed and you have known distance, so you can get something there. Or you have speed and acceleration or acceleration speed. So, what can you do to, to preserve this knowledge that you've already verified and after you preserve it, is somehow move it to the new universe? Again, if the new universe is a, you know, a derivative of the old universe there is a lot of value that you can extract. So, the, so if y is equal equal x squared y here how do we how do we calculate Let's see This is set A, how do we calculate the new city for y? We know how to map the elements of the universe, it's easy. There's a function there. But how do we map that membership membership function for the different functions as well? Is it squaring your values also, what happens to the values that, you know, to the elements that have more than membership value? Like here, that's member, let's see B. So you have an M, mu b for x. And this is a, so you have another membership value for the same x. So this is x three, for example. So how do you map these two values to the new universe. So things aren't as easy as you know, just square them, because that's, that's not the purpose, the membership values usually represent a logical understanding of what that element represent in that universe. So you can just square it. Okay, what you can do is to apply our known operations, you know, some variation of a T normalness known, that allows you to move the data and move the membership functions have the elements of x to the new universe, of y. So there has to be more nuance to it. And, you know, luckily for us, we do have a calculation that you can use to make that transformation. And I'm gonna, I'm gonna, I'm gonna list it, I'm gonna write it now. But I'm gonna, I'm gonna, I'm gonna have multiple examples to help. So for every y for everyone in this universe, there is a set fuzzy set where a membership value is defined for such why. So here we're saying that, for universe wise, similar to universe X, for every point, there's at least one membership value for a fuzzy set, and it's called B doesn't matter what you called. Now here, where y is a function of x. So y is a product of x. And if y is a product of x, there is a known membership value to it, there is a known membership value for it as long as y is a product of x. So that's number one. Number two, now we've we've said that the membership value exists now how do you calculate it? Well the value is, as I said earlier, a product of ethanol or a combination of this norm and Tino, so is the sub premium so it's a premium, or supreme of the minimum of lots of membership functions. One maybe x to 4x one here. Maybe fuzzy set, two also is present. So it's three and so on and so forth. Every fuzzy set and every element that contributed or contributes to the creation of y. So this why point here is the result of maybe one point result of two points, combine ation of points whatever it is to identify the value of y here, we have to go back and see what created. And based on that we can calculate its membership function. If it hasn't been created by anything, then we'll just assign it to zero. So, here we say every value every every elements in B has a known as a function. And here we say, well, if you didn't, if it didn't come through this path, the value is zero. So assign a default value for what we didn't know where it came from. Now, I've mentioned that it's always a combination of Anis known operation and a teen or operation. So here, I use this loosely, because a max is an ethnos impression. How about the Supreme, or what is the supreme? Well, Supreme is a max if there is a mask max value. So if you know the maximum if you know the maximum value, then you're suffering is the maximum value. But if you don't know the maximum value function on a calculation, then the upper bound of it serves a supplement. So if x is less than or equal 20, that's the maximum. X is less than 20. That's the upper bound. Something like that. Mmm. This is a gross simplification. But you could think of it this way. So in this lecture, in many, many of my notes, sometimes you'll find me use supreme and sometimes you'll find me Max. For all of our examples. Supreme is the max. So it is an is normal operation. Okay, let's have an example of, of transformation from one universe to another universe. And we'll say that y is x squared. I will say that for x, we know of other sets a where the elements are one, I'm sorry, minus 101. And two, those are the elements of this function of this set visit. And the membership that is very, so four minus one is point 340. It's point 141. It's point 242. It's point four. So this is a fuzzy set that doesn't have a one as an element. So it's, the feature of normality isn't perfect. Okay, so we say that y equals x square. So for us, I think for this for the set the new one, it didn't have the following elements, zero times 00. minus one times minus one is one and then one one times one is one and four, so only four elements, only three elements have been produced. From the Original Universe, the space in this transformation, okay, but we know that values forever in each one of these ones, foot so for zero. We said the calculation happens to be supreme of minimum I'm of all the values that that gets us to here at four zero, wait, it's only point 1.2. So 2.1, so there are no other values, so the whole notion of supreme and minimum is useless. So it is point 141, it can come from one or from minus one, this in this operation minus one squared is one, one squared is one. So that means I have to take the max the max of them min for every element, so for minus one, I have only one value. So that's point three. For one, I have only this value. And that's point two. So, the max of this values point three whether we max usually is referred to or it's not like this, and T known as refer to like this. And you will find me using this notation as well. So, anyways, so it's point 1.3. And then we have four only comes from two, so the value is point four. And this is called one to one mapping, we have only one known fuzzy set in universe X, and you can map it to a one fuzzy set in y. But what if we have multiple fuzzy sets? Okay, so far, this is a has the elements of minus 1012. Again, this is an example because this assume that the two fuzzy sets overlap. So, don't worry about that minus 101 and two, so, you have two fuzzy sets, they share the same elements with different values. point 4.7 point 513. And y is a product of these two sets. So, we have x one belonging to the set we have to belong to this now again, they share the same universe X odd belongs to the same universe, just different sets, y is a is a combination of these two, when y is a function of these two elements of these two sets and the calculation could be that y is x one square square plus x two square so this is lots of combinations, right? You have 01141014 And then you have these different combinations coming together. And generally speaking, you need to calculate the membership value. So an example is basically you know, this zero and this zero. So you have y equals zero squared plus zero squared equals zero. So we have an element of why that is you. So what we need to do is basically to calculate the membership function of zero. Okay. So how do we calculate the membership function of zero? We've always said it's, it's, it's a premium of minimum of many things. So what leads us to zero? Well zero is kind that comes from point two and point seven. So there's a premium of minimum. Now this is the same x when you have the same x value, because again, we have this immune Reverse, you have to take them minimum. So it's point two and point seven. And then you take there's a premium. So for zero, the membership function is point two because that's the minimum which is point two, and the max of point two is point two. Okay, so that is how about another element within universe? Why? Well, what kind of an element? Well, we did zero. So let's do one. So, one again is the supreme of the minimum of all values. So when we say f inverse y, we mean all values that had led to the creation of y. So here, for example, these now our two points have contributed to the creation of why. So for one, for one way to figure out what are the values that contributed to the creation of what? Well, before we do the next one, let's find the values that lead to the creation of value. So, for one, these are the pairs that made it possible for us to get one. Minus one here Okay, so these are the four pairs that led to the creation of one. So the calculation would be supreme of minimum of the membership functions of these values minus one, functional zero. So 1.7 is the pair, point 2.7. So, men act only on pairs, okay. Point 4.7. Point two points. So, that means, point 7.2, point four and point two, these are premium this value is pointer because that's the highest value. So, when you have two fuzzy sets, contributing to a new one, it's called a dash. And the universe of y is how you calculate the elements of a dash. And this how you calculate the membership functions of a dash. So how about the other elements? Remember, every fuzzy set in every universe has all elements. So a dash has all elements of y, even the ones that you can calculate a membership function for Well, in that case, for example, membership function have to remember should function of three or those ones or equals zero, because we cannot calculate them. They're not no, they cannot result from any calculation. Actually stand corrected. We wish a function of two is can be resulted from one membership function of three there's no way that you have x one square plus x two square leading you to three. I don't think you can. And that is why I conducted myself for two because one squared plus one squared equals two. So there is this value. For example, we'll assign it zero and you know any other value that may be in a position where you cannot calculate it, you'd have to assign it zero. So for example, six, six is combination of three and three, that doesn't happen to unfold, four happens to doesn't, because there is no number, there is no integer. But the value is four is two is the square of which is two. Now it gets tricky when you start to go to continuous universe, from continuous universe to continuous universe, because then, you know, two is square root of two is present in the continuous universe, you can calculate. So you can have the different decorations happen, and it gets tricky when you start doing that. Okay, so here we introduce the extension principle. And we it is basically, see if we have a nice example it is basically, we're applying Max, like when it is one to one, we apply Max, because you don't have pairs of elements contributing. For example, we're mapping from this state to a new universe where the calculation is x to minus three a square my state. So for the universe, these are the elements of the universe. And it is basically point one and point three, they'll contribute, you'll take their max. So whenever you have a repeated number, like this is different way of looking at it. You list, you take the original values, you transform them, and you keep their membership functions. And then you combine and the combination will become their, their max. So this is the continuous case, which is, as I said, usually challenging because you'll end up with something like this for the membership a grade. of an exam before the continuous case. Okay, so that's one operation that we've, we've discussed, which is the extension, you know, you're extending from one from one universe to another universe, the extension function is known, the calculation is deterministic, so you know how to do it. Now, how about the other situations where we're not interested in extension, not interested in extending the value, we're interested in projections. You know, if you have a house that looks like this, and you're doing designs, you say I want to have a vertical projection, horizontal projection, the house can be translated into something like this. Like, that's projection from the top. And maybe that kind of project, I did not do good in engineering drawing. But you get the point when it comes to projecting a higher dimension to a lower image. So think of projection as dimensionality reduction of sorts. I'm saying here of sorts, because that was never the intention, intention of it. Sometimes analogies are interesting because they help you. You know, imagine how the person works with energy isn't supposed to be the literal interpretation of the operation. So So let's say that we've established a relationship between two fuzzy sets, you know, let's say that we have fuzzy sets a that has three elements. And fuzzy set B that has two elements And we established a relationship or where the relationship between x and y. So this is, you know, X i belongs to x, y belongs to Hi. So r is a function of x and y. So it's a function of x and y such that it is the Cartesian product between X and Y. So what you're doing, you're essentially calculating the Cartesian Cartesian product. So that's, that's the relationship in a Cartesian product is a relationship. But the unique thing about the Cartesian product is that it takes a one dimensional fuzzy set and produces a two dimensional set. of sorts. Think of it this this way, usually the first citizen it does add, it does add a dimension. So when you combine these two fuzzy sets, you'll end up with two dimensional relation. Now it is a Cartesian product, the Cartesian product is usually the mean of the oppression. So I'll say we have point five, we have point nine. We have pointed again, in here the Y, you have point eight, and point nine. And the way the Cartesian product works, it's a T norm, so takes the minimum. So point five and point 8.5, point 9.8. It's point 8.8. and point it is point 8.5, point nine and point eight. So that's how your regular Cartesian product operate. Okay, so we ended up, we took a one dimensional relation, one dimensional fuzzy sets, and we produced a two dimensional fuzzy set of source. Now, this fuzzy set is a function of x and y. And sometimes I'm interested in only in the y component, or I'm interested only in the x component. So I want to take this two dimensional relationship and projected on its axes. So how do I do that? Well, the rule is basically you'd have multiple projections of AR. So if you are projecting on x, then you're taking the maximum value of your resultant outcome of the product projected on x. So if this is your x, and this is your y, then you project into this direction by taking the maximum value. In this case, projection and x is point five point 9.8. When you're doing a projection to why you're going into this direction. And again, you're taking the maximum value on why in this case, it's point eight and point nine. So, if you have a two dimensional matrix and you assume it came as a product of T known and you apply these sorts of rules function, you can extract the X, return them to the X and to the Y source. So it's, it's a neat way and helps you extracting those elements. Okay, there's a third projection is called Total projection that's basically take your goal Next, you're going y, and you'll take the maximum value, in which case it's point nine. That's the maximum element of the whole thing. So so here we we give a definition of the different projections, say a projection, one you have projection to, and you have the total projection. This is the visual representation of a projection, how you present it on whether the x dimension or the y dimension. So if we have a three dimensional sorts of two dimensional three dimensional function here, two dimensional function was great. And you want to project it on X, even W something like this one. I'll tell you why you get this and you projected on why you will end up with this outcome. Now it is not the same, just a projection. So here's an example. We have this rule of this relationship between X and Y, Y and X I'm sorry, the projection towards x. You go all the way here. Any take the highest value that's 1.9. And one projection towards why you have the highest value which is point 5.9 1.9 1.6. And obviously, because one is the highest number here, that's a total projection. But if notice how we were able to reconstruct or decompose it into x&y projections now we didn't know the oppression that resulted in the two dimensional relationship, but if it if it is Cartesian product, and that would be your x and y. Okay. So what do we do after we get our x and y? Well, there's something that's called cylindrical extension because concept of cylindrical cylindrical extension is basically here you have only x and you have only y. So, I want to extend the one dimensional representation of x into a two dimensional representation. And I want to extend the one dimensional representation of y into a two dimensional representation. So why don't be able to extend this something that they can deal with and again, you could think of it as the opposite of demonstrating reduction. But you know, if you have an operation that concerns for example, the union between two fuzzy sets one of them is one dimensional, the other one is two dimensional, well, it looks like this. So one dimensional you have two dimensional. So, this is your x. So, obviously, to do a proper union, it has to be you know, proper damage. So, what you do you take this one, and you extend it on the x direction. So if we, before we go to this example, the outcome of this x if extended cylindrical and r1 would be point five I've got to be, you're only repeating the value do nothing and that's and then you are extending on x. If you're extending on y. Again, these are just your values, you're just you're just repeating them as many times as you have x. So in the previous example, here, we have the, we have the first projection, we have, we have the first projection, the second projection. And now we're just extending it over and over and over, extending the second projection over and over and over. So let's say that you have here one dimension of data set that looks like this. And you want to extend it to become two dimension. Well, this is how you're going to end up with this how we're going to be your shape. Now, it's, it's a neat operation. And so the projection and the cylindrical extension allow you to change the dimensions to suit whatever operation you have. So if you find yourself in a position where the dimensions aren't matching, you just either extend or project okay. So, we cover these rules, we're still having to answer the the the purpose of this of building this fuzzy logic system which is inference. So inferencing is a process of composing rules to generate a prediction now in fuzzy logic, we know fuzzy sets, we know operations. We know operators we know the broad category of operations, an operator and product category of operators, as t known and it's known, and we know how they relate to the operations we know few tricks like extension and projection. So we know enough to be able to start composing the rules so composition, operations, should be able to start doing some composition services the fun thing, let's say that you are in universe X. And you have a good you know, the relationship between it and the universe right. So in the last discussion session, I had seen who say can you have an approach in between two different universities courses? And the answer is yes. You know, think of this as a humidity and think of this as wind and we have also a composition of wind and say that's not good. And say, right, okay. And we know that there's a relationship here and we know that there's a relationship here so, we do have a relation between x and y, and we do have a relationship between y between y&z Knowing that this can I infer a relationship between x and Zed is it possible to imply Can I imply that knowing gay knowing x well that's the inference right so, in a way I need to find an implication and implication I need to find an implication that encompasses this knows to an implication that maps that takes me from x to y is up a compositional operation between what I already know R one and R two this is composition so, I know r one, I know r two I'm going to compose them to create an implication once I have the implication I can do whatever I want now, I want could be as I said earlier, like in this example could be you know a two dimensional set alright could be you know the relationship between x and y could be Cartesian product and now, two also could be a two dimensional set so, I need to make sure that I create the relationship between I create my composition operation to account for the variations of these relationships. So, somehow whether it's extends it to get x y&z I do understand x and y where x and y and x y Zed are x and y is outcome of the first relation and Y and Zed are outcomes second relation now, I need to compose all these things which means I need to find my operation needs to be inclusive of variation okay. So, earlier we had dealt with an issue, what do you do have outcomes that comes from different variations and you're mixing them together to get an outcome that was basically the the extension that you had earlier where you know, you had to multiple variations coming together and producing a new outcome one value as a matter of fact. So, this had served us very well earlier. So, why not saying that the membership function have the implication here the inference is the supreme of the minimum of these religions relationships on what they share, right, so on on the direction that they are sharing, for example, here that would be on why. All right. And that's why what we're interested here is why? Because that's what what brings them together so, on why. So think that's the projection but think of it as a projection why. And now you're taking different variations. So the projection but I'll give an example. So let's say that we have a relationship that's characterized as 010001001 here, that's your Y and that's your x. And you have another relationship that is characterized as and that's your life. So now you're comparing the y's together to produce a new role. So If you're taking these two things together, first you take the minimum of wise and then the maximum this relationship, so the minimum is zero. So you have 001000101. And their minimum here is 00, and zero, so that's it, men, men, and then and then you take their max chapters to be zero as well. So what we've learned earlier when it comes to extension happens to be very useful. So let's see what we have as as, as an example. So, in fuzzy inference to make a process, the rule K is first collectively match with available data. So you start with matching rules for data. And then you've you start identifying your composition or role by saying I is composed i is D composed with K and the calculation of the membership, the implication is a premium on the minimum of the minimum on y given that y is the shared element between the two relations. This relationship is known as sub premium minimum or maximum. In most cases, it's only it's just known as as maximum compression or composition. Okay. So let's see if we have an example we have a and we have c. So, we identify relationship by four or by saying that you know, the relationship between ANC is minimum pressure sores. Okay. So, and we have another another operation here. That is, y and z. And it's calculated this way. So, these these are my membership functions, these are my calculations. So 0.10 0.70010 0.40 point 2.1 Is point 1.2 point 2.21 point what is point one, so, just have this pairwise element and take the minimum and that time to create your membership functions. Okay, before I go on, and present the rest of the example, I'm gonna have to get back and generalize what we've learned so far. It's very important for us to do the generalization. And that basically means that if you know x, and its relationship to y, and you know y, and its relationship to Zed there's nothing that prevents you from saying I wanted to from x dash, the implication was basically mapping from x to z, but if I know this implication, can I map from x hat to Zed or from x hat from x dash dash? So if I understand the implication that allow me to map from x to Zed Can I map a slight variation of x to a slight variation of that so if I, if I find this as per this rule, can I do that? And this is what we're doing here you identify your composition. This case, we made it to be this one. And then you introduce a new A that is different than you originally And then you apply it, you apply your max min or supreme min rule. And you end up with something like this. And that's basically your c dash more in this later. Don't worry about it. Think of this as a precursor of why we're teaching why I'm teaching the the operations of composition. To give you an easier example to digest. With Vinod say that they have two relationships that look like this and now I want to know the inference or the composition, composition in operation, so are composed with R two R one composed with R two gives me my application, I just want to calculate the application here. Well, it's a max min operation here. Alright, so in this case, let's do Max, I'm going to do only one and then I'm going to list the numbers and then you can calculate it on your own min on the same values here. So let's say that this is your y and this is your y, okay? So you have point five and point six you have point five and point five. I'm sorry, point five and point six. So this is why one, this is y two, this is y one, this is y two. So for y one and y one, oops, y one and y one, point 5.6 For y two and y 2.1 and point five so the minimum here is point five. The minimum here is point one. And their max is point five, and that gives me the first that gives me the first element here, which happens to be point five and then i i Go on there, take this one, I get it here. So take this one I composed with these two, this one composed with these two, and that gives me the rest of the first row and that's the implication of r1 composed without the value. So now I can use this one to the bunch of other things. Now as you've seen here, it's a max min operation. So it's a max min operation don't have to be a maximum crush to be quite honest. Right. Max isn't is non operator men is it t normal operate. So you could have max product that's another 18 Or you could have a max average whatever T norm you have, you could use it to do the composition so it doesn't have to be maximum composition okay here we talk that you could do multiple operations doesn't really matter to reminisce now. What are the properties of composition? Well, the properties are basically as we said last time commutativity so O P composed with Rs are composed with P associativity, distributivity. And De Morgan's law as well as inclusion. So same rules as we've seen in the past, apply. So I want to there's a very quick study case study case study that I'm not going to explain, I just want to walk you through it. And I hope that you folks are work at it at home. This is a very detailed example, where we are going to be applying all the operations. But we've had in the past, so our he is the relationship in the relationship between x and y, this is x and this is y in terms of elements, so they have equal the same elements. And the fuzzy relation is represented by this. Now, whatever lead to this to do relationship, it doesn't really matter. What we know is our x and y is this to the relationship. And the problem statement says have projection over X have a projection over y, r, have a relationship of x, y to one and X i to do. So there's plenty of things you've been asked to do. And that almost goes through the entire operation that we've presented in this in our so far. So this think of this as the capping example, where it takes you through whatever, whatever, whatever you've taught, you know, there's projections on X, there's, there's the having the relationship being between x and and, and one. So basically, it's an men relationship. There is I'm sorry, not men relationship is one is forcing the value on on one or on two. You could have different projections, union intersection, a cutoff at certain alpha, alpha can be defined, you'd have extending extensions, you have the graphical representation of these extensions. So this is a very comprehensive example that you could go through to better hopefully better understand the different concepts that we have outlined so far. So this is the this is the the conclusion of the first half of today's lecture. The second half will go into the inference into how to write rules, how to translate rules into fuzzy sets, how to drive predictions, and hopefully that drive or brings about closure to the subject. So we're going to talk more about if if a is x and b is y, then see is it so if it's raining and it's windy, that's if it is humid, and so indeed it's gonna rain. So we're going to talk about how do you get how do you go from from writing an actual rule linguistically to a number Alright, like it's gonna rain might be prorated. So if it is if the if the wind is 50 kilometer, an hour humidity is 90. Then there's 70% chance of rain, something like that. So we're going to talk about how to get to that to there to see you in the in the second half. Thank you


ECE657 Lecture 10 Part II
Fri, Apr 07, 2023 10:02AM â€¢ 1:13:54
SUMMARY KEYWORDS
rule, dash, fuzzy, output, calculate, observation, max, input, operator, entails, intersect, composed, function, consequence, called, point, antecedent, inference, intersection, crisp

Hello, everyone. Welcome to the second part of today's lecture 10th lecture. In this part, we will get to the point where it gets me, it gets interesting. Now that whatever we had to fall wasn't interesting. But there's lots that's been left to design, which is basically, we have been taught quite a lot of things about how fuzzy logic works, fuzzy sets, rules, stuff like that. But I've never gotten into the prediction, or the intelligence component of it. Which, given the title of the course, is an interesting thing not to tackle so far. So I want to go back to where we started at the beginning of the course, and see how we can you know, complete the circuit. So fuzzy reasoning. Plus, I'm saying reasoning here. It's approximate reasoning. When approximating an output, whenever you have a box, an input and output is machine learning in this is an approximate approximated output. And this is in this case, a fuzzy inference system it is a conclusion from a set have f, then maybe you can say else, then rules and non facts. So this box is basically a bunch of f s, or F then rules that have been built on known facts. Example, if x is A, then y is b. Right? If X is n, then y is b, this encompasses any rule. If you wait up late, then you can arrive late. X is a is an antecedent Why is B is a consequence. So in a way, what we're modeling is a connection between antecedent. And a consequence that's built on experience. I know many will ask me, how do we get to these antecedents and consequences? And the answer is absolutely expert Bayes. And this is the implication that we've had earlier. A leads to B. So let's settle with the rule is a leads to B there's that connection between A and B. So if x is A, then y is b. Okay, the antecedent and the consequence are facts. Facts as insofar we believe in our experience. So the facts because we believe in our experience. Now, the facts are facts when we write the rules, but in reality, we don't have The same factual observation for example, if it is if it is in the morning when the sun is in the East these two statements are correct, but what if the time was noon? Will the sun be in the east? So, what's the input mind you this is our our part of the box this is your f then oh f this than this, but what if the observation was a little bit different from the knowledge with which you built your information. So, there is a deviation of the observation deviate. So, it is not morning, it's new. Well, the consequence the fact that the sun in the East should not remain as is it should change slightly though, right because this is not a huge departure from the fact. So, the observation here is a little bit deviates a little bit from the fact so, you have an antecedent you have a consequence, you use your knowledge of the antecedent and the consequence to create a rule and then knowing this rule, you could move and fair a different outcome conclusion based on an observation. So, to refer it is a conclusion the output is a conclusion from a set of rules and non facts. So this is a conclusion that is obtained from sets of rules and no in fact. Responding I can add responding to an observation so that's basically it. Okay. So what we need to do is the ability to move from a dash to v dash the composition rules that we've learned earlier tells us if you want to move from here to here to means a dash needs to be composed with this so B dash is a dash cam composed with a rule that are the rules that we have created. So a few notes, usually when you create a rule, it's two dimensional. You know, think of it as a some sort of Cartesian product. And the observation is, is is one dimensional. So this is common. It's common that the observation is of different dimension from the ruler. That's why we a little bit changed this shave and we'll say well, the dash is the sort of cylindrical extension of a dash composed with a with a roll of MB. Again, in case this is one dimensional, this is two dimensional you need to do that to allow it to work together. So that's one, two, as we said earlier when it comes to the company position. Usually when you have a composition rule, the arrangement for it is a max min arrangement. So, that's a max on the min arrangement. Okay, so that's, that's basically us being able to obtain be out of the observation and Okay, so here is I've mentioned, I've discussed this dash, dash and dash and that gives you v dash projection projections, we'll discuss this. Okay. Okay. stration. Okay, I have you here. So the rule of inference in a conventional logic is modus ponens. Affirm by affirming. So here's an example. If tomato is red, that's a fact. Then tomatoes ripe. That's a factual conclusion. Okay, which means a implies Orientales. B. Now, in real life, it's not the city that the tomato is red all the time, tomato could be slightly red, or little bit red or mix. So as it's ripe, maybe not dried, maybe slightly ripe. So again, the fact that x is a is a, the role of x is eight in y is b, and the conclusion is consequence is wise B. In fuzzy reasoning, x is a dash. It's not a so it's a little bit right 100% trade. So the rule is based on the facts, so the conclusion has to change a little bit from its usual factual situation. So if we're the case, when in building the rules here, a looks like this, then the observational most likely look like this. So this is a and this is a dash. But if that's the case, then B that may look like this. May looks like this. That's B may in fact, be something like this in this v dash. So our job is that we need to be able to figure this v dash out of a dash given our initial factual factual observation. So this has to be based on real data or real life information. The way you construct your fuzzy sets, like this is an actual fuzzy set. The way you construct this fuzzy set this from real life, these fuzzy sets are going to be inferred. They aren't going to be calculated before the input is presented. Once we get that we're looking to something like this, which is generally just the application of max min rule. So Max over x where you're applying the min on the membership function for the observation and the membership function of the rule. So what we're interested in at this point, so this is a this is a given is how do we calculate this membership function folder and if we calculate it, then everything else is done. And we can add we can address the situation where to make to a slightly or it we can we can predict with a tribe are a little bit ripe Before I go to this example, I'd like to actually present a I would like to talk about this notion here because it's important for us to be able to calculate this membership function. And I think it's important to understand how we can do that. So, to go back if x is a then why is b Okay. So, the rule is that a leads to b Okay. Now, this is this rule can have two meanings linguistically speaking, the first one is a is coupled with B the way we understand it is that if A is present then B is present and vital A is coupled with B the second one says a entails b so, the existence of a tells you that B exists here a comes with B they come together and second one if one tells you about the other. Now, there is great deal of similarity between those two notions but if we want to calculate remember membership function for all we need to understand whether a is coupled with B or A entails V and we need to understand what that means mathematically how do you calculate the membership functions up so, let's start by saying a is coupled with B will is coupled with B as you can imagine, means you have a T operative between the membership function of A and B the couple the lead us to believe that to calculate the membership function of r you need a T operator operator to operate on a EMP and there are many many T gnomes that can be used right we can use the main operator This is called the Mamdani segment alright. So, a dash composed with odd is a dash men a men B second option to represent a TI operator is algebra algebraic product and you may see this referred to as Larson's rule Oh, you could do a bounded product so, this whole thing becomes if this man could do it like this, and this isn't mean for example, if we're talking about them then but anyways doesn't really matter what you choose. All of these ones are T norms and they will give you the representation that A is coupled with we now, be mindful with this presentation here that depending on what you do now with a min there's no problem here, but if you use Cartesian product is Do you know this can be TD Two dimensional, which means you have to change this one. So, keep an eye on it, if you decide to choose the norms that present that take you from one dimension to dimension the second option is to represent second option is to represent a is a entails B. So, that's Option number two it can be done in many ways. One of them is called the material implication it is basically our is a entails B which means a compliment can be represented by a compliment now, it says Matt Union but think of it as is known. And that's called that as implication. So, that's what There's also something called propositional. Calculus and it's basically our A entails b it is a max or is norm A T norm b and this is the complement in some of the literature, you will find it described as union intersection. But I'd like these notions because they are more generic and I do want to commit to union and intersection on a make it is known to there's also the Extended Properties propositional calculus and again our A entails B is a complement B complement b Okay. Again, you can see it in other areas where it says A complement intersection of the union B complement a complement a complement okay an example the example of present if x is a then y is b x here is has three elements and why has to a in this rule is represented as this could think of it as triangle MB is represented by this halftime So, now we have our fact. So, this is our rule these are facts This is the antecedent and this is the conclusion. And we have an observation which isn't the fact this is this is a bit different than the fact that means if x is a dash then y is b dash surely remember t, x y there's always a there's a rule say if x is greater from x dash and y is greater from y dash, then T x y is greater than T extension y dash, forget about this one, just understand that the same operators apply, even if we change the fuzzy sets as long as they belong to the same universe, this is certainly the case where this is the rule the fact and this is the observation. So, now, we need to calculate we have a, we have a we have V So, we need to calculate v dash which as we said earlier a dash composed with the relationship between arm. So, we said this one now that now this whole thing is maximum, so there's no problem now the problem is how to calculate this relationship well we have introduced multiple rules I think we're going to use this one to represent a entails the reason I'm using it is because my example actually uses in the slice users man damn and Danny and Danny so I want to use something else in this example and then we'll go back to mum dad. So, propositional Calculus says that R is a compliment to a maximum. So, what can we use for this one this is a t know a T operator T no operator. So, you could use Cartesian product it is x y So, a d x 1x 2x 3.1 by two so, 5.1 point 5.5 And point five is point four. So, point 5.41 is one and one is 1.4 is point four. So, one point 4.6 And one is point 6.6 And point four is point four. So, point six and point four. So, this gives me this part. Now, ah again is the max between this, so, this is two d, and this is one D, so, I'll take this cylindrical extension of a and I'll take the max would be So, for a dash happens to be point six point 9.7 Sorry, this is great fix fix. This is the compliment I'm still doing so, the compliment of A happens to be so a compliment is point five zero and point four so, is point five zero point 4.5 0.4 cylindrical extension if if you missed it, it's basically because this is X you have to wise you're just repeating your x twice. So that's an integral extension. And all we need to do is apply the cylindrical extension and that tells me that our MB on x and y is the max. So here is point five and point five is point five zero and one is one, and point six and point four is point six. So I have one, I have point six, then there is the calculation looks like this. And that tells me that I hear a B A tells me so this gives me gets me all the way to this room. Now we said b dash is R is a dash composed without of x and y. So now we will only be left with the composition. So a dash is point six point 9.7. That's along that's the T transpose on x. And the rule is point five 1.6 or the relationship point 5.4 And point four again. So now we have to do max this is a max menu. So we'll have to do the men. The men of point six and point five. The min of point nine and one. The min of point seven and point six and Max on it at max on the main of point six and point 5.6 And point 5.9 And point 4.7 And point four Okay, the first one is essentially point 5.9 And point six and the max of it is point nine. And the second one would be point five that's a min point four that's a min point four that's a min and the max is point five. So B dash is point nine and point five that's P that Videsh you guys CB it is 1.4 So slightly different from you're actually slightly different. Which isn't bad. But that tells you how knowing how knowing your you'll, your rules and your facts and your observation can lead you into knowing your outcome. So let's see, go through some visual exercises. We'll start with this visual exercise once again. We said it's a maximun rule. And what we'll be using for most parties is McDaniel. That's what we'll be using. Pay which is basically a dash a just a straight up employee imputation of over Theano. So we have A and we have a dash. And all we need to do is to take the min and in that you projected on B and that tells you will be cuts so that you'll be dash. So a dash gives you the intersection point you projected in B and gives you the new B. That's a visual implementation of how v dash is different than b okay if you have to antecedents So so far, we said one antecedent, and one consequence if a is x than y is b, but in most of the time you have more than one antecedent, you have two unseeded antecedent, sometimes three antecedents, and the gist of it is basically if it is humid and it's windy, then it is going to rain. So you have two antecedents. And when they come together, they contribute to the consequence. So how do we deal with that? Again, let me in the past when we had one antecedent and one consequence, we said Will a dash, the observation T operator on a Additi operator on V SM dinosaur? So what do we have to so these two represent a one antecedent one consequence? Well, it doesn't make a whole lot of difference. So originally, we said we have a and we have, we have beat and less than right, and this In consequence, now is there C as well. So in a way, we need to solve A and B together. And then we need to solve whatever comes out of them. We'll see because a he does entail B, or s coupled with b, a and v. So as coupled with a B. And once those two things are coupled with each other, they're coupled with C, so that gives you a, b and c or this T operator. So in a way it becomes a dash A, B, and C. So having more than antecedent just means that's why we've done is rule is very much liked, because all you need to do is to add a T operator here in a good shape. So the result would be I'm sorry, I just say here, there is B dash as well. There is also a D, A, B, C. So this is my rule and then I have A dash and B that's coming together. So I need to solve this situation. And then I have them composed with the row. So with mum, Danny resolving these two would be just a dash at the operating room Videsh, so that's fine. That's one value. And he it's another implication solving. So when I had to present that in a max min rule, so Max oxen, Max on x and y on this whole calculation So leave this outside, all of these are T gnomes. So there's really no reason why we should separate them, or put them all of them like this, they shouldn't be proud, this is actually very proper, with the, with the properties of T normes. A, B, C is A, B and C. So we're applying those properties. That's why the properties are very important. Now we rearrange, which is also a, b equals b, intersection with it. So we rearrange. So put the B de dash next to a, we'll put the B dash next to B. And we live we leave the scene so and now we apply another property that we've learned. And that property says A, C is A union B intersection A union C. So this is what we did here. We apply the max on the first element here. Write and then there's the T norm here. And then we apply the max on this term as well. We've done nothing wrong, we just distributed the max. So what does that mean? Well, it does mean that I have the A's together and the B's together. So I can calculate the degree of validity for x and the degree of validity for Y, how far is B dash from B? How far is a dash for me, and this gives me my firing strength. So, let me explain what does that mean? A intersection with a amusing intersection here as an example of de nom is equal A if A equals A dash, M B intersection with V is equal V if b equals V dash, so if you're if your observation is as is exactly your fact, fewer observations are your fact then this entire term becomes a, b, c, which is the value of your room. Essentially, your conclusion is the factual conclusion. So that's one that's why the findings so the findings T string here is max if you think of it as the finding strength opposite if this is a and this is a dash then a dash intersection with a is fine. See, similarly b dash intersection with V can also be fine. If this is what you have Bnbs which means either this or this can be zero. If that's the case, then your value here is zero because you're taking them in. So if any of the observation is outside of the fuzzy logic, representing your facts, then your membership function for that observation for that The rule is zero. So as an example, we have more than one antecedent, we have two inputs A dash, and B dash. Now a dash intersect with a, so that's good, B dash intersect with b, so that's good as well. And now we project both of them. Not on C, but on a T node. So let's say it's a min here. So we take the minimum signal, and that gets projected into C, and that gives you c dash. So a dash teen on a intersection with a, and here's you have a teen on B dash, teen arm B. And all that is projected or intersected, in essence, with C. So that's the visual representation. Okay. So I said, so far, this is one rule and one conclusion, what if you have tools and that's also the case when you whenever you have a fuzzy system, you have lists of rules. I tried to figure out your outcome based on the list of rules, right. So earlier when I gave my example here, about a dash and A being five, I said your outcome can be fine. Okay, what does that mean? Well, it means that one of the rules will not yield an outcome, so we'll have to go with IELTS right. So else here is an OR function else is all right, either this rule or this rule or or or or okay. So, the calculation is fairly simple. We have two inputs A dash and B dash composed in the past was A dash B dash composed with R. Now we have two Rs, two rules R one. So a dash v does in the past used to be composed with R. Now we have two Rs as composed with either one of them. So you have a maxi or you have an old or you have a union, one of if we did if we distribute, distribute, which is also a property of compositions, then what we need to calculate is basically an A dash, b dash composed with r1. RS two, we'll distribute so we calculate a dash v dash composed with r1 Ada dash, b dash composed with Archer. So we can create these compositional values, we solve them as in the past multiple antecedents, and one rule, and then once we have the outcome we'll take the max. So that's that's essentially how the calculation is, is done. So an example here, we have rule number one, we have rule number two. So you have the input. The input intersect here with a two and a one. So they intersect in both. So here the first wa fires for both routes, be in intersect with B dash, and b two and b one. So WB fires for the first row, and WB fires for the second row. Okay, so forget about the second rule. Let's solve for the first row. So intersect here, intersect here, the T norm takes the minimum. So this is my output for the first rule. intersect here intersect here so This is my output for the second row, the function, the C's, they didn't have to be the same. And the is in the rule, they didn't have to be the same. The observation is is constantly the same observation, but the membership functions varies based on the rule. So, for example, if your rule is if a is small and B is fast, then C is close else if A is medium and V is soup superfast then see is more or less close so if you want to visualize what this says is that small and medium are two different fuzzy sets, right. So, here, you're saying this is small, like this. And here, you're saying you have medium, which looks like this, that's A and then B you have fast and super fast. So, which could be real fast here and super fast here. So, you have fast and you have super fast. And then you have close and soap and super close, closer more disclose. So, this is close, and this is more or less close. So, this leads to close. And this leads to more risk close. So, now your input, your A could look like this. So it applies for both, and your B could look like this. So it intersects with both. So you take this one intersect here, intersect here, take this one intersect here. So, this is a very bad example, because I did functions I shouldn't have done. Let's make this way. So it intersect this way to 60 intersect there. So you have this and this and this. So you have this area and you have this. So that's that's how you ended up with different activation functions for the different roles. Now, once you have the output of rule one, Rule two, it's a max operation here. So you take as we said in the past, it's the max. So it's it's a max, for every point. It's a maximum value. We've discussed that in union. So think of this as union of C one and c two, same implementation. Okay. So, so far, we spoken about the fuzzy input, we spoken about the fuzzy output number, and we spoken about the rules and we spent some time on figuring out the rules. And we discussed you know the variety of implementation. So here we have 1234 rules, you have one input, it activates one input value activates multiple rules. And then you just take the min for each rule and then you take the max. So so far, so good. But we have an issue here which is basically your input It's usually a crisp value. So your input is a crisp value. And your output is not a crisp, your input is a crisp value. But your rules are fuzzy rules. So how do we take the input? And we make it look like this? Right? I mean, the observation isn't this kind of function, the observation is usually a number 30 or 50. are served. That's your observation, your observations in actual number, it is not this font, this this fuzzy set. So how do we make a crisp value? If false, is it? Well, this is a process that is called falsification? No, chill. We take a crisp value. I and you falsify it. So if you have an observation that says, the value is 30. So that's you advise you a Chris value me says, you put one. If y is y, zero, why not? And zeros? Well, so if this is why, and you're 30, then that's. It that's what. So that's crisp, falsification says no, says one, if y is y zero, so it's one decrease otherwise. So instead of zero everywhere, start decreasing your value. So you activate at your values, one, add the actual reading, what a decreases, it decreases with some delta here. And there are ways of calculating the decreasing, you know. You could, like here's the calculation. So these are defined number originally, in your classification process. And this is your, your reading the value that you read. So you decide what are going to be your extremes. It's maybe delta over your y zero. So in a y zero plus 30%, minus 30%. And then you say this is the 15% 15% here. And that gives you the different values. And the reason why we do that is because no measurement is 100% accurate. So you want to allow for imprecision. If you remember the first time we spoke about fuzzy inference system, we said, we need to make value of the imprecision and happens that say, Oh, what was the speed of the car around 60, around six, this is a, this is 60. What we're seeing is not just 60, we're saying it's around 60. So allowing for this versification. And depending on your function, whether it's singleton with it that's crisp, or triangular or Gaussian, all you need to do is to apply a function. And that function will do the calculation for you. If this triangular, this is the function for it to the Gaussian, and this is the function for it. And essentially, it's it's just an application of it. So here's an example where we have an input, that's an absolute fact and you have to act fuzzy functions and the input intersect with both. So what you do is that you say well, for a one dash looks like this, and for a B dash looks like this, and you apply your rules. So you have an input a crisp value. You falsify it So Chris fuzzy phi, you apply your rules here you have an output that is fuzzy but the problem is that your output usually goes to a machine. So, your fuzzy system is for an air conditioner and now you're saying the output is slight increase, that's the output that's it for the output your air conditioner needs a precise voltage value to operate. If you you you cannot input this kind of a shape to a motor like okay what does that mean? You have to put an actual voltage value. So the machine can operate which means you have to de Fuzzi fi so output can be crisp. Okay, remember, last last lecture say I said you will be able to say if it is windy, it is humid, then it's 90% chance as scary. This 90% is a crisper, the actual output, maybe slight chance, high chance of raining. This is fuzzy. That's good. But you may want to a number and the number is 90%. So how do we get to the 90%? Well, there are many ways to go about it. And I'm gonna I'm gonna pass to this graph and explain on it how you do that. So I'm going to use this graph because it has positive values. So, if you see what we did here we said if you have multiple rules, your output is a max of these multiple rules. So, your output most likely will look like the union of different fuzzy sets. So, now, we have an output that looks like this and we want to take one value. So the output goes from minus 10 to 10 we only need one value one value as an output not all these matters. So, what are the weights which which with which we could use with which we could you know obtain the output? Well, there are multiple approaches. So, the first host of methods is called the maximum the maximum. Methods and the maximum method is look at the maximum value. So this is the maximum value here and choose either the small note the smallest of maximum, so this one as the smallest maximum or the largest of maximum. There you could use the mean of maximum surrounded Sir Arthur, it could be two could be five, or could be it depending on your choice of method, whether it's IS LM or M or M. And that's a parameter that you have to designate. Once you designated we know which one is your OPT. So that's one approach and it's called the maxima methods. Another approach has to do with the centroid methods. So, reality of the matter this is an area so as an area may be the centroid of the area, the center of gravity or maybe the center of some or maybe the center of area different ways of calculating the center's like different ways of calculating the maximum, which is S O M, L, O M, M or M. So, whatever it is, this will give you the number that can respond to the center of your gravity, for example, or somewhere. And there is a value in knowing that because that value correspond to, you know, to some meaningful geometric representation to understand what do I mean by geometric representation. If you have a circle of supposedly a circle, then your center of gravity is this point. So, this is an extreme unique point. If you have a triangle then your center of gravity is this point. So, this point is very valuable like there is there is a geometric representation to it. So, if you go to this graph, for example this can be your center of gravity, this intro is a little bit higher, but that's most likely because of the way other stuff, but this can be your center of gravity. So, the value here which might be 3.5 becomes your crisp output. And that's in essence, the diversification scheme. You choose one of these methods approaches and you choose one of the methods of the approaches. And I know, I know that I will be asked which one is the best the best one or which one is the most suitable one? My answer is like always, it's up to you space and experience and subject matter understanding there is no right or wrong. The last in the fuzzy inference system is what we I have alluded to in the past, which is basically how do you build a fuzzy inference system. And in the I said, we do have a max min model, which essentially take the minimum of your inputs operators, A, B, A, B, and C. And it takes the max over all the rules. So that's called mem Dan is fuzzy ml. And then there's another model is called to genius fuzzy model. A third one that I'm not going to cover it's called scope. tsukamoto Fuzzy mode. So let me cover these two as the by their name. The Mamdani is a max min operator. So you apply min on your inputs all the way this was we've explained and then you take the max of all rules, and that becomes your output for your input. So that's, that's the Mamdani fuzzy model. And here we have a bunch of examples and how you calculate the output sugeno On the other hand is an interesting model. So while Mamdani is a fuzzy base is tea is a fuzzy logic based system. One output is calculated based on the minimum value intersection value all the way this genie the output is an actual function of the inputs. So you have to calculate an equation for example, if x is More than y is this equation, if x is medium then y is this equation, if X is larger than y is this equation. So, you come here and you apply your math you know small this is your actual input value, this is your x input value it correspond with lot it correspond with meaning medium here and correspond to small here. So, with small you get this y one with medium you get this y two. With large, you get this why three? Now, how do you get your output in Mamdani, the output is the maximum or the union in sugeno, the output is the average could be a normal average y one plus y two plus y three divided by three. And if you have weights to your rule, then it becomes a weighted. Average. And that's a genius model. And here are a bunch of examples. Or you could go through them to see how it applies. Now, this is this marks the end of the fuzzy inference systems, we do have a couple of case studies, I think it makes sense that you go through them given that we have exceeded the time a little bit what you're gonna get out of them is basically how do you take your rules and present them visually. And then based on your input values, you start calculating your output. So, this is min Mamdani. So, basically you have your input here and your input here, this is the minimum set triggers here empathy and empathy are the minimum set triggers here empathy and empathy and these are the minimum. So, triggers here triggers here and all you need to do is to take the maximum of the output which gives you this function and then based on your method, maybe centroid, you can create your diversified output. And again, the other example is similar, again to this meme, Danny's fuzzy inference system, a bunch of inputs and you have the outputs. And he explains the reasoning behind the calculations. So, these are three quasi fuzzy case studies. Go through them. If you have a question, we can discuss it in the live session. So next lecture will be dedicated to the evolutionary computing, I can allocate a part explain the case studies if you folks feel that they are not clear, but I need you to explain them to ask them to make this clear to me in our next discussion session. And this way, I'll understand whether I can review some of these case studies next lecture or not. So looking looking forward to your feedback. So thank you, and see you next week in our discussion session.


ECE657 Lecture 11
Fri, Apr 07, 2023 10:01AM â€¢ 1:42:09
SUMMARY KEYWORDS
chromosomes, mutation, solution, fitness, solving, function, crossover, problem, chosen, probability, generation, encoding, multiple, represent, chance, selection, genetic algorithm, calculate, constraints, understanding

Hello, everyone, welcome to our 11th lecture on final lecture as well as a matter of fact. So, during this storm, we've gone through multiple subjects. We've covered intelligent systems and vision system design, we've gone through a discussion what do we mean by intelligent intelligence. And then as we explored the tools for intelligent system design, we we first discussed neural networks and how it looked like and the various paradigms, learning paradigms architectures and the way it works, whether it's forward neural networks or recurrent neural networks, deep shallow or supervised, unsupervised and then from there, we moved into fuzzy logic or the field of fuzzy logical fuzzy inference systems, and then we introduced the concept of soft computing. So, it was a belated introduction. But it made sense because its introduction came from, from the field of fuzzy logic, so I wanted to be late about that. To be able to give the field its its you credit for it, I will say soft computing is is basically our ability to exploit implicit nature's tolerance to imprecision and uncertainty in fields of, of learning. And, you know, we say an example of that is fuzzy logic, and fuzzy inference systems at large as they represent the behavioral aspects of, of our surroundings, if you if, if if you want to think of it, you know, it's it's how we act, how we reason how do how do we arrive at conclusions, and I discussed the multiple approaches there. And prior to that, we looked into largely neural networks, we discussed also logistic regression, but you know, they're used for neural networks anyways. And that's more of a biology approach where we said when you look at how brains operate, and we think they have new, we know they have neurons, but we think that they interact certain ways. And we try to model systems based and our today and I'll find a lecture we are going to discuss an entire different field of study for soft computing and that is evolutionary evolutionary computing and that's at this is as as as as aged over technique as the other two fuzzy logic and your network trace back the roots in the 50s and 660s. And so, those illusionary computing it does take a different approach towards solving problems. And our emphasize the word solving problems here because for fuzzy logic is about solving problems, right? It just go about it based on him. verbalizing, using the language to to write your your rules or understanding neural networks is about also solving problems. Evolutionary computing is about solving problems. Maybe Different types of problems by mimicking the, the, by mimicking a certain understanding of evolution, in how things evolved from one state to another, embodying lots of the evolutionary concepts. The much talked about concepts is not the scientific concept of evolution, it just talked about concept, what we're good at is taking a very surface look at a subject and we think it works this way. So therefore, we're going to build an entire approach based on what we think things work while they're being developed. So we have neural networks developed in the their precursors, you're talking about 30s, and 40s. And what we thought then 100 years ago, that our neurological system, the way how our neurological system works, so you have a very limited understanding of how things work. At the time, and even the scientific truths or facts or, or, or relevant or prevalent opinions aren't. Will position. So when you when, when you study, these algorithms, please do understand are just, it's a take on a subject, it's not, it's not the way the subjects operate in the field of study. So please do not debate evolutionary scientists based on what I'm going to present to you today. So I think this whole long winded conversation is basically to prevent that from happening. So usually, computing is basically a creation of an algorithm that mimics what we think the evolutionary process looks like. And and the the goal of that creation of that algorithm is basically to solve certain class of problems. And that class of problems is optimization. So let's say we have this function. Okay, so this is a function we're weird one, but let's say that our goal is to is to find x that minimizes this function. So, there is no deterministic way through which you can find a solution this is not a convex problem, you have lots of local minimum you have multiple maxima as well. So, this one maximum, one maximum, one maximum, one maximum, this is a global maximum and bunch of local maxima. And similarly, you have a minimum, a minimum, another minimum, a global minimum, and bunch of other local minimum. So, you have that and think that your exercise is basically to figure out a way to solve this problem where you can end up not necessarily if there's minimization with your global minimum of this maximization, your global maximum. That's not the goal of the exercise. The goal of the exercise is to get a good enough maximum say this one or a good enough minimum, say this one that yields an answer in a good time. So, essentially what we're saying is that there is no deterministic way. method to solve for, say one. And then well, we'll have to also say we don't need this, we don't need necessarily to find the optimum solution so we're fine with having some imprecision in our answer, as long as the answer is good enough. So I think the concept of good enough. That's so with that understanding we need to also understand why wouldn't we use because some might chance saying, Well, if you spend all our time, just go one by one and compare every point here, computationally, you could actually find your global minimum, you could actually find your, your global maximum just by brute force run all of x's. Alright? The challenge is, this problem problems can be computationally prohibitive. Brute force can take forever compute. And usually, you're solving the problem for real time application, which means you don't have weeks to optimize, you have a module, you have an engine, you have an actual actuator, you have something that's actually running. And it requires you to provide it with an input that, you know, with a prompt with, which is going to act, you know, you have a controller, and you want to reduce the temperature. Alright, so you're trying to find the best parameter that gives you the best new temperature, okay? Do you want the best new temperature was good enough temperature that doesn't violate constraints? Well, if the best one could take forever, so maybe a good enough temperature, or an input for your engine is enough. So even if there's a solution might be computationally prohibitive. There are also there are also problems that you're trying to solve that deal with with this continuous problem, space, or function, you know, if you have a problem that looks like this, no. Where these areas are undefined, you know, think of them like you're dividing by zero here, something like that. Alright, so the function has is undefined here. Even with the idea of hill climbing, or, you know, ascending or descending to find the solution, you may end up with a situation where you can't necessarily descend your hell then climb back up, because there's nothing to descend here. So the function could have multiple places where it's not defined, or he didn't know what's going to happen. So that adds a layer of complexity to your problem. There are a class of problems that are difficult to handle. Yeah, they're constraints that we think of integer programming, for example, and stuff like that. There are a bunch of problems in optimization that makes any of the deterministic approaches here and no go. There are NP problems so you don't have a deterministic way to solve that problem. system is problem for example. So, there are many ways where many problems that cannot be solved deterministically there are many problems that are very expensive to be solved deterministically So, knowing all these things and knowing that we we can generally tolerate in precision a new class of problems, a new class of solution was was designed where, you know, finding those, those peaks, and those valleys can be done in a good way. So, there is so there's that that aspect of things where we could do these things. And that's evolutionary computing. So, the goal initially, is design an algorithm that solves solves for parameter estimation No, I have no undefined problems, but you know, your problem is trying to do some parameter estimation. So that's essentially it. Okay. So what's genetic? Computing and, you know, what is as you look at the algorithm for them, what's that algorithm that we are designing? So, as I said, GA is an attempt to naively mimic an incomplete understanding of evolution. When I say Mimic, I say like, every mechanism or mechanics, the mechanics of, of, of the actual mechanics, right, and you program them and you put them in an algorithm, then you use the algorithm, that's why it's the so let's, let's let you take a step back and say, Okay, let's, if we're now talking about evolution, then we'll have to break down the concepts from evolution perspective. And again, the idea is quite intuitive, and that, you know, you know, the whole concept of sequence survival to the fittest, or the most adaptive. And the way, you know, you produce solutions or genes does make sense, if you're, if you are producing things, and improving up in your solution. Solving a problem means you find a solution, then you improve it. Right. So let's, let's take a quick step back and see well, how does the cause How does our understanding of of distribution theory look like? Because that will inform our the algorithm is created. So to think that you have a cell and you have some 64 pair of chromosomes. Usually, you have a nuclear he nuclei here. And in your body, those cells usually split, right, okay. And medical of nature, they split and they produce new cells of the cells and they replace the old and dying cells. With again, some 46 pairs of chromosomes. This process of splitting is called mitosis. So that one we're not interested in, much like we know the cells split and produce new cells. But it doesn't help us in our approach. What helps us however, if we take this one, and we consider it from pre production perspective, Because of usually volution is generation generation exercise takes generations to reach to any stage. So if we are going to go about reproduction now, so we have the same cell on a cell, and it has its own pair of chromosomes, chromosomes, and then you know, it splits like this and from it it have another cell that has half of the chromosomes the combining companion cell comes that has also another half chromosome. And those two cells combined and produce a noose new cell it's actually the 46 pair of chromosomes. Skulls meiosis So, this process called meiosis So, you've noticed that you have to if I were to enlarge the if I were to improve this graph let's say so, you have your cells that are usually engaged in mitosis. Contributing half of them in a meiosis process where you have a process you have a process of generating a new cell, entirely new cell that combine elements from the origin from from the parent cells. And that means you have a new generation and there's a lot to look at here. This, again, is this very primitive understanding where there's lots you can glean off of it, and there's lots you could learn from it. The first one is that the new generation the chromosomes aren't theirs, right. This is a new generation, but their chromosomes come from zones come from prior generation. So, it makes you it's something that you have no contribution to, right yet you have not chosen any of your features, those are heredity. So, you know, you have the heredity aspect of things. You got no choice in these things. And some of these things aren't even hurted from the parent generation. As a matter of fact, the majority of them are usually come from the the one generation prior to the grandparents generation, which what led to the creation of this cell. You think you have so, you already have contribution coming from from from from many generations past. So, this generation is made up from previous generations, and those previous generations interact. There are all sorts of things that could happen where those chromosomes not like there are the chromosomes are perfectly split. So, you take half of features from one generation and other half features from another generation from another parent. That's that's not how outcomes, you have things that come together that mix, you know, you could have a Schabel an eye from a parent, but the color of the eye from another parent, right, you could have a color of hair from one parent and the and the texture of hair from the other parent. Or you could have mix of colors, you know, you could have many things that could happen where it's a cross over between a group of heretical features, that creates, you know, a diversity of the things that you could have access to. All right, because the passing of genes means there are many, many, many things that are left to chance to what to get, because you didn't know how things mix up, you didn't know which chromosomes you're going to end up with. So there's lots of chance to choose stuff. And the higher the diversity of things you could choose with, the greater the probability of, of things to move. Alright, so the concept of diversity here comes to mind, the diversity of options, what you may end up with. So, because of all these things, and because if we trace this back perfectly, you could see that there's a limited amount of things you could access access, could access, there's a lot of probability. Or chance, say chance. That needs to be taken into consideration. Okay. So that's essentially, if you take a look at this overly simplistic image, you start thinking, Oh, well. Now that's, that's an interesting exercise. Okay, why? What does it mean to me? And that's, that's a fair question. So we'd like to take this a step further. And say, we're actually not talking about sales here. I mean, reality for if we, for being honest, the whole concept of sell doesn't matter. We're not into building sales. What we care about is those chromosomes because those are the ones that carry the genes with the information. So if we want to model it in a way we can say, well, let's say that we have a group of chromosomes Okay, say that we have a group of chromosomes so let me bring it back on now. Chromosomes usually carry information, data, every chromosome carries certain piece of information or certain piece of data. And let me be a little bit callous here and say, well, let's say that scare is actually bits of information right. So let's say that this is what we have something like this okay okay. Now those chromosomes come from different patterns. So, you know, many, many things could happen, you know, some chromosomes pass as is so the data pass, as I say perfectly inherent, and fathers notes which means the next generation would have the same data makeup some chromosomes, you know, not all of them will pass. So, this passes is and you know pass really a piece of information here. And this one passes only other piece of information. And then for whatever reason you cross over and what happens essentially, is that you're only passing part of the chromosomes are part of the information, not all of it, and the rest of it is made up by the crossover. The same goes here, you're only passing part of the information and the rest of it comes from the previous patent. So that's gonna happen, you know, this is a chromosome that went as is, you know, passed as this was same for mission tat. And this is a chromosome a new entirely new chromosome within different information. Now I know this is seems like duplicate but human me, life is not that easy. Actually, let me make this zero so you'd have pre produced chromosome you have new chromosomes just from this process, you have chromosomes that for whatever reason. Usually rare. Just end up mutating. So passes, passes, may take this zero, for example, at meet, it's very rare chance, but mutation does happen in law in the environment or life. So it's a possibility, and this is us modeling this possibility. In our understanding, so this is the understanding of part of, of, of how creation is creation, how the generation of a new generation and the creation, new generation happens. You know, and let's say that the other chromosomes just pass as is. Something like that. Okay. After that, after the process of meeting. What usually happens over a long period of time in life is that every part of these things does represent something, you know, to present an object. So let's say object one object to object three, object four, five, and six. So whatever, nose, ears, eyes, lips, hash, all of these objects do have some fitness value. And you know what? Maybe you do have two options for the nose. Why not? Alright. And that fitness value is how good it is. So let's say disqualified is 8075 6065 40 and two. And again, over a long period of time the probability of being chosen later are the probability of it being being past starts to be makes sense, you know, calculate. This is good news. How often how, what's the probability with surviving multiple generations for example? So there's a probability of survival is going to be at 0% here could be 10%, it could be 70, could be 60% or and after that, after the After many, many, many generation, or generations, you know, some of these chromosomes paths end up surviving, because they have high chance of survival. And some of them just die out. Once that's done, you have a new case of reproduction. So there are lots of questions to, you know, like this is how we think of taking data, or chromosomes information, and then trying to understand their goodness, in this evolutionary process. So, we need to figure out very few things, we need to figure out how do we generate these informations are represented? How do we do the mating part? Now, this whole cross over thinking? Like, what are the chances of it? This whole mutation part thinking, like, Oh, what are the chances of it as well? This this also case of, of something that gets selected as is? What are the chances of it as well? Also, who said that this is a nurse, like who was able to take this code or this information and say, Well, it means this symbol, you know, so moving from chord to some sort of a phenotype when we say this is a nose, this is a mouth How do you calculate fitness? How do you calculate you know, the chances of being high fit high fitness so there are lots of questions. And we can better observe them by drawing some parallels between our genetic algorithm and the problem that we're trying to solve which is optimization. So, you know, when optimization you look into objective function you have constraints you have your input parameters, right? What's going to come in you have success calculation, or maybe you call IT Convergence calculation very much tied with the objective usually. So you have these things. Now, let's look at the problem that we're trying to deal with when we did about so this is this is optimization normally also how to solve the problem? This can be something I've solved for us to create Well, first we need to figure out you know, encoding i How do you come up with these numbers? And why is it vital we need to figure it out. Our meeting on population was to publish your meeting. These do not come from nowhere, has to be a place where they start the starting point of your mating pool. Actually, similar to similar to optimization in which we had our fitness for our fitness coach maybe maybe it's tied to calculating success here. Cross over is also something that we need to figure out. And so is mutation. So you could think of fitness as a way of looking into the objective function optimization. So if you, the closer you are to self satisfying an objective function, the higher fitness, you know, think of us trying to maximize the price of a motion does. So your fitness score is the price of pride. So, you know, that could be it. So, knowing these two things, now we have an understanding of as we develop a genetic algorithm that deals with encoding, I'm gonna make the connection, your input parameters while acknowledging your constraints in doing so, it will and the questions more impacting even the population selection here on the mating pool, urine your ability to calculate your fitness score based on what should have been the conversion objective function. And, you know, also your ability to converge, or conversions also is an issue. One Stop. So, if we look into the field of search we look into the field of of, of search techniques. There are multiple aspects of it, there's the deterministic one, there's the numerical one on numerical approaches. And there's the guided random search. From that you have two classes, we do have evolutionary computing. And simulated annealing simulated annealing is when you try searching by having big steps and short steps after to find your solution, you know, think of you have a hot liquid in a spoon and you move the spoon a lot. So the record moves and starts to freeze. But when you move a little bit, it reaches where you want it to be. So that's called simulated annealing. So search techniques guided on themselves evolutionary computing. From there you have four paradigms. The first paradigm is genetic algorithm. And that is the one that is more concerned with actually solving optimization problems. From there, you'd have two other paradigms we're not going to discuss today. And there are basically different takes on either genetic algorithm or genetic programming. So what I'll be discussing today will be genetic algorithms, and genetic programming, I'll spend most of my time on genetic algorithm, because if you understand it, then the other three are just variations of it. Okay, so as I said, genetic algorithm is interested in solving for these challenges. Essentially, the first challenge it solves for is encoding. Encoding is the ability to take parameters of a function and actually put them in numbers, you know, let's say that you are solving for y equal function of x 1x 2x 3x, four. Those are your your, your, your, your parameters that we can represent them as a form of genotypes. x 123 and x four, call them genotypes. They're essentially the genes, okay? If you look at evolutionary computing if you're looking at optimization, then if you are minimizing for y, then you're trying to find x 1x 2x Three, and x four that minimize for life. So this is your solution is to find the best value for all these four parameters so for me, you know, you think all I want to represent them by some numbers like, you know, 0100 or something like that. So that's encoding your encoding you genotypes into some values. And after that, you know, you take this encoding, and you put it in numbers that can be understood. And that means converting to phenotype. So, we're currently concerned with how do we encode? How do we encode our parameters? Well, these one is binary coding. So you know, choose and vector length of when forever every gene or chromosome and then you know, assign values to it, different genes, chromosomes could have different length. So this one is for, as long as three forks up. You could have as as much length or as little length as you want, depending on your precision. So in a nutshell, you can actually go to this problem and represent the solution space as binary values. There's another way of doing it called floating point coding. And that's basically your inputs. Now, your parameters x and y, x 1x 2x 3x. Four are actually comes in real numbers. And you put one renumber after the other, which means you don't have to decoding, you could just represent this as point 3.45 And seven, as is, there is no need to, ah, to change them, crossover can be done by just taking the average sort of actual crossover. And there is something called Gray Coding. And it basically you're going to decimal numbers and you're mapping them into your binary digits. And every single time you're increasing your number, you're increasing one digit, you're changing it up or down. And and your operation of minimization is by calculating your hamming distance between the adjacent numbers, so 01 They are in distances, when for example, something like that. So this is another form of coding. Today, for most likely we will be using the binary coding just because it's easier to explain in the context of of genetic algorithms. So genotype p is your inputs, as I said, and the inputs code for your phenotypes. So, he calls the 110000 is this code represents your phenotype or your solution essentially have a good solution that solution okay. So solution oneness phenotype, so, you can choose another phenotype and so on, so forth. Right reality, when you put all the chromosomes together, you could say well, this is a monkey, this is a cow and so on and so forth. Or this is brown bear. And this is why to bear and you are in the in the ports, like in the South Pole, not the North Pole, whatever it is. So, white bears have higher chances have have higher fitness to the world. So let's let's take few examples. Let's say that for y x 2x three and x four. We are going to be using binary columns. So this is solution one and this is solution two possible solutions. And you go ahead and you say, x 1x 2x three and x four, and x one has 01 1x. Two has 00100 is length x three has 010164 has 011110. B is our solution to this problem solution for this problem. So 00101011110101010, something like that. So, essentially, this is a minimization problem where we took the potential solutions and represented them as binary numbers. Another example, for encoding if I wanted to make it in a much in a better optimization function is basically let's say that we're trying to solve for A minimize x two divided by two plus 125 divided by x. And the constraints that x is less than or equal 15. And greater than zero, notice that you have zero here. So you cannot divide. So, you have x. So that's your parameters, that's all problem to solving for your coding for it could be something like this, this is your decimal 30. So that's basically simple, you just come and produce a bunch of potential solutions to the problem. And then you you proceed. But the first part is to look at your optimization problem, and to extract your parameters. Now one, and then you decide on generating your input size. And maybe because you're here limited to 15, you say the maximum is what what, whatever provides you with 15, maybe in terms of length. Another example if you're solving for this kind of optimization problem. So this is a huge, this is a complicated problem. By the way, it's not an easy one to solve to optimize for. And let's say that, for some reason, your x is constrained from one to 10, your y constraint from 10 to minus 10. So your sort of genotypes are x and y here, and you will present them with something like this 0110111001. So this is 13. And this is 25. Notice that 13 is higher violates the constraints, and 25 violates the constraint. Although that's bad, this means the distribution has bad fitness to sell is going to be chosen, but you can still represent it it can still be an option because remember, you're listing multiple representation of different solutions. Okay, so we said so you have solution here you have solution here, I started going to randomly choose 1,000,200 station. Once you've chosen multiple solutions, and you've encoded them, you need to figure out how to select them. So you need to figure out the selection of the next of the fit solutions. Now, relative the matter once you're done here, you're qualified your problem. There is bunch of genetic operations that you need to do. So everything I'm gonna explain right now is an operator. So remember when you look here, encoding is basic include encoding, basically So at this point of our understanding of genetic algorithm, it gets you to the point where you do have your chromosomes represented as binary numbers. After that, the actual evolution algorithm kicks in the actual genetic operations it can. The first of these operation is selection. And selection is basically you look at you chromosomes. And so the way it goes that you have to calculate the fitness of your chromosomes. Solutions So, how do you go about that? Well, there are many ways to go with well, you could calculate the probability of choice by basically normalizing the fitness of every solution for the summation of also issues. So, basically, you're saying the summation of the, of the vulnerability of choice for all solutions are calculated only once. To and that is what we describe as the roulette wheel procedure. So, assign a probability to be choose chosen for reproduction. And then, you know, let's say chromosome one, chromosome one, let's take this a little bit to the side. Let's say that chromosome one has a selection, probability equal 9990 is a lot equal 20. So that's, that's, that takes a lot of, of the piece of the pie. Other, right, because this one represents one, the whole area represents one if you're at 20%. And you're taking this pie chart, right. So this is 20%. This is 10% is whatever. So when you flip when you rotate it, if I find that your piece of pie is here, your chance of being chosen in an hour late is is way, way bigger. So that's the winner. The problem that you're it's you're, you're rolling in rolling the dice as you choose, which means you could choose the same thing multiple times because it has higher fitness, ie the chromosomes that are more precise, with a higher fitness, not just have higher chances of being selected to the next generation. It has higher chances of being selected multiple times to the next generation. And that's the conversion of solution. If you have a solution, that is the best solution. And you want to choose five potential solutions out of 10. Wouldn't it be good is that four out of those five new solutions are basically the best solution. So therefore, you didn't have to choose between them. So that's the concept between the whole relating, there's the ranking model. And the ranking model says, instead of having to worry about calculating the probability, because sometimes, because the fitness values would be very close, sometimes their probability of choice will be very close. You know, you'd go from 70 to 10 90%. That's not a lot different. So you may end up choosing a bunch of things here. And if you lower 70% to one or two, you do not want to choose 70%. So instead of doing that, maybe you want to do ranking. Maybe you want to take your top, so ranking. Maybe you want to take your top 20 solution and those are the ones that pass you get them passed to the next Just getting chosen. Alright, so that's the latest. The latest just choose the top 10 or 20. And those are the ones to go to the next iteration, the ranking. The ranking is basically, we fix this ranking, and I mentally just the ranking builds on the elitist. So it says, you know, if you're number one, your probability of being chosen is Is this some value that you predetermined as the value of choice to the best solution you have. Now, one who comes after, can be chosen if the first one is not chosen, so that's the probability of them chosen. Given that the first one wasn't chosen, I'm sorry, I've left it, that's affirmative, them being chosen, given the the first one was just. So there's probably two of them being chosen, given that no one else, the previous two were not chosen. And you could think of it all the way to the last one. Having this probability? Okay. Something like that. So once you rank the probability of choice here, first, you, you still have the latest still there. So number one has the highest probability assigned to them by you, you get to say, Well, if you're number one, the probability of choice is 50. It's not based on their fitness. It's based on a predetermined value formula, and then you rank the rest of them as normal. And then you play your knowledge. And this way you get, you may get to choose your one, your best solution over and over and over with no problem. So that is selection. If you have 20 solutions or of chromosomes, how do you choose the top chain, and that's one way to go a lot. And other operator is cross over. So that's another operator. So I have to again, take you back to my example here. We said from the solutions, some of them get selected as is. So we explained how could that happen? How you could actually get selected directly, and then others could cruise over as well. So now we need to calculate how, how crossover happens? How do you get to a point where you get selected, again, when you get cross off. So crossover is basically to grow chromosomes, or solutions or solutions. Crossing values to produce something new. Essentially, you have the first chromosome here, you have the second chromosome here. And your first chromosome will be merged with the second chromosome. One way to go about it is fixed point. Crossover. It's basically you have one point here. That's fixed at length you say like, after Tim Pitt Timbits you crossover. And what you do the part before the crossover point for the first chromosome and the part after the crossover point for the second chromosome get merged into a new one. So something like this gives you this output. Something like this gives you this output it's as simple as that. Another approach it's you know, you do it twice you do two points. do it twice, you have two points. And then you get to it, you get to cross them over in many ways, you go at the beginning, you cross over here, and you come back at the top. That gives you one way. Alright? You come here, you take the top, and you keep the bottom. That's another way to this basically how you got these two. What also, you could do something like this, you could cross at the beginning, and don't cross back up. Or you could go all the way to second and then you proceed, you could do this, and then you do this or you could cross from it. So you could you could treat the MultiPoint sector points are sold in many, many ways that that gives rise to many potential possibilities of crossing over. Now since we we said possibility. Cross over has has to have a probability value assigned to it. Okay so now we have two probabilities, probability of choice or selection, called selection here for now. And probative Cross offers. So those are two probabilities. I just want to remind you operators selection. Cross over. The third potential operation is mutation. mutation is essentially happens in life. It's not common, it's Rev. Every mutation is rare. That's why they always unfortunately, on top of a certain diseases, they say this is a rare genetic mutation, they are rare. But again, if you're going through hundreds of generations, mutations are bound to happen. You know, why do you have white bears in the poll? Well, because that's a mutation, or one simply mutation throughout the multiple generations of black and brown, there's the white bear on the pole, it's there's lots of snow, just survival there for something that is white. So it assimilates with the environment, it can hunt safely, is higher than those who are, you know, clear in the environment. So the color that works best with the environment has the highest chances of survival. And then this how you get degeneration of lots of white poor nerves. And the fact that now we're seeing bears that aren't white bears in the polls say that there is a change in environment that generated in us successful mutation for the new adaptation. So it's, it's, it's, again, from an evolutionary perspective, it's very interesting aspect to understand how the slow to understand the flow changes. And the environments it's an evidence or a witness of a slow change, because change because mutation is one of the things that are mostly most harshly judged by the environment if it is bad mutations in the environment, deems it deems it as not fit and kills us are very quick. But if survives, then that means something another example of mutation in life the there's been study of female elephants in Africa not developing their their, their ivory. And the reason why they you know, because of the hunters and the bitten they tend to kill them for a chance to sell their ivory. So a change of environments it they don't need it anymore because now it's a liability they get killed because of it or the females who do not have them do not get killed. Therefore, they get to be to re to procreate, and therefore the produce new generations with the genes of not having adverse ivory tusks. So basically, that's another example of mutation or environment where, where it was mandated by the environment for it to happen. So mutation is a very handy tool, when you understand evolution. And when talking about optimization, I would say that you will do in a case of optimization for a function like this one, sorry, for function like this one I'm going to change it a little bit here. New distribution happens to be here. So, mutation allows you to somehow cheat by saying, Well, I'm going this path. And I keep going up, which means most likely, I'm going to end up with this main. Alright, you know, you go down, you go up, distribution, not good. Not good. Not good, this good. But mutation does is basically this point is 30. And this point is 70. Mutation just takes it and randomly throws it can randomly throw it here, but can also randomly throw it here. So you have good mutation, and there you have bad mutations? Okay. So a good mutation will lead to a solution. So you're here, boom. If I the next edition of a fast, you're here, you're stuck in a worse minimum. So that's a bad mutation. But mutation gives you a chance at exploring aspects that you wouldn't normally reach just by going normally. So that's basically what mutation is, it's a, it's a bounded mental change of the structure of your algorithm of your solution that allows you to do things that you have, you wouldn't have the chance of doing normally, or going through these two operations of selection crossover, because depending on your starting pool of chromosomes or genes, there isn't much you could do other than doing lots of crossover to introduce diversity, and crossover selection, crossover selection. But still a product from the ancestor genes that you will produced. Mutation says, all those ones are great, but I'm gonna introduce something that's never existed before Charles Lee, new prospect of my solution. So there are multiple ways of doing mutation. The easiest way is basically you go and you take one binary value, say one, and you flip it to zero, or you take a zero, and you flip it to one. That's the easy one. How you do a mutation, just find the chromosome. And, and it gets chosen. Let's say you're chosen, the it's chosen for mutation with certain probability. So enlisting our genetic operations, selection, cross over. And mutation, all these are usually driven by some probability value, or relative selection, probability of crossover and probability of mutation. And what you usually have to deal with is the aspect of playing with these values. The aspect of assigning some value here, so you may be biased towards crossover. So mutation, so you drag this point here, so less chances of mutation and higher chances of crossover and selection. Maybe your opposite. Maybe you're saying I didn't know why. Why would anyone think that but I want to ever want to meet it. Alright, that's bad. You didn't want to see a loss. Some mutations because most mutations aren't good. Alright? So but anyway, you get with something like this even allows mutation, and maybe lots of crossover. Or some might say, Listen, I want to, I want to select all of my solutions. So I'm gonna give you a small space for crossover mutation. So which means if you have 10 G chromosomes in the first generation, it's going to have 10, you're going to have 10, and so on, and so forth. So what are the known issues of whatever I've said so far? Well, because it's heuristic, because there is no way that you judge success in a global way. At reality, it's it's, it's it, you may end up with with premature convergence, you may end up hitting your local minima. Again, there's, it's a heuristic approach of just walking. And you hope when you're hoping that your starting point was a good enough starting point, that you will reach a solution just by doing selection and crossover. But usually, that leads to local minima usually. Unless you have a fantastic starting point. Well, alternatively, some people say, Well, it did use mutation, because mutation frees you from your starting point. But mutations could start interfering with each other. That causes you to go back and forth. You know, you have a good mutation here. Because you didn't know which mutation works or not. Now mutation here throws you here, then you have another mutation throws you back here, another mutation throws you here, another mutation throws you here. So if you if you do have a lot of mutations, they just interfere with each other. There's also a now an issue of deception. Now deception, the literature, there is no universal definition of it. But think of it as a way that your schema, the way you encoding or representing your solution gives you misleading information about the fitness, the way you're presenting your solution, or the way your skin because some of the schema allows you to do random things like some of their presentation allows you to simulate represented like this going to start here. So, some of those representations might give you misleading information about your fitness value. And if your understanding of fitness is incorrect, then you may end up having a bad choice of probability of moving forward now, because fitness contributes to direct calculation of selection like in the room late model or it is directly associated with the latest model or associated with the ranking mode either way anyways, if you are not getting the proper fitness understanding of your solution, you ever will end up with a bad situation. Okay, so last thing in conversion in genetic algorithm. Last part is convergence. So, we have encoding and we have genetic operations that you have conversions. So how do you convert well, you convert with maybe some criteria like number of generations. You say my solution is going to be found, after 20 generations time. My solution will run for 30 minutes you have no more new information from your krisily formation is bad. Let's say no more improvement. No improvement, no see no improvement. You know, if you have a conflicts function, and you're here, no matter how you try, you're not going to have any improvement right. You're done. So, if you observe that case, then maybe maybe you found a good solution. Most of this is manual inspection where you actually go and see your, your, your current generations, you know, you have multiple generations exe. So you go on your investment, you manually inspect your current generation of species. And if they look good, then you stop the, if they didn't look good, you just keep them running until mon generations are produced that you like, there are features. So that's how you do convergence. So if I was to, if I was to, to summarize how genetic algorithm operates, you know, you do have to start with an initial initial population of chromosome solutions. And that gives you your population. Once you have your population, your initial population, you can create this fitness value. Alright, so let's say that you're trying to do minimization of effects. So you calculate. So it's F x, y, z. So this is your initial solution. So you start with 20 of these values. And for every one, you calculate effects, and that gives you the fitness the fifth, this is just the value of f x. So you can create that, okay. And maybe the value is zero. So you know, if x is greater than zero, and there's a solution that gives you you what you want. Okay? If that's the case, then awesome stop. That isn't the case, I do have 20 solutions or 20, chromosomes, none of them is what I want. So what do I do? Well, you have three operations, selection, crossover and mutation, you go on, you apply your operations. And from there, you produce your offsprings, you apply the selection, you apply the crossover, you apply the mutation, and now they give you 20, new solutions, not new, like 20 solutions for offspring, some of them are the same ones, some of them are new. And those are your offsprings, they represent your new population, you can call it the fitness value. If then, if this your solution, yes, stop, no, reapply the evolutionary operators. So basically have the for for the patience, you have the present generations, you do selection, you have the parents, you apply variations, new generations, you replace, and so on, and so forth. And that gives you the cycle with which you could go out forever, but you know, for as long as, as you need to be. This is the algorithm for genetic algorithm or just its representation in actual pseudocode. And you'd see that, again, how the process or the process is described in pseudocode, in case you want to actually do it yourself. Okay, so, in implementation perspective, it's fairly easy. So let's take an example. And see and see if, if, if, if we can solve using genetic algorithm. So this is all a function that we're optimizing for. It is not just a simple function for optimization, like if someone gives you something like this one, it's really tough task, you know, cosine task exponential, certainly is a function of constraints is that x is between zero and point five, that's your constraints. You want to use your precision by three decimals. So your encoding has to be three decimals. Your population size is 10. So you have 10, two possible solutions for X. So your gene, genotype is x needs to be represented, encoded to be precise by three decimals. And you have 10 of it. The probability of crossover is zero is 25%. And the probability of mutation is 10%. There is no probability of selection Shin, because every every chromosome either selected, cross over or mutated, so that's essentially the understanding. So you start at random. So this is your initial population a randomly selected, okay, between zero and 1.5. Some of it are a little bit greater than 1.5, which then I'm sorry, between zero and point five, some of them are lit. Some of them actually most of them are below point two, which, you know, if you're okay, this is my range, but all of them are less than a very small portion of the, of the solution, which is fine, like there's nothing against that. So you have your initial population, and now you start by producing this is like, if you want to imagine it, if you plot your function, it looks like this. If you throw, I'm trying to find this anyways oh, my fault, I was looking into the wrong values. Actually, the decimal values here, go from zero all the way to point five. And based on that one, we calculate the fitness which is just plugging the numbers just plug in the numbers here in this function. So that gives you the fitness and then based on the selection probability, which is based in your fitness value, you'd have these values okay. So, this is our graphical illustration. Now, obviously, this is your solution here. For them, if this minimization and this is your solution here, if this is maximization, obviously, so anyways, these are the cars these are far from either solution. They're far away. So let's do the first generation and we'll apply selection. Again, we'll select a population of 10 and there is nothing there. We were essentially selected the new population using the relate so some of them had been selected twice this has been selected twice had been selected two or three times actually these two had been selected twice okay. So this is one solution, this is one solution, this one solution so 123123 or solely for from hear me for from here means for me only four okay so this made it because had higher probability this made it as well a lot times and one point or three and this had made it again. So these two for example, have high chance of being selected just because of hers fitness value, essentially. Okay. Okay. So now, again, our solutions if this minimization here is maximization here, you're still far away from where it should be. So we apply another operations, and we'll do crossover. Again crossover is is is probabilistic. And we decided that probate is 25%. So those two gods have chosen mutation has probative 10% or for whatever reason this government chosen and we're applying mutation on it, as well as crossover between those two values. And then we have a new decimal values and we have new fitness. And now if you graphically Look at the new values, they start appearing here. So again, you're still far away from your maximum value, but you are the peaks. So when we started when we started early on we were everywhere. Now, we are at the pits. Now this is a still local maximum, it's a good one. Now if you keep doing that, select, mutate and cross over, select, mutate, and crossover select the mutate crossover for 16 generations wind up. So we start with wind up with the solution that has the highest fitness value being this one. So actually, and by the way, this is very odd, like this is very uncommon example. But actually, we ended up finding our global Maxim maximum or maximum all of our maximum compared to everything else we end up with by finding our global maximum just by iterating through these exercises 16 times. So that's actually that's genetic algorithms in Nutshell. Population, population, fitness, those itself know, lots of evolutions, and so on and so forth. Okay, there's another aspect of genetic computing called genetic programming. You do genetic programming quite a lot. So genetic programming doesn't do deals with structures. So it doesn't necessarily deal with. It doesn't estimate x 1x 2x. Three, and on the like. It estimates how they interact with each other. So let's say that I have some effects here. Okay. And I know that my parameters are x 1x 2x 3x. Four. But I don't know. How, what is the function of those four variables? I don't know how they interact. I don't know if x if x is x 1x 2x 3x? Four. I don't know that's the function. Right? So what I do, I start by saying I have few operations, addition, subtraction, multiplication, division. And then I say, Well, I'll start with maybe multiplication between x one and an operation between x three, and maybe another operation here to an x one and x four. So in a way, you say, well, maybe y is x one, multiplied by x three, multiplied by x, one plus four, something like that. So this is a model, right? And essentially, what you do, these are your chromosomes. These operations are your chromosomes. So you have a bunch of chromosomes that represent a function, a program or a function or an operation. And you do start putting them together in different ways, right? And maybe you do mutation, so you mutate in this operation. And now instead of it's x one, plus four, maybe six, one plus five, so that's a mutation on All right. So that's you could do that mutation. You could end up taking this operation and studious let's do this again x four and four okay and this is seems to be addition so, this is an operation you can take it and you can put it somewhere like here, they could put it here and then it becomes something like this multiplication here x one here and multiplication x one and x three sorry take, it could cross over between it could change the makeup of this code and it makes something new out of it. So, now imagine all these chromosomes are functions programming functions, like Functions in Python, for example, self contained functions, they take inputs and produce outputs. And you're mixing them together in a diff in many ways, and they are recursive functions as well. So they can do the same things multiple times you can do it differently. So, imagine if you take a complicated those pieces of self contained codes, and you throw them to solve a problem, right. And you let the algorithm evolves your program by copying and pasting essentially, those functions multiple times to you. The depth also can be something that you control by saying go as deep as maybe 100 functions in different orders. And see what comes out of it as, as an exercise like, you know, you want to create a program that allows the robot to avoid obstacles. So you say, well, it has to go left and right and forward and backward, up and down. Right, so okay, and Taz, where it sees it obstacle has to do this. So a signal from so you have a function to avoidance, you have a function of stuff like that. So you have all these functions, and you throw them, right, we throw them in multiple random permutations, and you let your program runs. At work, you'd be extremely surprised by the amount of things you could do, just by going through this exercise, like the amount of cool things that can come out of it. That even you don't know how, how you could come up with because you're not actively writing the algorithm, you're writing your functions. Now, even writing the function is not an easy thing you need to be there's lots of programming overhead and in writing those recursive functions, but once you do that, the outcome would be something that even you the program, don't necessarily know or expect. So it's very nice how you get it becomes you're as surprised as anyone else but by your by you creation. So that's genetic programming a nutshell. It's about the structure of your model, not about the values of your model. And again, like I gave an example of program, but the example could be your modeling a phenomenon so you know, the input is wind and humidity and stuff like that. Those are the input of your system, and the output is something that Okay, and your model is to try to figure out how can I create a relationship between those input parameters to simulate my, my system, and you try different ways. And, you know, surprisingly, it works very well, that it models your system in a way that you didn't expect, even if you didn't know all of your parameters. So think of modeling as another aspect of genetic programming or the way to the upload an approach or usability of genetic programming. So that's genetic programming. It's it is genetic algorithm in the sense that, you know, population, genetic operations, knew of proofs of springs, and so on, so forth. But is more about how do you put programs together. So that's basically it in a nutshell. So I hope this, this sheds a good insight on genetic algorithms and genetic programming. There is much more of on the subject reading about it, you know, multi objective genetics algorithms and how to deal with constraints. But in essence, this is, this is how this is the gist of it, if you wish, I tried to get it in a concise manner, where one lecture could be, could be enough to understand it. Again, I will be extremely looking forward to seeing you folks in the in the live session. You could come up with all of your questions regarding genetic algorithms, genetic programming, I did not I did not put material on genetic program because the material I have is way bigger than what he just discussed. And I didn't I did not want to burden you with material for the second exam. So if you have any question, bring them and then co in our session Thursday, thank you and goodbye.
